
% The second edition of 'Reinforcement Learning: An Introduction' by Sutton and Barto provides comprehensive foundational background on reinforcement learning methods and principles. It is relevant for the paper's discussion on integrating language models with reinforcement learning for scenario simulation, especially in dynamic environments.
@inproceedings{sutton2018reinforcementl,
 author = {R. S. Sutton and A. Barto},
 title = {Reinforcement learning - an introduction, 2nd Edition},
 year = {2018}
}

% The paper 'DynaThink: Fast or Slow? A Dynamic Decision-Making Framework for Large Language Models' introduces a framework for LLMs to autonomously select between fast and slow inference methods, optimizing for efficiency and effectiveness. This study is relevant for supporting the concept of using LLMs to enhance decision-making by simulating potential future scenarios in dynamic environments. It can be cited in the related work section to highlight existing efforts in applying LLMs to dynamic decision-making tasks.
@article{pan2024dynathinkfo,
 author = {Jiabao Pan and Yan Zhang and Chen Zhang and Zuozhu Liu and Hongwei Wang and Haizhou Li},
 booktitle = {Conference on Empirical Methods in Natural Language Processing},
 pages = {14686-14695},
 title = {DynaThink: Fast or Slow? A Dynamic Decision-Making Framework for Large Language Models},
 year = {2024}
}

% The paper 'Towards Intelligent Emergency Management: A Scenario–Learning–Decision Framework Enabled by Large Language Models' discusses a scenario-based framework powered by LLMs to improve decision-making in emergency management contexts. This work supports our hypothesis that LLMs can generate diverse and plausible future scenarios, enhancing decision-making when integrated with reinforcement learning systems. It should be cited in the related work section to highlight existing efforts in applying LLMs to scenario simulation for decision-making in dynamic environments.
@article{wang2025towardsie,
 author = {Yi Wang and Chengliang Wang and Xueqing Zhang and Li Zeng},
 booktitle = {Mathematics},
 journal = {Mathematics},
 title = {Towards Intelligent Emergency Management: A Scenario–Learning–Decision Framework Enabled by Large Language Models},
 year = {2025}
}

% The paper 'HADES: Hardware Accelerated Decoding for Efficient Speculation in Large Language Models' introduces a novel approach to enhance the performance and energy efficiency of LLMs through hardware-level speculative decoding. This work is relevant to addressing the computational overhead risk factor in our proposal, as it provides insights into managing computational resources effectively in LLM-based systems. It should be cited in the risk factors and limitations section to support discussions on potential solutions for computational challenges in scenario simulation with LLMs.
@article{yang2024hadesha,
 author = {Ze Yang and Yihong Jin and Xinhe Xu},
 booktitle = {International Conference Civil Engineering and Architecture},
 journal = {2025 6th International Conference on Computer Engineering and Application (ICCEA)},
 pages = {01-05},
 title = {HADES: Hardware Accelerated Decoding for Efficient Speculation in Large Language Models},
 year = {2024}
}

% The paper 'Critical Scenario Generation for Developing Trustworthy Autonomy' discusses the challenges and methodologies for generating diverse, realistic, and effective scenarios in simulations. This work is relevant for supporting the discussion on evaluating the quality and diversity of LLM-generated scenarios in dynamic environments. It should be cited in the Experiments or Risk Factors And Limitations sections to highlight the challenges in scenario evaluation within LLM-based decision-making frameworks.
@article{ding2023criticalsg,
 author = {Wenhao Ding},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {Critical Scenario Generation for Developing Trustworthy Autonomy},
 volume = {abs/2305.00339},
 year = {2023}
}
