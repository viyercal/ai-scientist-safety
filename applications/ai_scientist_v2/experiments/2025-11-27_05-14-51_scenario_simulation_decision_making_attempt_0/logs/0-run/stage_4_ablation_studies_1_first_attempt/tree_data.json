{"edges": [[0, 3], [0, 2], [0, 1], [2, 4]], "layout": [[0.5, 0.0], [0.0, 0.5], [0.5, 0.5], [1.0, 0.5], [0.5, 1.0]], "plan": ["Hyperparam tuning name: batch size. To implement hyperparameter tuning for batch\nsize, I will modify the training loop to iterate over a list of predefined batch\nsizes. For each batch size, I will split the training data into batches, train\nthe model on each batch, and collect the training and validation metrics for\neach size. After completing the training for all batch sizes, I will save the\nresults in the specified structured format.", "Ablation name: Multi-Dataset Evaluation. To implement the Multi-Dataset\nEvaluation ablation study, I will create three distinct synthetic datasets with\nvarying characteristics, ensuring differences in feature distributions and\nreward functions. I will modify the existing training loop to iterate through\neach dataset, allowing the model's performance to be evaluated separately on\neach one. The results, including metrics and losses for train and validation\nphases, will be saved in a structured format under the specified naming\nconvention.", "Ablation name: Feature Dimensionality Reduction. To conduct an ablation study on\nfeature dimensionality reduction using PCA, I will first apply PCA on the\nsynthetic dataset to reduce its 10 features down to 5, 3, and 2 dimensions.\nThen, I will train the same neural network model on these reduced feature sets\nand assess model performances via training and validation losses, as well as\npredictive metrics. The results from these experiments will be saved in a\nstructured format.", "Ablation name: Multiple Synthetic Datasets Evaluation. To implement the ablation\nstudy for evaluating the model's performance on multiple synthetic datasets, I\nwill generate three distinct synthetic datasets with varying characteristics\n(such as feature distributions and noise levels). For each dataset, I will train\nthe model using different batch sizes and record the training and validation\nlosses along with the SORS metrics. After training on all datasets, the metrics\nwill be saved in a structured format that allows easy access and visualization.", "Seed node"], "code": ["import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\n\n# Set working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Synthetic dataset generation\nnp.random.seed(42)\nstate_space = np.random.rand(1000, 10)  # 1000 samples, 10 features\nactions = np.random.randint(0, 2, size=(1000, 1))  # Binary actions\nrewards = actions * np.sum(state_space, axis=1, keepdims=True) + np.random.normal(\n    0, 0.1, (1000, 1)\n)  # Reward function with noise\n\n# Train-test split\nX_train, X_val, y_train, y_val = train_test_split(\n    state_space, rewards, test_size=0.2, random_state=42\n)\n\n# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# Define the simple neural network\nclass SimpleNN(nn.Module):\n    def __init__(self):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(10, 32)\n        self.fc2 = nn.Linear(32, 1)\n\n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\n\n# Prepare data tensors\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\ny_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\nX_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\ny_val_tensor = torch.tensor(y_val, dtype=torch.float32).to(device)\n\n# Experiment data dictionary\nexperiment_data = {\n    \"hyperparam_tuning_batch_size\": {\n        \"synthetic_dataset\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n    },\n}\n\n# Hyperparameter tuning: batch sizes to experiment with\nbatch_sizes = [16, 32, 64, 128, 256]\nn_epochs = 50\n\nfor batch_size in batch_sizes:\n    print(f\"Training with batch size: {batch_size}\")\n\n    # Initialize model and optimizer for each batch size\n    model = SimpleNN().to(device)\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    criterion = nn.MSELoss()\n\n    for epoch in range(n_epochs):\n        model.train()\n\n        # Mini-batch training\n        for i in range(0, len(X_train_tensor), batch_size):\n            X_batch = X_train_tensor[i : i + batch_size]\n            y_batch = y_train_tensor[i : i + batch_size]\n            optimizer.zero_grad()\n            outputs = model(X_batch)\n            loss = criterion(outputs, y_batch)\n            loss.backward()\n            optimizer.step()\n\n        # Validation\n        model.eval()\n        with torch.no_grad():\n            val_outputs = model(X_val_tensor)\n            val_loss = criterion(val_outputs, y_val_tensor)\n\n            # Calculate SORS\n            sors = torch.mean(\n                torch.abs(val_outputs - y_val_tensor)\n            ).item()  # this is a simple version of SORS\n\n        # Store metrics\n        experiment_data[\"hyperparam_tuning_batch_size\"][\"synthetic_dataset\"][\"losses\"][\n            \"train\"\n        ].append(loss.item())\n        experiment_data[\"hyperparam_tuning_batch_size\"][\"synthetic_dataset\"][\"losses\"][\n            \"val\"\n        ].append(val_loss.item())\n        experiment_data[\"hyperparam_tuning_batch_size\"][\"synthetic_dataset\"][\"metrics\"][\n            \"train\"\n        ].append(sors)\n        experiment_data[\"hyperparam_tuning_batch_size\"][\"synthetic_dataset\"][\"metrics\"][\n            \"val\"\n        ].append(sors)\n\n        print(\n            f\"Epoch {epoch + 1}/{n_epochs}, Train Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}, SORS: {sors:.4f}\"\n        )\n\n# Save experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\n\n# Set working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n\n# Function to generate synthetic datasets\ndef generate_synthetic_dataset(seed, num_samples=1000, num_features=10):\n    np.random.seed(seed)\n    state_space = np.random.rand(num_samples, num_features)\n    actions = np.random.randint(0, 2, size=(num_samples, 1))\n    rewards = actions * np.sum(state_space, axis=1, keepdims=True) + np.random.normal(\n        0, 0.1, (num_samples, 1)\n    )\n    return state_space, rewards\n\n\n# Generate three distinct synthetic datasets\ndatasets = {\n    \"dataset_1\": generate_synthetic_dataset(42),\n    \"dataset_2\": generate_synthetic_dataset(43),\n    \"dataset_3\": generate_synthetic_dataset(44),\n}\n\n# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# Define the simple neural network\nclass SimpleNN(nn.Module):\n    def __init__(self):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(10, 32)\n        self.fc2 = nn.Linear(32, 1)\n\n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\n\n# Experiment data dictionary\nexperiment_data = {\"multi_dataset_evaluation\": {}}\n\n# Hyperparameter tuning: batch sizes to experiment with\nbatch_sizes = [16, 32, 64, 128, 256]\nn_epochs = 50\n\n# Train and evaluate on each dataset\nfor dataset_name, (state_space, rewards) in datasets.items():\n    print(f\"Evaluating {dataset_name}\")\n\n    # Train-test split\n    X_train, X_val, y_train, y_val = train_test_split(\n        state_space, rewards, test_size=0.2, random_state=42\n    )\n\n    # Prepare data tensors\n    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n    X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n    y_val_tensor = torch.tensor(y_val, dtype=torch.float32).to(device)\n\n    experiment_data[\"multi_dataset_evaluation\"][dataset_name] = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    for batch_size in batch_sizes:\n        print(f\"Training with batch size: {batch_size}\")\n\n        # Initialize model and optimizer for each batch size\n        model = SimpleNN().to(device)\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n        criterion = nn.MSELoss()\n\n        for epoch in range(n_epochs):\n            model.train()\n\n            # Mini-batch training\n            for i in range(0, len(X_train_tensor), batch_size):\n                X_batch = X_train_tensor[i : i + batch_size]\n                y_batch = y_train_tensor[i : i + batch_size]\n                optimizer.zero_grad()\n                outputs = model(X_batch)\n                loss = criterion(outputs, y_batch)\n                loss.backward()\n                optimizer.step()\n\n            # Validation\n            model.eval()\n            with torch.no_grad():\n                val_outputs = model(X_val_tensor)\n                val_loss = criterion(val_outputs, y_val_tensor)\n\n                # Calculate SORS\n                sors = torch.mean(torch.abs(val_outputs - y_val_tensor)).item()\n\n            # Store metrics\n            experiment_data[\"multi_dataset_evaluation\"][dataset_name][\"losses\"][\n                \"train\"\n            ].append(loss.item())\n            experiment_data[\"multi_dataset_evaluation\"][dataset_name][\"losses\"][\n                \"val\"\n            ].append(val_loss.item())\n            experiment_data[\"multi_dataset_evaluation\"][dataset_name][\"metrics\"][\n                \"train\"\n            ].append(sors)\n            experiment_data[\"multi_dataset_evaluation\"][dataset_name][\"metrics\"][\n                \"val\"\n            ].append(sors)\n\n            print(\n                f\"Epoch {epoch + 1}/{n_epochs}, Train Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}, SORS: {sors:.4f}\"\n            )\n\n# Save experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\n\n# Set working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Synthetic dataset generation\nnp.random.seed(42)\nstate_space = np.random.rand(1000, 10)  # 1000 samples, 10 features\nactions = np.random.randint(0, 2, size=(1000, 1))  # Binary actions\nrewards = actions * np.sum(state_space, axis=1, keepdims=True) + np.random.normal(\n    0, 0.1, (1000, 1)\n)  # Reward function with noise\n\n# Train-test split\nX_train, X_val, y_train, y_val = train_test_split(\n    state_space, rewards, test_size=0.2, random_state=42\n)\n\n# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# Define the simple neural network\nclass SimpleNN(nn.Module):\n    def __init__(self, input_dim):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(input_dim, 32)\n        self.fc2 = nn.Linear(32, 1)\n\n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\n\n# Experiment data dictionary\nexperiment_data = {\n    \"feature_dimensionality_reduction\": {\n        \"full_dataset\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n        \"pca_5d\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n        \"pca_3d\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n        \"pca_2d\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n    }\n}\n\n\n# Function to train and evaluate the model\ndef train_and_evaluate(X_train, X_val, y_train, y_val, experiment_key):\n    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n    X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n    y_val_tensor = torch.tensor(y_val, dtype=torch.float32).to(device)\n\n    batch_sizes = [16, 32, 64, 128, 256]\n    n_epochs = 50\n\n    for batch_size in batch_sizes:\n        print(f\"Training {experiment_key} with batch size: {batch_size}\")\n\n        model = SimpleNN(X_train.shape[1]).to(device)\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n        criterion = nn.MSELoss()\n\n        for epoch in range(n_epochs):\n            model.train()\n            for i in range(0, len(X_train_tensor), batch_size):\n                X_batch = X_train_tensor[i : i + batch_size]\n                y_batch = y_train_tensor[i : i + batch_size]\n                optimizer.zero_grad()\n                outputs = model(X_batch)\n                loss = criterion(outputs, y_batch)\n                loss.backward()\n                optimizer.step()\n\n            model.eval()\n            with torch.no_grad():\n                val_outputs = model(X_val_tensor)\n                val_loss = criterion(val_outputs, y_val_tensor)\n                sors = torch.mean(torch.abs(val_outputs - y_val_tensor)).item()\n\n            # Store metrics\n            experiment_data[\"feature_dimensionality_reduction\"][experiment_key][\n                \"losses\"\n            ][\"train\"].append(loss.item())\n            experiment_data[\"feature_dimensionality_reduction\"][experiment_key][\n                \"losses\"\n            ][\"val\"].append(val_loss.item())\n            experiment_data[\"feature_dimensionality_reduction\"][experiment_key][\n                \"metrics\"\n            ][\"train\"].append(sors)\n            experiment_data[\"feature_dimensionality_reduction\"][experiment_key][\n                \"metrics\"\n            ][\"val\"].append(sors)\n\n            print(\n                f\"Epoch {epoch+1}/{n_epochs}, Train Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}, SORS: {sors:.4f}\"\n            )\n\n\n# Train and evaluate on full dataset\ntrain_and_evaluate(X_train, X_val, y_train, y_val, \"full_dataset\")\n\n# Apply PCA and reduce dimensionality\npca_list = [5, 3, 2]\nfor n_components in pca_list:\n    pca = PCA(n_components=n_components)\n    X_train_pca = pca.fit_transform(X_train)\n    X_val_pca = pca.transform(X_val)\n    train_and_evaluate(X_train_pca, X_val_pca, y_train, y_val, f\"pca_{n_components}d\")\n\n# Save experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\n\n# Set working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n\n# Function to generate synthetic dataset\ndef generate_synthetic_dataset(\n    num_samples=1000, noise_level=0.1, feature_distribution=\"uniform\"\n):\n    state_space = (\n        np.random.rand(num_samples, 10)\n        if feature_distribution == \"uniform\"\n        else np.random.randn(num_samples, 10)\n    )\n    actions = np.random.randint(0, 2, size=(num_samples, 1))  # Binary actions\n    rewards = actions * np.sum(state_space, axis=1, keepdims=True) + np.random.normal(\n        0, noise_level, (num_samples, 1)\n    )\n    return train_test_split(state_space, rewards, test_size=0.2, random_state=42)\n\n\n# Generate multiple synthetic datasets\ndatasets = {\n    \"dataset_1\": generate_synthetic_dataset(\n        noise_level=0.1, feature_distribution=\"uniform\"\n    ),\n    \"dataset_2\": generate_synthetic_dataset(\n        noise_level=0.2, feature_distribution=\"uniform\"\n    ),\n    \"dataset_3\": generate_synthetic_dataset(\n        noise_level=0.1, feature_distribution=\"normal\"\n    ),\n}\n\n# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# Define the simple neural network\nclass SimpleNN(nn.Module):\n    def __init__(self):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(10, 32)\n        self.fc2 = nn.Linear(32, 1)\n\n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\n\n# Experiment data dictionary\nexperiment_data = {\"multiple_synthetic_datasets\": {}}\n\n# Hyperparameter tuning: batch sizes to experiment with\nbatch_sizes = [16, 32, 64, 128, 256]\nn_epochs = 50\n\nfor dataset_name, (X_train, X_val, y_train, y_val) in datasets.items():\n    print(f\"Evaluating on {dataset_name}\")\n\n    # Prepare data tensors\n    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n    X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n    y_val_tensor = torch.tensor(y_val, dtype=torch.float32).to(device)\n\n    experiment_data[\"multiple_synthetic_datasets\"][dataset_name] = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    for batch_size in batch_sizes:\n        print(f\" Training with batch size: {batch_size}\")\n\n        # Initialize model and optimizer for each batch size\n        model = SimpleNN().to(device)\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n        criterion = nn.MSELoss()\n\n        for epoch in range(n_epochs):\n            model.train()\n\n            # Mini-batch training\n            for i in range(0, len(X_train_tensor), batch_size):\n                X_batch = X_train_tensor[i : i + batch_size]\n                y_batch = y_train_tensor[i : i + batch_size]\n                optimizer.zero_grad()\n                outputs = model(X_batch)\n                loss = criterion(outputs, y_batch)\n                loss.backward()\n                optimizer.step()\n\n            # Validation\n            model.eval()\n            with torch.no_grad():\n                val_outputs = model(X_val_tensor)\n                val_loss = criterion(val_outputs, y_val_tensor)\n\n                # Calculate SORS\n                sors = torch.mean(\n                    torch.abs(val_outputs - y_val_tensor)\n                ).item()  # this is a simple version of SORS\n\n            # Store metrics\n            experiment_data[\"multiple_synthetic_datasets\"][dataset_name][\"losses\"][\n                \"train\"\n            ].append(loss.item())\n            experiment_data[\"multiple_synthetic_datasets\"][dataset_name][\"losses\"][\n                \"val\"\n            ].append(val_loss.item())\n            experiment_data[\"multiple_synthetic_datasets\"][dataset_name][\"metrics\"][\n                \"train\"\n            ].append(sors)\n            experiment_data[\"multiple_synthetic_datasets\"][dataset_name][\"metrics\"][\n                \"val\"\n            ].append(sors)\n\n            print(\n                f\" Epoch {epoch + 1}/{n_epochs}, Train Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}, SORS: {sors:.4f}\"\n            )\n\n# Save experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\n\n# Set working directory\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n# Synthetic dataset generation\nnp.random.seed(42)\nstate_space = np.random.rand(1000, 10)  # 1000 samples, 10 features\nactions = np.random.randint(0, 2, size=(1000, 1))  # Binary actions\nrewards = actions * np.sum(state_space, axis=1, keepdims=True) + np.random.normal(\n    0, 0.1, (1000, 1)\n)  # Reward function with noise\n\n# Train-test split\nX_train, X_val, y_train, y_val = train_test_split(\n    state_space, rewards, test_size=0.2, random_state=42\n)\n\n# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# Define the simple neural network\nclass SimpleNN(nn.Module):\n    def __init__(self, input_dim):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(input_dim, 32)\n        self.fc2 = nn.Linear(32, 1)\n\n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\n\n# Experiment data dictionary\nexperiment_data = {\n    \"feature_dimensionality_reduction\": {\n        \"full_dataset\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n        \"pca_5d\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n        \"pca_3d\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n        \"pca_2d\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n    }\n}\n\n\n# Function to train and evaluate the model\ndef train_and_evaluate(X_train, X_val, y_train, y_val, experiment_key):\n    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n    X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n    y_val_tensor = torch.tensor(y_val, dtype=torch.float32).to(device)\n\n    batch_sizes = [16, 32, 64, 128, 256]\n    n_epochs = 50\n\n    for batch_size in batch_sizes:\n        print(f\"Training {experiment_key} with batch size: {batch_size}\")\n\n        model = SimpleNN(X_train.shape[1]).to(device)\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n        criterion = nn.MSELoss()\n\n        for epoch in range(n_epochs):\n            model.train()\n            for i in range(0, len(X_train_tensor), batch_size):\n                X_batch = X_train_tensor[i : i + batch_size]\n                y_batch = y_train_tensor[i : i + batch_size]\n                optimizer.zero_grad()\n                outputs = model(X_batch)\n                loss = criterion(outputs, y_batch)\n                loss.backward()\n                optimizer.step()\n\n            model.eval()\n            with torch.no_grad():\n                val_outputs = model(X_val_tensor)\n                val_loss = criterion(val_outputs, y_val_tensor)\n                sors = torch.mean(torch.abs(val_outputs - y_val_tensor)).item()\n\n            # Store metrics\n            experiment_data[\"feature_dimensionality_reduction\"][experiment_key][\n                \"losses\"\n            ][\"train\"].append(loss.item())\n            experiment_data[\"feature_dimensionality_reduction\"][experiment_key][\n                \"losses\"\n            ][\"val\"].append(val_loss.item())\n            experiment_data[\"feature_dimensionality_reduction\"][experiment_key][\n                \"metrics\"\n            ][\"train\"].append(sors)\n            experiment_data[\"feature_dimensionality_reduction\"][experiment_key][\n                \"metrics\"\n            ][\"val\"].append(sors)\n\n            print(\n                f\"Epoch {epoch+1}/{n_epochs}, Train Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}, SORS: {sors:.4f}\"\n            )\n\n\n# Train and evaluate on full dataset\ntrain_and_evaluate(X_train, X_val, y_train, y_val, \"full_dataset\")\n\n# Apply PCA and reduce dimensionality\npca_list = [5, 3, 2]\nfor n_components in pca_list:\n    pca = PCA(n_components=n_components)\n    X_train_pca = pca.fit_transform(X_train)\n    X_val_pca = pca.transform(X_val)\n    train_and_evaluate(X_train_pca, X_val_pca, y_train, y_val, f\"pca_{n_components}d\")\n\n# Save experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n"], "term_out": ["['Using device: cuda', '\\n', 'Training with batch size: 16', '\\n', 'Epoch 1/50,\nTrain Loss: 9.9592, Val Loss: 8.7622, SORS: 2.4666', '\\n', 'Epoch 2/50, Train\nLoss: 7.0277, Val Loss: 6.3445, SORS: 2.4516', '\\n', 'Epoch 3/50, Train Loss:\n6.7200, Val Loss: 6.1832, SORS: 2.4465', '\\n', 'Epoch 4/50, Train Loss: 6.6892,\nVal Loss: 6.1759, SORS: 2.4451', '\\n', 'Epoch 5/50, Train Loss: 6.6577, Val\nLoss: 6.1693, SORS: 2.4437', '\\n', 'Epoch 6/50, Train Loss: 6.6252, Val Loss:\n6.1637, SORS: 2.4425', '\\n', 'Epoch 7/50, Train Loss: 6.5943, Val Loss: 6.1582,\nSORS: 2.4412', '\\n', 'Epoch 8/50, Train Loss: 6.5650, Val Loss: 6.1531, SORS:\n2.4400', '\\n', 'Epoch 9/50, Train Loss: 6.5368, Val Loss: 6.1482, SORS: 2.4387',\n'\\n', 'Epoch 10/50, Train Loss: 6.5090, Val Loss: 6.1436, SORS: 2.4375', '\\n',\n'Epoch 11/50, Train Loss: 6.4829, Val Loss: 6.1395, SORS: 2.4363', '\\n', 'Epoch\n12/50, Train Loss: 6.4575, Val Loss: 6.1358, SORS: 2.4352', '\\n', 'Epoch 13/50,\nTrain Loss: 6.4326, Val Loss: 6.1324, SORS: 2.4341', '\\n', 'Epoch 14/50, Train\nLoss: 6.4087, Val Loss: 6.1294, SORS: 2.4330', '\\n', 'Epoch 15/50, Train Loss:\n6.3862, Val Loss: 6.1265, SORS: 2.4320', '\\n', 'Epoch 16/50, Train Loss: 6.3635,\nVal Loss: 6.1242, SORS: 2.4311', '\\n', 'Epoch 17/50, Train Loss: 6.3417, Val\nLoss: 6.1218, SORS: 2.4301', '\\n', 'Epoch 18/50, Train Loss: 6.3206, Val Loss:\n6.1203, SORS: 2.4294', '\\n', 'Epoch 19/50, Train Loss: 6.2981, Val Loss: 6.1189,\nSORS: 2.4286', '\\n', 'Epoch 20/50, Train Loss: 6.2786, Val Loss: 6.1181, SORS:\n2.4279', '\\n', 'Epoch 21/50, Train Loss: 6.2578, Val Loss: 6.1169, SORS:\n2.4272', '\\n', 'Epoch 22/50, Train Loss: 6.2397, Val Loss: 6.1161, SORS:\n2.4266', '\\n', 'Epoch 23/50, Train Loss: 6.2199, Val Loss: 6.1152, SORS:\n2.4260', '\\n', 'Epoch 24/50, Train Loss: 6.2034, Val Loss: 6.1150, SORS:\n2.4255', '\\n', 'Epoch 25/50, Train Loss: 6.1860, Val Loss: 6.1154, SORS:\n2.4250', '\\n', 'Epoch 26/50, Train Loss: 6.1692, Val Loss: 6.1150, SORS:\n2.4246', '\\n', 'Epoch 27/50, Train Loss: 6.1513, Val Loss: 6.1153, SORS:\n2.4241', '\\n', 'Epoch 28/50, Train Loss: 6.1386, Val Loss: 6.1153, SORS:\n2.4237', '\\n', 'Epoch 29/50, Train Loss: 6.1208, Val Loss: 6.1147, SORS:\n2.4232', '\\n', 'Epoch 30/50, Train Loss: 6.1061, Val Loss: 6.1145, SORS:\n2.4228', '\\n', 'Epoch 31/50, Train Loss: 6.0913, Val Loss: 6.1151, SORS:\n2.4225', '\\n', 'Epoch 32/50, Train Loss: 6.0763, Val Loss: 6.1153, SORS:\n2.4222', '\\n', 'Epoch 33/50, Train Loss: 6.0599, Val Loss: 6.1152, SORS:\n2.4218', '\\n', 'Epoch 34/50, Train Loss: 6.0464, Val Loss: 6.1162, SORS:\n2.4216', '\\n', 'Epoch 35/50, Train Loss: 6.0345, Val Loss: 6.1149, SORS:\n2.4209', '\\n', 'Epoch 36/50, Train Loss: 6.0220, Val Loss: 6.1158, SORS:\n2.4207', '\\n', 'Epoch 37/50, Train Loss: 6.0093, Val Loss: 6.1169, SORS:\n2.4205', '\\n', 'Epoch 38/50, Train Loss: 5.9939, Val Loss: 6.1171, SORS:\n2.4202', '\\n', 'Epoch 39/50, Train Loss: 5.9770, Val Loss: 6.1192, SORS:\n2.4201', '\\n', 'Epoch 40/50, Train Loss: 5.9619, Val Loss: 6.1201, SORS:\n2.4200', '\\n', 'Epoch 41/50, Train Loss: 5.9463, Val Loss: 6.1204, SORS:\n2.4197', '\\n', 'Epoch 42/50, Train Loss: 5.9417, Val Loss: 6.1209, SORS:\n2.4195', '\\n', 'Epoch 43/50, Train Loss: 5.9276, Val Loss: 6.1212, SORS:\n2.4193', '\\n', 'Epoch 44/50, Train Loss: 5.9132, Val Loss: 6.1217, SORS:\n2.4190', '\\n', 'Epoch 45/50, Train Loss: 5.8990, Val Loss: 6.1211, SORS:\n2.4186', '\\n', 'Epoch 46/50, Train Loss: 5.8868, Val Loss: 6.1207, SORS:\n2.4184', '\\n', 'Epoch 47/50, Train Loss: 5.8734, Val Loss: 6.1208, SORS:\n2.4180', '\\n', 'Epoch 48/50, Train Loss: 5.8633, Val Loss: 6.1209, SORS:\n2.4178', '\\n', 'Epoch 49/50, Train Loss: 5.8518, Val Loss: 6.1207, SORS:\n2.4174', '\\n', 'Epoch 50/50, Train Loss: 5.8437, Val Loss: 6.1211, SORS:\n2.4173', '\\n', 'Training with batch size: 32', '\\n', 'Epoch 1/50, Train Loss:\n10.1707, Val Loss: 10.1217, SORS: 2.4759', '\\n', 'Epoch 2/50, Train Loss:\n8.5165, Val Loss: 8.3449, SORS: 2.4685', '\\n', 'Epoch 3/50, Train Loss: 7.2613,\nVal Loss: 6.9286, SORS: 2.4595', '\\n', 'Epoch 4/50, Train Loss: 6.7853, Val\nLoss: 6.2893, SORS: 2.4513', '\\n', 'Epoch 5/50, Train Loss: 6.7926, Val Loss:\n6.1950, SORS: 2.4460', '\\n', 'Epoch 6/50, Train Loss: 6.8027, Val Loss: 6.1917,\nSORS: 2.4442', '\\n', 'Epoch 7/50, Train Loss: 6.7769, Val Loss: 6.1858, SORS:\n2.4435', '\\n', 'Epoch 8/50, Train Loss: 6.7549, Val Loss: 6.1809, SORS: 2.4428',\n'\\n', 'Epoch 9/50, Train Loss: 6.7367, Val Loss: 6.1768, SORS: 2.4420', '\\n',\n'Epoch 10/50, Train Loss: 6.7198, Val Loss: 6.1731, SORS: 2.4412', '\\n', 'Epoch\n11/50, Train Loss: 6.7031, Val Loss: 6.1696, SORS: 2.4404', '\\n', 'Epoch 12/50,\nTrain Loss: 6.6869, Val Loss: 6.1662, SORS: 2.4397', '\\n', 'Epoch 13/50, Train\nLoss: 6.6709, Val Loss: 6.1631, SORS: 2.4390', '\\n', 'Epoch 14/50, Train Loss:\n6.6551, Val Loss: 6.1603, SORS: 2.4383', '\\n', 'Epoch 15/50, Train Loss: 6.6401,\nVal Loss: 6.1577, SORS: 2.4376', '\\n', 'Epoch 16/50, Train Loss: 6.6255, Val\nLoss: 6.1553, SORS: 2.4370', '\\n', 'Epoch 17/50, Train Loss: 6.6112, Val Loss:\n6.1531, SORS: 2.4364', '\\n', 'Epoch 18/50, Train Loss: 6.5976, Val Loss: 6.1512,\nSORS: 2.4358', '\\n', 'Epoch 19/50, Train Loss: 6.5842, Val Loss: 6.1494, SORS:\n2.4352', '\\n', 'Epoch 20/50, Train Loss: 6.5714, Val Loss: 6.1477, SORS:\n2.4346', '\\n', 'Epoch 21/50, Train Loss: 6.5588, Val Loss: 6.1461, SORS:\n2.4341', '\\n', 'Epoch 22/50, Train Loss: 6.5469, Val Loss: 6.1447, SORS:\n2.4336', '\\n', 'Epoch 23/50, Train Loss: 6.5350, Val Loss: 6.1434, SORS:\n2.4331', '\\n', 'Epoch 24/50, Train Loss: 6.5238, Val Loss: 6.1423, SORS:\n2.4326', '\\n', 'Epoch 25/50, Train Loss: 6.5124, Val Loss: 6.1412, SORS:\n2.4321', '\\n', 'Epoch 26/50, Train Loss: 6.5018, Val Loss: 6.1403, SORS:\n2.4316', '\\n', 'Epoch 27/50, Train Loss: 6.4911, Val Loss: 6.1393, SORS:\n2.4312', '\\n', 'Epoch 28/50, Train Loss: 6.4807, Val Loss: 6.1386, SORS:\n2.4308', '\\n', 'Epoch 29/50, Train Loss: 6.4710, Val Loss: 6.1379, SORS:\n2.4304', '\\n', 'Epoch 30/50, Train Loss: 6.4616, Val Loss: 6.1373, SORS:\n2.4300', '\\n', 'Epoch 31/50, Train Loss: 6.4523, Val Loss: 6.1368, SORS:\n2.4296', '\\n', 'Epoch 32/50, Train Loss: 6.4435, Val Loss: 6.1364, SORS:\n2.4292', '\\n', 'Epoch 33/50, Train Loss: 6.4349, Val Loss: 6.1363, SORS:\n2.4289', '\\n', 'Epoch 34/50, Train Loss: 6.4266, Val Loss: 6.1361, SORS:\n2.4286', '\\n', 'Epoch 35/50, Train Loss: 6.4178, Val Loss: 6.1364, SORS:\n2.4283', '\\n', 'Epoch 36/50, Train Loss: 6.4092, Val Loss: 6.1363, SORS:\n2.4280', '\\n', 'Epoch 37/50, Train Loss: 6.4007, Val Loss: 6.1364, SORS:\n2.4278', '\\n', 'Epoch 38/50, Train Loss: 6.3924, Val Loss: 6.1367, SORS:\n2.4275', '\\n', 'Epoch 39/50, Train Loss: 6.3841, Val Loss: 6.1372, SORS:\n2.4273', '\\n', 'Epoch 40/50, Train Loss: 6.3767, Val Loss: 6.1375, SORS:\n2.4271', '\\n', 'Epoch 41/50, Train Loss: 6.3695, Val Loss: 6.1377, SORS:\n2.4269', '\\n', 'Epoch 42/50, Train Loss: 6.3627, Val Loss: 6.1378, SORS:\n2.4267', '\\n', 'Epoch 43/50, Train Loss: 6.3569, Val Loss: 6.1379, SORS:\n2.4265', '\\n', 'Epoch 44/50, Train Loss: 6.3508, Val Loss: 6.1380, SORS:\n2.4263', '\\n', 'Epoch 45/50, Train Loss: 6.3455, Val Loss: 6.1379, SORS:\n2.4261', '\\n', 'Epoch 46/50, Train Loss: 6.3401, Val Loss: 6.1381, SORS:\n2.4259', '\\n', 'Epoch 47/50, Train Loss: 6.3351, Val Loss: 6.1380, SORS:\n2.4257', '\\n', 'Epoch 48/50, Train Loss: 6.3302, Val Loss: 6.1385, SORS:\n2.4256', '\\n', 'Epoch 49/50, Train Loss: 6.3252, Val Loss: 6.1385, SORS:\n2.4255', '\\n', 'Epoch 50/50, Train Loss: 6.3211, Val Loss: 6.1391, SORS:\n2.4254', '\\n', 'Training with batch size: 64', '\\n', 'Epoch 1/50, Train Loss:\n11.9955, Val Loss: 12.2566, SORS: 2.4905', '\\n', 'Epoch 2/50, Train Loss:\n11.2798, Val Loss: 11.4991, SORS: 2.4775', '\\n', 'Epoch 3/50, Train Loss:\n10.5719, Val Loss: 10.7524, SORS: 2.4750', '\\n', 'Epoch 4/50, Train Loss:\n9.8045, Val Loss: 9.9522, SORS: 2.4739', '\\n', 'Epoch 5/50, Train Loss: 8.9488,\nVal Loss: 9.0651, SORS: 2.4716', '\\n', 'Epoch 6/50, Train Loss: 8.0737, Val\nLoss: 8.1449, SORS: 2.4685', '\\n', 'Epoch 7/50, Train Loss: 7.3464, Val Loss:\n7.3325, SORS: 2.4650', '\\n', 'Epoch 8/50, Train Loss: 6.8703, Val Loss: 6.7480,\nSORS: 2.4614', '\\n', 'Epoch 9/50, Train Loss: 6.6518, Val Loss: 6.4180, SORS:\n2.4584', '\\n', 'Epoch 10/50, Train Loss: 6.6103, Val Loss: 6.2806, SORS:\n2.4559', '\\n', 'Epoch 11/50, Train Loss: 6.6407, Val Loss: 6.2440, SORS:\n2.4541', '\\n', 'Epoch 12/50, Train Loss: 6.6698, Val Loss: 6.2395, SORS:\n2.4530', '\\n', 'Epoch 13/50, Train Loss: 6.6774, Val Loss: 6.2389, SORS:\n2.4524', '\\n', 'Epoch 14/50, Train Loss: 6.6710, Val Loss: 6.2371, SORS:\n2.4520', '\\n', 'Epoch 15/50, Train Loss: 6.6602, Val Loss: 6.2350, SORS:\n2.4517', '\\n', 'Epoch 16/50, Train Loss: 6.6496, Val Loss: 6.2329, SORS:\n2.4513', '\\n', 'Epoch 17/50, Train Loss: 6.6405, Val Loss: 6.2309, SORS:\n2.4509', '\\n', 'Epoch 18/50, Train Loss: 6.6323, Val Loss: 6.2291, SORS:\n2.4505', '\\n', 'Epoch 19/50, Train Loss: 6.6245, Val Loss: 6.2273, SORS:\n2.4501', '\\n', 'Epoch 20/50, Train Loss: 6.6169, Val Loss: 6.2255, SORS:\n2.4497', '\\n', 'Epoch 21/50, Train Loss: 6.6092, Val Loss: 6.2238, SORS:\n2.4492', '\\n', 'Epoch 22/50, Train Loss: 6.6014, Val Loss: 6.2220, SORS:\n2.4488', '\\n', 'Epoch 23/50, Train Loss: 6.5935, Val Loss: 6.2203, SORS:\n2.4484', '\\n', 'Epoch 24/50, Train Loss: 6.5855, Val Loss: 6.2186, SORS:\n2.4480', '\\n', 'Epoch 25/50, Train Loss: 6.5776, Val Loss: 6.2169, SORS:\n2.4475', '\\n', 'Epoch 26/50, Train Loss: 6.5696, Val Loss: 6.2152, SORS:\n2.4471', '\\n', 'Epoch 27/50, Train Loss: 6.5616, Val Loss: 6.2136, SORS:\n2.4467', '\\n', 'Epoch 28/50, Train Loss: 6.5537, Val Loss: 6.2120, SORS:\n2.4462', '\\n', 'Epoch 29/50, Train Loss: 6.5457, Val Loss: 6.2103, SORS:\n2.4458', '\\n', 'Epoch 30/50, Train Loss: 6.5380, Val Loss: 6.2087, SORS:\n2.4453', '\\n', 'Epoch 31/50, Train Loss: 6.5303, Val Loss: 6.2071, SORS:\n2.4449', '\\n', 'Epoch 32/50, Train Loss: 6.5226, Val Loss: 6.2055, SORS:\n2.4444', '\\n', 'Epoch 33/50, Train Loss: 6.5150, Val Loss: 6.2039, SORS:\n2.4440', '\\n', 'Epoch 34/50, Train Loss: 6.5075, Val Loss: 6.2024, SORS:\n2.4435', '\\n', 'Epoch 35/50, Train Loss: 6.5000, Val Loss: 6.2008, SORS:\n2.4431', '\\n', 'Epoch 36/50, Train Loss: 6.4923, Val Loss: 6.1994, SORS:\n2.4427', '\\n', 'Epoch 37/50, Train Loss: 6.4847, Val Loss: 6.1979, SORS:\n2.4422', '\\n', 'Epoch 38/50, Train Loss: 6.4771, Val Loss: 6.1965, SORS:\n2.4418', '\\n', 'Epoch 39/50, Train Loss: 6.4693, Val Loss: 6.1951, SORS:\n2.4413', '\\n', 'Epoch 40/50, Train Loss: 6.4619, Val Loss: 6.1937, SORS:\n2.4409', '\\n', 'Epoch 41/50, Train Loss: 6.4549, Val Loss: 6.1923, SORS:\n2.4405', '\\n', 'Epoch 42/50, Train Loss: 6.4479, Val Loss: 6.1910, SORS:\n2.4400', '\\n', 'Epoch 43/50, Train Loss: 6.4408, Val Loss: 6.1897, SORS:\n2.4396', '\\n', 'Epoch 44/50, Train Loss: 6.4337, Val Loss: 6.1885, SORS:\n2.4392', '\\n', 'Epoch 45/50, Train Loss: 6.4267, Val Loss: 6.1872, SORS:\n2.4388', '\\n', 'Epoch 46/50, Train Loss: 6.4199, Val Loss: 6.1860, SORS:\n2.4383', '\\n', 'Epoch 47/50, Train Loss: 6.4132, Val Loss: 6.1848, SORS:\n2.4379', '\\n', 'Epoch 48/50, Train Loss: 6.4065, Val Loss: 6.1837, SORS:\n2.4375', '\\n', 'Epoch 49/50, Train Loss: 6.3998, Val Loss: 6.1826, SORS:\n2.4371', '\\n', 'Epoch 50/50, Train Loss: 6.3934, Val Loss: 6.1815, SORS:\n2.4367', '\\n', 'Training with batch size: 128', '\\n', 'Epoch 1/50, Train Loss:\n11.0955, Val Loss: 11.3447, SORS: 2.4872', '\\n', 'Epoch 2/50, Train Loss:\n10.5948, Val Loss: 10.8394, SORS: 2.4863', '\\n', 'Epoch 3/50, Train Loss:\n10.1126, Val Loss: 10.3477, SORS: 2.4849', '\\n', 'Epoch 4/50, Train Loss:\n9.6378, Val Loss: 9.8638, SORS: 2.4834', '\\n', 'Epoch 5/50, Train Loss: 9.1758,\nVal Loss: 9.3842, SORS: 2.4816', '\\n', 'Epoch 6/50, Train Loss: 8.7260, Val\nLoss: 8.9090, SORS: 2.4799', '\\n', 'Epoch 7/50, Train Loss: 8.2874, Val Loss:\n8.4412, SORS: 2.4781', '\\n', 'Epoch 8/50, Train Loss: 7.8796, Val Loss: 7.9923,\nSORS: 2.4764', '\\n', 'Epoch 9/50, Train Loss: 7.5071, Val Loss: 7.5725, SORS:\n2.4741', '\\n', 'Epoch 10/50, Train Loss: 7.1819, Val Loss: 7.1921, SORS:\n2.4711', '\\n', 'Epoch 11/50, Train Loss: 6.9258, Val Loss: 6.8696, SORS:\n2.4677', '\\n', 'Epoch 12/50, Train Loss: 6.7444, Val Loss: 6.6172, SORS:\n2.4646', '\\n', 'Epoch 13/50, Train Loss: 6.6385, Val Loss: 6.4419, SORS:\n2.4622', '\\n', 'Epoch 14/50, Train Loss: 6.5926, Val Loss: 6.3338, SORS:\n2.4601', '\\n', 'Epoch 15/50, Train Loss: 6.5904, Val Loss: 6.2782, SORS:\n2.4583', '\\n', 'Epoch 16/50, Train Loss: 6.6111, Val Loss: 6.2565, SORS:\n2.4568', '\\n', 'Epoch 17/50, Train Loss: 6.6346, Val Loss: 6.2521, SORS:\n2.4558', '\\n', 'Epoch 18/50, Train Loss: 6.6497, Val Loss: 6.2531, SORS:\n2.4551', '\\n', 'Epoch 19/50, Train Loss: 6.6528, Val Loss: 6.2537, SORS:\n2.4546', '\\n', 'Epoch 20/50, Train Loss: 6.6462, Val Loss: 6.2527, SORS:\n2.4542', '\\n', 'Epoch 21/50, Train Loss: 6.6349, Val Loss: 6.2505, SORS:\n2.4539', '\\n', 'Epoch 22/50, Train Loss: 6.6216, Val Loss: 6.2479, SORS:\n2.4536', '\\n', 'Epoch 23/50, Train Loss: 6.6088, Val Loss: 6.2454, SORS:\n2.4532', '\\n', 'Epoch 24/50, Train Loss: 6.5970, Val Loss: 6.2430, SORS:\n2.4528', '\\n', 'Epoch 25/50, Train Loss: 6.5863, Val Loss: 6.2409, SORS:\n2.4524', '\\n', 'Epoch 26/50, Train Loss: 6.5766, Val Loss: 6.2389, SORS:\n2.4520', '\\n', 'Epoch 27/50, Train Loss: 6.5677, Val Loss: 6.2371, SORS:\n2.4516', '\\n', 'Epoch 28/50, Train Loss: 6.5591, Val Loss: 6.2353, SORS:\n2.4511', '\\n', 'Epoch 29/50, Train Loss: 6.5509, Val Loss: 6.2336, SORS:\n2.4507', '\\n', 'Epoch 30/50, Train Loss: 6.5423, Val Loss: 6.2319, SORS:\n2.4502', '\\n', 'Epoch 31/50, Train Loss: 6.5333, Val Loss: 6.2300, SORS:\n2.4497', '\\n', 'Epoch 32/50, Train Loss: 6.5232, Val Loss: 6.2280, SORS:\n2.4492', '\\n', 'Epoch 33/50, Train Loss: 6.5120, Val Loss: 6.2258, SORS:\n2.4487', '\\n', 'Epoch 34/50, Train Loss: 6.5003, Val Loss: 6.2236, SORS:\n2.4481', '\\n', 'Epoch 35/50, Train Loss: 6.4888, Val Loss: 6.2215, SORS:\n2.4476', '\\n', 'Epoch 36/50, Train Loss: 6.4773, Val Loss: 6.2196, SORS:\n2.4471', '\\n', 'Epoch 37/50, Train Loss: 6.4661, Val Loss: 6.2177, SORS:\n2.4466', '\\n', 'Epoch 38/50, Train Loss: 6.4553, Val Loss: 6.2159, SORS:\n2.4461', '\\n', 'Epoch 39/50, Train Loss: 6.4447, Val Loss: 6.2141, SORS:\n2.4455', '\\n', 'Epoch 40/50, Train Loss: 6.4343, Val Loss: 6.2123, SORS:\n2.4450', '\\n', 'Epoch 41/50, Train Loss: 6.4239, Val Loss: 6.2105, SORS:\n2.4445', '\\n', 'Epoch 42/50, Train Loss: 6.4137, Val Loss: 6.2088, SORS:\n2.4439', '\\n', 'Epoch 43/50, Train Loss: 6.4035, Val Loss: 6.2071, SORS:\n2.4434', '\\n', 'Epoch 44/50, Train Loss: 6.3934, Val Loss: 6.2054, SORS:\n2.4429', '\\n', 'Epoch 45/50, Train Loss: 6.3833, Val Loss: 6.2037, SORS:\n2.4423', '\\n', 'Epoch 46/50, Train Loss: 6.3734, Val Loss: 6.2021, SORS:\n2.4418', '\\n', 'Epoch 47/50, Train Loss: 6.3632, Val Loss: 6.2005, SORS:\n2.4413', '\\n', 'Epoch 48/50, Train Loss: 6.3531, Val Loss: 6.1989, SORS:\n2.4407', '\\n', 'Epoch 49/50, Train Loss: 6.3430, Val Loss: 6.1974, SORS:\n2.4402', '\\n', 'Epoch 50/50, Train Loss: 6.3330, Val Loss: 6.1958, SORS:\n2.4397', '\\n', 'Training with batch size: 256', '\\n', 'Epoch 1/50, Train Loss:\n12.2534, Val Loss: 12.3903, SORS: 2.4964', '\\n', 'Epoch 2/50, Train Loss:\n12.0336, Val Loss: 12.1734, SORS: 2.4882', '\\n', 'Epoch 3/50, Train Loss:\n11.8116, Val Loss: 11.9537, SORS: 2.4854', '\\n', 'Epoch 4/50, Train Loss:\n11.5856, Val Loss: 11.7286, SORS: 2.4842', '\\n', 'Epoch 5/50, Train Loss:\n11.3532, Val Loss: 11.4972, SORS: 2.4836', '\\n', 'Epoch 6/50, Train Loss:\n11.1188, Val Loss: 11.2588, SORS: 2.4834', '\\n', 'Epoch 7/50, Train Loss:\n10.8754, Val Loss: 11.0118, SORS: 2.4832', '\\n', 'Epoch 8/50, Train Loss:\n10.6256, Val Loss: 10.7554, SORS: 2.4830', '\\n', 'Epoch 9/50, Train Loss:\n10.3692, Val Loss: 10.4896, SORS: 2.4829', '\\n', 'Epoch 10/50, Train Loss:\n10.1024, Val Loss: 10.2119, SORS: 2.4826', '\\n', 'Epoch 11/50, Train Loss:\n9.8220, Val Loss: 9.9228, SORS: 2.4822', '\\n', 'Epoch 12/50, Train Loss: 9.5310,\nVal Loss: 9.6240, SORS: 2.4815', '\\n', 'Epoch 13/50, Train Loss: 9.2361, Val\nLoss: 9.3182, SORS: 2.4807', '\\n', 'Epoch 14/50, Train Loss: 8.9412, Val Loss:\n9.0085, SORS: 2.4799', '\\n', 'Epoch 15/50, Train Loss: 8.6514, Val Loss: 8.6988,\nSORS: 2.4790', '\\n', 'Epoch 16/50, Train Loss: 8.3676, Val Loss: 8.3929, SORS:\n2.4780', '\\n', 'Epoch 17/50, Train Loss: 8.0894, Val Loss: 8.0936, SORS:\n2.4765', '\\n', 'Epoch 18/50, Train Loss: 7.8246, Val Loss: 7.8076, SORS:\n2.4751', '\\n', 'Epoch 19/50, Train Loss: 7.5769, Val Loss: 7.5405, SORS:\n2.4738', '\\n', 'Epoch 20/50, Train Loss: 7.3516, Val Loss: 7.2937, SORS:\n2.4723', '\\n', 'Epoch 21/50, Train Loss: 7.1531, Val Loss: 7.0717, SORS:\n2.4707', '\\n', 'Epoch 22/50, Train Loss: 6.9863, Val Loss: 6.8785, SORS:\n2.4692', '\\n', 'Epoch 23/50, Train Loss: 6.8512, Val Loss: 6.7160, SORS:\n2.4678', '\\n', 'Epoch 24/50, Train Loss: 6.7502, Val Loss: 6.5834, SORS:\n2.4664', '\\n', 'Epoch 25/50, Train Loss: 6.6788, Val Loss: 6.4797, SORS:\n2.4649', '\\n', 'Epoch 26/50, Train Loss: 6.6341, Val Loss: 6.4028, SORS:\n2.4634', '\\n', 'Epoch 27/50, Train Loss: 6.6105, Val Loss: 6.3488, SORS:\n2.4621', '\\n', 'Epoch 28/50, Train Loss: 6.6031, Val Loss: 6.3132, SORS:\n2.4609', '\\n', 'Epoch 29/50, Train Loss: 6.6067, Val Loss: 6.2911, SORS:\n2.4598', '\\n', 'Epoch 30/50, Train Loss: 6.6149, Val Loss: 6.2785, SORS:\n2.4588', '\\n', 'Epoch 31/50, Train Loss: 6.6241, Val Loss: 6.2720, SORS:\n2.4580', '\\n', 'Epoch 32/50, Train Loss: 6.6314, Val Loss: 6.2687, SORS:\n2.4574', '\\n', 'Epoch 33/50, Train Loss: 6.6352, Val Loss: 6.2670, SORS:\n2.4568', '\\n', 'Epoch 34/50, Train Loss: 6.6351, Val Loss: 6.2657, SORS:\n2.4564', '\\n', 'Epoch 35/50, Train Loss: 6.6316, Val Loss: 6.2645, SORS:\n2.4560', '\\n', 'Epoch 36/50, Train Loss: 6.6252, Val Loss: 6.2632, SORS:\n2.4557', '\\n', 'Epoch 37/50, Train Loss: 6.6169, Val Loss: 6.2617, SORS:\n2.4554', '\\n', 'Epoch 38/50, Train Loss: 6.6075, Val Loss: 6.2603, SORS:\n2.4551', '\\n', 'Epoch 39/50, Train Loss: 6.5975, Val Loss: 6.2589, SORS:\n2.4548', '\\n', 'Epoch 40/50, Train Loss: 6.5875, Val Loss: 6.2575, SORS:\n2.4546', '\\n', 'Epoch 41/50, Train Loss: 6.5776, Val Loss: 6.2562, SORS:\n2.4543', '\\n', 'Epoch 42/50, Train Loss: 6.5679, Val Loss: 6.2550, SORS:\n2.4540', '\\n', 'Epoch 43/50, Train Loss: 6.5586, Val Loss: 6.2537, SORS:\n2.4537', '\\n', 'Epoch 44/50, Train Loss: 6.5495, Val Loss: 6.2524, SORS:\n2.4534', '\\n', 'Epoch 45/50, Train Loss: 6.5405, Val Loss: 6.2511, SORS:\n2.4530', '\\n', 'Epoch 46/50, Train Loss: 6.5319, Val Loss: 6.2496, SORS:\n2.4526', '\\n', 'Epoch 47/50, Train Loss: 6.5230, Val Loss: 6.2481, SORS:\n2.4522', '\\n', 'Epoch 48/50, Train Loss: 6.5140, Val Loss: 6.2465, SORS:\n2.4518', '\\n', 'Epoch 49/50, Train Loss: 6.5051, Val Loss: 6.2448, SORS:\n2.4513', '\\n', 'Epoch 50/50, Train Loss: 6.4958, Val Loss: 6.2430, SORS:\n2.4509', '\\n', 'Execution time: 7 seconds seconds (time limit is 10 minutes).']", "['Using device: cuda', '\\n', 'Evaluating dataset_1', '\\n', 'Training with batch\nsize: 16', '\\n', 'Epoch 1/50, Train Loss: 9.9592, Val Loss: 8.7622, SORS:\n2.4666', '\\n', 'Epoch 2/50, Train Loss: 7.0277, Val Loss: 6.3445, SORS: 2.4516',\n'\\n', 'Epoch 3/50, Train Loss: 6.7200, Val Loss: 6.1832, SORS: 2.4465', '\\n',\n'Epoch 4/50, Train Loss: 6.6892, Val Loss: 6.1759, SORS: 2.4451', '\\n', 'Epoch\n5/50, Train Loss: 6.6577, Val Loss: 6.1693, SORS: 2.4437', '\\n', 'Epoch 6/50,\nTrain Loss: 6.6252, Val Loss: 6.1637, SORS: 2.4425', '\\n', 'Epoch 7/50, Train\nLoss: 6.5943, Val Loss: 6.1582, SORS: 2.4412', '\\n', 'Epoch 8/50, Train Loss:\n6.5650, Val Loss: 6.1531, SORS: 2.4400', '\\n', 'Epoch 9/50, Train Loss: 6.5368,\nVal Loss: 6.1482, SORS: 2.4387', '\\n', 'Epoch 10/50, Train Loss: 6.5090, Val\nLoss: 6.1436, SORS: 2.4375', '\\n', 'Epoch 11/50, Train Loss: 6.4829, Val Loss:\n6.1395, SORS: 2.4363', '\\n', 'Epoch 12/50, Train Loss: 6.4575, Val Loss: 6.1358,\nSORS: 2.4352', '\\n', 'Epoch 13/50, Train Loss: 6.4326, Val Loss: 6.1324, SORS:\n2.4341', '\\n', 'Epoch 14/50, Train Loss: 6.4087, Val Loss: 6.1294, SORS:\n2.4330', '\\n', 'Epoch 15/50, Train Loss: 6.3862, Val Loss: 6.1265, SORS:\n2.4320', '\\n', 'Epoch 16/50, Train Loss: 6.3635, Val Loss: 6.1242, SORS:\n2.4311', '\\n', 'Epoch 17/50, Train Loss: 6.3417, Val Loss: 6.1218, SORS:\n2.4301', '\\n', 'Epoch 18/50, Train Loss: 6.3206, Val Loss: 6.1203, SORS:\n2.4294', '\\n', 'Epoch 19/50, Train Loss: 6.2981, Val Loss: 6.1189, SORS:\n2.4286', '\\n', 'Epoch 20/50, Train Loss: 6.2786, Val Loss: 6.1181, SORS:\n2.4279', '\\n', 'Epoch 21/50, Train Loss: 6.2578, Val Loss: 6.1169, SORS:\n2.4272', '\\n', 'Epoch 22/50, Train Loss: 6.2397, Val Loss: 6.1161, SORS:\n2.4266', '\\n', 'Epoch 23/50, Train Loss: 6.2199, Val Loss: 6.1152, SORS:\n2.4260', '\\n', 'Epoch 24/50, Train Loss: 6.2034, Val Loss: 6.1150, SORS:\n2.4255', '\\n', 'Epoch 25/50, Train Loss: 6.1860, Val Loss: 6.1154, SORS:\n2.4250', '\\n', 'Epoch 26/50, Train Loss: 6.1692, Val Loss: 6.1150, SORS:\n2.4246', '\\n', 'Epoch 27/50, Train Loss: 6.1513, Val Loss: 6.1153, SORS:\n2.4241', '\\n', 'Epoch 28/50, Train Loss: 6.1386, Val Loss: 6.1153, SORS:\n2.4237', '\\n', 'Epoch 29/50, Train Loss: 6.1208, Val Loss: 6.1147, SORS:\n2.4232', '\\n', 'Epoch 30/50, Train Loss: 6.1061, Val Loss: 6.1145, SORS:\n2.4228', '\\n', 'Epoch 31/50, Train Loss: 6.0913, Val Loss: 6.1151, SORS:\n2.4225', '\\n', 'Epoch 32/50, Train Loss: 6.0763, Val Loss: 6.1153, SORS:\n2.4222', '\\n', 'Epoch 33/50, Train Loss: 6.0599, Val Loss: 6.1152, SORS:\n2.4218', '\\n', 'Epoch 34/50, Train Loss: 6.0464, Val Loss: 6.1162, SORS:\n2.4216', '\\n', 'Epoch 35/50, Train Loss: 6.0345, Val Loss: 6.1149, SORS:\n2.4209', '\\n', 'Epoch 36/50, Train Loss: 6.0220, Val Loss: 6.1158, SORS:\n2.4207', '\\n', 'Epoch 37/50, Train Loss: 6.0093, Val Loss: 6.1169, SORS:\n2.4205', '\\n', 'Epoch 38/50, Train Loss: 5.9939, Val Loss: 6.1171, SORS:\n2.4202', '\\n', 'Epoch 39/50, Train Loss: 5.9770, Val Loss: 6.1192, SORS:\n2.4201', '\\n', 'Epoch 40/50, Train Loss: 5.9619, Val Loss: 6.1201, SORS:\n2.4200', '\\n', 'Epoch 41/50, Train Loss: 5.9463, Val Loss: 6.1204, SORS:\n2.4197', '\\n', 'Epoch 42/50, Train Loss: 5.9417, Val Loss: 6.1209, SORS:\n2.4195', '\\n', 'Epoch 43/50, Train Loss: 5.9276, Val Loss: 6.1212, SORS:\n2.4193', '\\n', 'Epoch 44/50, Train Loss: 5.9132, Val Loss: 6.1217, SORS:\n2.4190', '\\n', 'Epoch 45/50, Train Loss: 5.8990, Val Loss: 6.1211, SORS:\n2.4186', '\\n', 'Epoch 46/50, Train Loss: 5.8868, Val Loss: 6.1207, SORS:\n2.4184', '\\n', 'Epoch 47/50, Train Loss: 5.8734, Val Loss: 6.1208, SORS:\n2.4180', '\\n', 'Epoch 48/50, Train Loss: 5.8633, Val Loss: 6.1209, SORS:\n2.4178', '\\n', 'Epoch 49/50, Train Loss: 5.8518, Val Loss: 6.1207, SORS:\n2.4174', '\\n', 'Epoch 50/50, Train Loss: 5.8437, Val Loss: 6.1211, SORS:\n2.4173', '\\n', 'Training with batch size: 32', '\\n', 'Epoch 1/50, Train Loss:\n10.1707, Val Loss: 10.1217, SORS: 2.4759', '\\n', 'Epoch 2/50, Train Loss:\n8.5165, Val Loss: 8.3449, SORS: 2.4685', '\\n', 'Epoch 3/50, Train Loss: 7.2613,\nVal Loss: 6.9286, SORS: 2.4595', '\\n', 'Epoch 4/50, Train Loss: 6.7853, Val\nLoss: 6.2893, SORS: 2.4513', '\\n', 'Epoch 5/50, Train Loss: 6.7926, Val Loss:\n6.1950, SORS: 2.4460', '\\n', 'Epoch 6/50, Train Loss: 6.8027, Val Loss: 6.1917,\nSORS: 2.4442', '\\n', 'Epoch 7/50, Train Loss: 6.7769, Val Loss: 6.1858, SORS:\n2.4435', '\\n', 'Epoch 8/50, Train Loss: 6.7549, Val Loss: 6.1809, SORS: 2.4428',\n'\\n', 'Epoch 9/50, Train Loss: 6.7367, Val Loss: 6.1768, SORS: 2.4420', '\\n',\n'Epoch 10/50, Train Loss: 6.7198, Val Loss: 6.1731, SORS: 2.4412', '\\n', 'Epoch\n11/50, Train Loss: 6.7031, Val Loss: 6.1696, SORS: 2.4404', '\\n', 'Epoch 12/50,\nTrain Loss: 6.6869, Val Loss: 6.1662, SORS: 2.4397', '\\n', 'Epoch 13/50, Train\nLoss: 6.6709, Val Loss: 6.1631, SORS: 2.4390', '\\n', 'Epoch 14/50, Train Loss:\n6.6551, Val Loss: 6.1603, SORS: 2.4383', '\\n', 'Epoch 15/50, Train Loss: 6.6401,\nVal Loss: 6.1577, SORS: 2.4376', '\\n', 'Epoch 16/50, Train Loss: 6.6255, Val\nLoss: 6.1553, SORS: 2.4370', '\\n', 'Epoch 17/50, Train Loss: 6.6112, Val Loss:\n6.1531, SORS: 2.4364', '\\n', 'Epoch 18/50, Train Loss: 6.5976, Val Loss: 6.1512,\nSORS: 2.4358', '\\n', 'Epoch 19/50, Train Loss: 6.5842, Val Loss: 6.1494, SORS:\n2.4352', '\\n', 'Epoch 20/50, Train Loss: 6.5714, Val Loss: 6.1477, SORS:\n2.4346', '\\n', 'Epoch 21/50, Train Loss: 6.5588, Val Loss: 6.1461, SORS:\n2.4341', '\\n', 'Epoch 22/50, Train Loss: 6.5469, Val Loss: 6.1447, SORS:\n2.4336', '\\n', 'Epoch 23/50, Train Loss: 6.5350, Val Loss: 6.1434, SORS:\n2.4331', '\\n', 'Epoch 24/50, Train Loss: 6.5238, Val Loss: 6.1423, SORS:\n2.4326', '\\n', 'Epoch 25/50, Train Loss: 6.5124, Val Loss: 6.1412, SORS:\n2.4321', '\\n', 'Epoch 26/50, Train Loss: 6.5018, Val Loss: 6.1403, SORS:\n2.4316', '\\n', 'Epoch 27/50, Train Loss: 6.4911, Val Loss: 6.1393, SORS:\n2.4312', '\\n', 'Epoch 28/50, Train Loss: 6.4807, Val Loss: 6.1386, SORS:\n2.4308', '\\n', 'Epoch 29/50, Train Loss: 6.4710, Val Loss: 6.1379, SORS:\n2.4304', '\\n', 'Epoch 30/50, Train Loss: 6.4616, Val Loss: 6.1373, SORS:\n2.4300', '\\n', 'Epoch 31/50, Train Loss: 6.4523, Val Loss: 6.1368, SORS:\n2.4296', '\\n', 'Epoch 32/50, Train Loss: 6.4435, Val Loss: 6.1364, SORS:\n2.4292', '\\n', 'Epoch 33/50, Train Loss: 6.4349, Val Loss: 6.1363, SORS:\n2.4289', '\\n', 'Epoch 34/50, Train Loss: 6.4266, Val Loss: 6.1361, SORS:\n2.4286', '\\n', 'Epoch 35/50, Train Loss: 6.4178, Val Loss: 6.1364, SORS:\n2.4283', '\\n', 'Epoch 36/50, Train Loss: 6.4092, Val Loss: 6.1363, SORS:\n2.4280', '\\n', 'Epoch 37/50, Train Loss: 6.4007, Val Loss: 6.1364, SORS:\n2.4278', '\\n', 'Epoch 38/50, Train Loss: 6.3924, Val Loss: 6.1367, SORS:\n2.4275', '\\n', 'Epoch 39/50, Train Loss: 6.3841, Val Loss: 6.1372, SORS:\n2.4273', '\\n', 'Epoch 40/50, Train Loss: 6.3767, Val Loss: 6.1375, SORS:\n2.4271', '\\n', 'Epoch 41/50, Train Loss: 6.3695, Val Loss: 6.1377, SORS:\n2.4269', '\\n', 'Epoch 42/50, Train Loss: 6.3627, Val Loss: 6.1378, SORS:\n2.4267', '\\n', 'Epoch 43/50, Train Loss: 6.3569, Val Loss: 6.1379, SORS:\n2.4265', '\\n', 'Epoch 44/50, Train Loss: 6.3508, Val Loss: 6.1380, SORS:\n2.4263', '\\n', 'Epoch 45/50, Train Loss: 6.3455, Val Loss: 6.1379, SORS:\n2.4261', '\\n', 'Epoch 46/50, Train Loss: 6.3401, Val Loss: 6.1381, SORS:\n2.4259', '\\n', 'Epoch 47/50, Train Loss: 6.3351, Val Loss: 6.1380, SORS:\n2.4257', '\\n', 'Epoch 48/50, Train Loss: 6.3302, Val Loss: 6.1385, SORS:\n2.4256', '\\n', 'Epoch 49/50, Train Loss: 6.3252, Val Loss: 6.1385, SORS:\n2.4255', '\\n', 'Epoch 50/50, Train Loss: 6.3211, Val Loss: 6.1391, SORS:\n2.4254', '\\n', 'Training with batch size: 64', '\\n', 'Epoch 1/50, Train Loss:\n11.9955, Val Loss: 12.2566, SORS: 2.4905', '\\n', 'Epoch 2/50, Train Loss:\n11.2798, Val Loss: 11.4991, SORS: 2.4775', '\\n', 'Epoch 3/50, Train Loss:\n10.5719, Val Loss: 10.7524, SORS: 2.4750', '\\n', 'Epoch 4/50, Train Loss:\n9.8045, Val Loss: 9.9522, SORS: 2.4739', '\\n', 'Epoch 5/50, Train Loss: 8.9488,\nVal Loss: 9.0651, SORS: 2.4716', '\\n', 'Epoch 6/50, Train Loss: 8.0737, Val\nLoss: 8.1449, SORS: 2.4685', '\\n', 'Epoch 7/50, Train Loss: 7.3464, Val Loss:\n7.3325, SORS: 2.4650', '\\n', 'Epoch 8/50, Train Loss: 6.8703, Val Loss: 6.7480,\nSORS: 2.4614', '\\n', 'Epoch 9/50, Train Loss: 6.6518, Val Loss: 6.4180, SORS:\n2.4584', '\\n', 'Epoch 10/50, Train Loss: 6.6103, Val Loss: 6.2806, SORS:\n2.4559', '\\n', 'Epoch 11/50, Train Loss: 6.6407, Val Loss: 6.2440, SORS:\n2.4541', '\\n', 'Epoch 12/50, Train Loss: 6.6698, Val Loss: 6.2395, SORS:\n2.4530', '\\n', 'Epoch 13/50, Train Loss: 6.6774, Val Loss: 6.2389, SORS:\n2.4524', '\\n', 'Epoch 14/50, Train Loss: 6.6710, Val Loss: 6.2371, SORS:\n2.4520', '\\n', 'Epoch 15/50, Train Loss: 6.6602, Val Loss: 6.2350, SORS:\n2.4517', '\\n', 'Epoch 16/50, Train Loss: 6.6496, Val Loss: 6.2329, SORS:\n2.4513', '\\n', 'Epoch 17/50, Train Loss: 6.6405, Val Loss: 6.2309, SORS:\n2.4509', '\\n', 'Epoch 18/50, Train Loss: 6.6323, Val Loss: 6.2291, SORS:\n2.4505', '\\n', 'Epoch 19/50, Train Loss: 6.6245, Val Loss: 6.2273, SORS:\n2.4501', '\\n', 'Epoch 20/50, Train Loss: 6.6169, Val Loss: 6.2255, SORS:\n2.4497', '\\n', 'Epoch 21/50, Train Loss: 6.6092, Val Loss: 6.2238, SORS:\n2.4492', '\\n', 'Epoch 22/50, Train Loss: 6.6014, Val Loss: 6.2220, SORS:\n2.4488', '\\n', 'Epoch 23/50, Train Loss: 6.5935, Val Loss: 6.2203, SORS:\n2.4484', '\\n', 'Epoch 24/50, Train Loss: 6.5855, Val Loss: 6.2186, SORS:\n2.4480', '\\n', 'Epoch 25/50, Train Loss: 6.5776, Val Loss: 6.2169, SORS:\n2.4475', '\\n', 'Epoch 26/50, Train Loss: 6.5696, Val Loss: 6.2152, SORS:\n2.4471', '\\n', 'Epoch 27/50, Train Loss: 6.5616, Val Loss: 6.2136, SORS:\n2.4467', '\\n', 'Epoch 28/50, Train Loss: 6.5537, Val Loss: 6.2120, SORS:\n2.4462', '\\n', 'Epoch 29/50, Train Loss: 6.5457, Val Loss: 6.2103, SORS:\n2.4458', '\\n', 'Epoch 30/50, Train Loss: 6.5380, Val Loss: 6.2087, SORS:\n2.4453', '\\n', 'Epoch 31/50, Train Loss: 6.5303, Val Loss: 6.2071, SORS:\n2.4449', '\\n', 'Epoch 32/50, Train Loss: 6.5226, Val Loss: 6.2055, SORS:\n2.4444', '\\n', 'Epoch 33/50, Train Loss: 6.5150, Val Loss: 6.2039, SORS:\n2.4440', '\\n', 'Epoch 34/50, Train Loss: 6.5075, Val Loss: 6.2024, SORS:\n2.4435', '\\n', 'Epoch 35/50, Train Loss: 6.5000, Val Loss: 6.2008, SORS:\n2.4431', '\\n', 'Epoch 36/50, Train Loss: 6.4923, Val Loss: 6.1994, SORS:\n2.4427', '\\n', 'Epoch 37/50, Train Loss: 6.4847, Val Loss: 6.1979, SORS:\n2.4422', '\\n', 'Epoch 38/50, Train Loss: 6.4771, Val Loss: 6.1965, SORS:\n2.4418', '\\n', 'Epoch 39/50, Train Loss: 6.4693, Val Loss: 6.1951, SORS:\n2.4413', '\\n', 'Epoch 40/50, Train Loss: 6.4619, Val Loss: 6.1937, SORS:\n2.4409', '\\n', 'Epoch 41/50, Train Loss: 6.4549, Val Loss: 6.1923, SORS:\n2.4405', '\\n', 'Epoch 42/50, Train Loss: 6.4479, Val Loss: 6.1910, SORS:\n2.4400', '\\n', 'Epoch 43/50, Train Loss: 6.4408, Val Loss: 6.1897, SORS:\n2.4396', '\\n', 'Epoch 44/50, Train Loss: 6.4337, Val Loss: 6.1885, SORS:\n2.4392', '\\n', 'Epoch 45/50, Train Loss: 6.4267, Val Loss: 6.1872, SORS:\n2.4388', '\\n', 'Epoch 46/50, Train Loss: 6.4199, Val Loss: 6.1860, SORS:\n2.4383', '\\n', 'Epoch 47/50, Train Loss: 6.4132, Val Loss: 6.1848, SORS:\n2.4379', '\\n', 'Epoch 48/50, Train Loss: 6.4065, Val Loss: 6.1837, SORS:\n2.4375', '\\n', 'Epoch 49/50, Train Loss: 6.3998, Val Loss: 6.1826, SORS:\n2.4371', '\\n', 'Epoch 50/50, Train Loss: 6.3934, Val Loss: 6.1815, SORS:\n2.4367', '\\n', 'Training with batch size: 128', '\\n', 'Epoch 1/50, Train Loss:\n11.0955, Val Loss: 11.3447, SORS: 2.4872', '\\n', 'Epoch 2/50, Train Loss:\n10.5948, Val Loss: 10.8394, SORS: 2.4863', '\\n', 'Epoch 3/50, Train Loss:\n10.1126, Val Loss: 10.3477, SORS: 2.4849', '\\n', 'Epoch 4/50, Train Loss:\n9.6378, Val Loss: 9.8638, SORS: 2.4834', '\\n', 'Epoch 5/50, Train Loss: 9.1758,\nVal Loss: 9.3842, SORS: 2.4816', '\\n', 'Epoch 6/50, Train Loss: 8.7260, Val\nLoss: 8.9090, SORS: 2.4799', '\\n', 'Epoch 7/50, Train Loss: 8.2874, Val Loss:\n8.4412, SORS: 2.4781', '\\n', 'Epoch 8/50, Train Loss: 7.8796, Val Loss: 7.9923,\nSORS: 2.4764', '\\n', 'Epoch 9/50, Train Loss: 7.5071, Val Loss: 7.5725, SORS:\n2.4741', '\\n', 'Epoch 10/50, Train Loss: 7.1819, Val Loss: 7.1921, SORS:\n2.4711', '\\n', 'Epoch 11/50, Train Loss: 6.9258, Val Loss: 6.8696, SORS:\n2.4677', '\\n', 'Epoch 12/50, Train Loss: 6.7444, Val Loss: 6.6172, SORS:\n2.4646', '\\n', 'Epoch 13/50, Train Loss: 6.6385, Val Loss: 6.4419, SORS:\n2.4622', '\\n', 'Epoch 14/50, Train Loss: 6.5926, Val Loss: 6.3338, SORS:\n2.4601', '\\n', 'Epoch 15/50, Train Loss: 6.5904, Val Loss: 6.2782, SORS:\n2.4583', '\\n', 'Epoch 16/50, Train Loss: 6.6111, Val Loss: 6.2565, SORS:\n2.4568', '\\n', 'Epoch 17/50, Train Loss: 6.6346, Val Loss: 6.2521, SORS:\n2.4558', '\\n', 'Epoch 18/50, Train Loss: 6.6497, Val Loss: 6.2531, SORS:\n2.4551', '\\n', 'Epoch 19/50, Train Loss: 6.6528, Val Loss: 6.2537, SORS:\n2.4546', '\\n', 'Epoch 20/50, Train Loss: 6.6462, Val Loss: 6.2527, SORS:\n2.4542', '\\n', 'Epoch 21/50, Train Loss: 6.6349, Val Loss: 6.2505, SORS:\n2.4539', '\\n', 'Epoch 22/50, Train Loss: 6.6216, Val Loss: 6.2479, SORS:\n2.4536', '\\n', 'Epoch 23/50, Train Loss: 6.6088, Val Loss: 6.2454, SORS:\n2.4532', '\\n', 'Epoch 24/50, Train Loss: 6.5970, Val Loss: 6.2430, SORS:\n2.4528', '\\n', 'Epoch 25/50, Train Loss: 6.5863, Val Loss: 6.2409, SORS:\n2.4524', '\\n', 'Epoch 26/50, Train Loss: 6.5766, Val Loss: 6.2389, SORS:\n2.4520', '\\n', 'Epoch 27/50, Train Loss: 6.5677, Val Loss: 6.2371, SORS:\n2.4516', '\\n', 'Epoch 28/50, Train Loss: 6.5591, Val Loss: 6.2353, SORS:\n2.4511', '\\n', 'Epoch 29/50, Train Loss: 6.5509, Val Loss: 6.2336, SORS:\n2.4507', '\\n', 'Epoch 30/50, Train Loss: 6.5423, Val Loss: 6.2319, SORS:\n2.4502', '\\n', 'Epoch 31/50, Train Loss: 6.5333, Val Loss: 6.2300, SORS:\n2.4497', '\\n', 'Epoch 32/50, Train Loss: 6.5232, Val Loss: 6.2280, SORS:\n2.4492', '\\n', 'Epoch 33/50, Train Loss: 6.5120, Val Loss: 6.2258, SORS:\n2.4487', '\\n', 'Epoch 34/50, Train Loss: 6.5003, Val Loss: 6.2236, SORS:\n2.4481', '\\n', 'Epoch 35/50, Train Loss: 6.4888, Val Loss: 6.2215, SORS:\n2.4476', '\\n', 'Epoch 36/50, Train Loss: 6.4773, Val Loss: 6.2196, SORS:\n2.4471', '\\n', 'Epoch 37/50, Train Loss: 6.4661, Val Loss: 6.2177, SORS:\n2.4466', '\\n', 'Epoch 38/50, Train Loss: 6.4553, Val Loss: 6.2159, SORS:\n2.4461', '\\n', 'Epoch 39/50, Train Loss: 6.4447, Val Loss: 6.2141, SORS:\n2.4455', '\\n', 'Epoch 40/50, Train Loss: 6.4343, Val Loss: 6.2123, SORS:\n2.4450', '\\n', 'Epoch 41/50, Train Loss: 6.4239, Val Loss: 6.2105, SORS:\n2.4445', '\\n', 'Epoch 42/50, Train Loss: 6.4137, Val Loss: 6.2088, SORS:\n2.4439', '\\n', 'Epoch 43/50, Train Loss: 6.4035, Val Loss: 6.2071, SORS:\n2.4434', '\\n', 'Epoch 44/50, Train Loss: 6.3934, Val Loss: 6.2054, SORS:\n2.4429', '\\n', 'Epoch 45/50, Train Loss: 6.3833, Val Loss: 6.2037, SORS:\n2.4423', '\\n', 'Epoch 46/50, Train Loss: 6.3734, Val Loss: 6.2021, SORS:\n2.4418', '\\n', 'Epoch 47/50, Train Loss: 6.3632, Val Loss: 6.2005, SORS:\n2.4413', '\\n', 'Epoch 48/50, Train Loss: 6.3531, Val Loss: 6.1989, SORS:\n2.4407', '\\n', 'Epoch 49/50, Train Loss: 6.3430, Val Loss: 6.1974, SORS:\n2.4402', '\\n', 'Epoch 50/50, Train Loss: 6.3330, Val Loss: 6.1958, SORS:\n2.4397', '\\n', 'Training with batch size: 256', '\\n', 'Epoch 1/50, Train Loss:\n12.2534, Val Loss: 12.3903, SORS: 2.4964', '\\n', 'Epoch 2/50, Train Loss:\n12.0336, Val Loss: 12.1734, SORS: 2.4882', '\\n', 'Epoch 3/50, Train Loss:\n11.8116, Val Loss: 11.9537, SORS: 2.4854', '\\n', 'Epoch 4/50, Train Loss:\n11.5856, Val Loss: 11.7286, SORS: 2.4842', '\\n', 'Epoch 5/50, Train Loss:\n11.3532, Val Loss: 11.4972, SORS: 2.4836', '\\n', 'Epoch 6/50, Train Loss:\n11.1188, Val Loss: 11.2588, SORS: 2.4834', '\\n', 'Epoch 7/50, Train Loss:\n10.8754, Val Loss: 11.0118, SORS: 2.4832', '\\n', 'Epoch 8/50, Train Loss:\n10.6256, Val Loss: 10.7554, SORS: 2.4830', '\\n', 'Epoch 9/50, Train Loss:\n10.3692, Val Loss: 10.4896, SORS: 2.4829', '\\n', 'Epoch 10/50, Train Loss:\n10.1024, Val Loss: 10.2119, SORS: 2.4826', '\\n', 'Epoch 11/50, Train Loss:\n9.8220, Val Loss: 9.9228, SORS: 2.4822', '\\n', 'Epoch 12/50, Train Loss: 9.5310,\nVal Loss: 9.6240, SORS: 2.4815', '\\n', 'Epoch 13/50, Train Loss: 9.2361, Val\nLoss: 9.3182, SORS: 2.4807', '\\n', 'Epoch 14/50, Train Loss: 8.9412, Val Loss:\n9.0085, SORS: 2.4799', '\\n', 'Epoch 15/50, Train Loss: 8.6514, Val Loss: 8.6988,\nSORS: 2.4790', '\\n', 'Epoch 16/50, Train Loss: 8.3676, Val Loss: 8.3929, SORS:\n2.4780', '\\n', 'Epoch 17/50, Train Loss: 8.0894, Val Loss: 8.0936, SORS:\n2.4765', '\\n', 'Epoch 18/50, Train Loss: 7.8246, Val Loss: 7.8076, SORS:\n2.4751', '\\n', 'Epoch 19/50, Train Loss: 7.5769, Val Loss: 7.5405, SORS:\n2.4738', '\\n', 'Epoch 20/50, Train Loss: 7.3516, Val Loss: 7.2937, SORS:\n2.4723', '\\n', 'Epoch 21/50, Train Loss: 7.1531, Val Loss: 7.0717, SORS:\n2.4707', '\\n', 'Epoch 22/50, Train Loss: 6.9863, Val Loss: 6.8785, SORS:\n2.4692', '\\n', 'Epoch 23/50, Train Loss: 6.8512, Val Loss: 6.7160, SORS:\n2.4678', '\\n', 'Epoch 24/50, Train Loss: 6.7502, Val Loss: 6.5834, SORS:\n2.4664', '\\n', 'Epoch 25/50, Train Loss: 6.6788, Val Loss: 6.4797, SORS:\n2.4649', '\\n', 'Epoch 26/50, Train Loss: 6.6341, Val Loss: 6.4028, SORS:\n2.4634', '\\n', 'Epoch 27/50, Train Loss: 6.6105, Val Loss: 6.3488, SORS:\n2.4621', '\\n', 'Epoch 28/50, Train Loss: 6.6031, Val Loss: 6.3132, SORS:\n2.4609', '\\n', 'Epoch 29/50, Train Loss: 6.6067, Val Loss: 6.2911, SORS:\n2.4598', '\\n', 'Epoch 30/50, Train Loss: 6.6149, Val Loss: 6.2785, SORS:\n2.4588', '\\n', 'Epoch 31/50, Train Loss: 6.6241, Val Loss: 6.2720, SORS:\n2.4580', '\\n', 'Epoch 32/50, Train Loss: 6.6314, Val Loss: 6.2687, SORS:\n2.4574', '\\n', 'Epoch 33/50, Train Loss: 6.6352, Val Loss: 6.2670, SORS:\n2.4568', '\\n', 'Epoch 34/50, Train Loss: 6.6351, Val Loss: 6.2657, SORS:\n2.4564', '\\n', 'Epoch 35/50, Train Loss: 6.6316, Val Loss: 6.2645, SORS:\n2.4560', '\\n', 'Epoch 36/50, Train Loss: 6.6252, Val Loss: 6.2632, SORS:\n2.4557', '\\n', 'Epoch 37/50, Train Loss: 6.6169, Val Loss: 6.2617, SORS:\n2.4554', '\\n', 'Epoch 38/50, Train Loss: 6.6075, Val Loss: 6.2603, SORS:\n2.4551', '\\n', 'Epoch 39/50, Train Loss: 6.5975, Val Loss: 6.2589, SORS:\n2.4548', '\\n', 'Epoch 40/50, Train Loss: 6.5875, Val Loss: 6.2575, SORS:\n2.4546', '\\n', 'Epoch 41/50, Train Loss: 6.5776, Val Loss: 6.2562, SORS:\n2.4543', '\\n', 'Epoch 42/50, Train Loss: 6.5679, Val Loss: 6.2550, SORS:\n2.4540', '\\n', 'Epoch 43/50, Train Loss: 6.5586, Val Loss: 6.2537, SORS:\n2.4537', '\\n', 'Epoch 44/50, Train Loss: 6.5495, Val Loss: 6.2524, SORS:\n2.4534', '\\n', 'Epoch 45/50, Train Loss: 6.5405, Val Loss: 6.2511, SORS:\n2.4530', '\\n', 'Epoch 46/50, Train Loss: 6.5319, Val Loss: 6.2496, SORS:\n2.4526', '\\n', 'Epoch 47/50, Train Loss: 6.5230, Val Loss: 6.2481, SORS:\n2.4522', '\\n', 'Epoch 48/50, Train Loss: 6.5140, Val Loss: 6.2465, SORS:\n2.4518', '\\n', 'Epoch 49/50, Train Loss: 6.5051, Val Loss: 6.2448, SORS:\n2.4513', '\\n', 'Epoch 50/50, Train Loss: 6.4958, Val Loss: 6.2430, SORS:\n2.4509', '\\n', 'Evaluating dataset_2', '\\n', 'Training with batch size: 16',\n'\\n', 'Epoch 1/50, Train Loss: 14.4167, Val Loss: 11.0752, SORS: 2.5916', '\\n',\n'Epoch 2/50, Train Loss: 9.8239, Val Loss: 7.7015, SORS: 2.5687', '\\n', 'Epoch\n3/50, Train Loss: 8.0464, Val Loss: 6.7403, SORS: 2.5516', '\\n', 'Epoch 4/50,\nTrain Loss: 7.9448, Val Loss: 6.7151, SORS: 2.5503', '\\n', 'Epoch 5/50, Train\nLoss: 7.9609, Val Loss: 6.7185, SORS: 2.5507', '\\n', 'Epoch 6/50, Train Loss:\n7.9681, Val Loss: 6.7208, SORS: 2.5510', '\\n', 'Epoch 7/50, Train Loss: 7.9644,\nVal Loss: 6.7224, SORS: 2.5512', '\\n', 'Epoch 8/50, Train Loss: 7.9636, Val\nLoss: 6.7240, SORS: 2.5514', '\\n', 'Epoch 9/50, Train Loss: 7.9629, Val Loss:\n6.7257, SORS: 2.5516', '\\n', 'Epoch 10/50, Train Loss: 7.9623, Val Loss: 6.7274,\nSORS: 2.5518', '\\n', 'Epoch 11/50, Train Loss: 7.9629, Val Loss: 6.7276, SORS:\n2.5516', '\\n', 'Epoch 12/50, Train Loss: 7.9616, Val Loss: 6.7285, SORS:\n2.5516', '\\n', 'Epoch 13/50, Train Loss: 7.9660, Val Loss: 6.7282, SORS:\n2.5511', '\\n', 'Epoch 14/50, Train Loss: 7.9688, Val Loss: 6.7298, SORS:\n2.5511', '\\n', 'Epoch 15/50, Train Loss: 7.9723, Val Loss: 6.7318, SORS:\n2.5512', '\\n', 'Epoch 16/50, Train Loss: 7.9695, Val Loss: 6.7333, SORS:\n2.5513', '\\n', 'Epoch 17/50, Train Loss: 7.9683, Val Loss: 6.7359, SORS:\n2.5515', '\\n', 'Epoch 18/50, Train Loss: 7.9616, Val Loss: 6.7375, SORS:\n2.5515', '\\n', 'Epoch 19/50, Train Loss: 7.9611, Val Loss: 6.7395, SORS:\n2.5516', '\\n', 'Epoch 20/50, Train Loss: 7.9563, Val Loss: 6.7411, SORS:\n2.5517', '\\n', 'Epoch 21/50, Train Loss: 7.9538, Val Loss: 6.7436, SORS:\n2.5519', '\\n', 'Epoch 22/50, Train Loss: 7.9523, Val Loss: 6.7451, SORS:\n2.5519', '\\n', 'Epoch 23/50, Train Loss: 7.9493, Val Loss: 6.7474, SORS:\n2.5521', '\\n', 'Epoch 24/50, Train Loss: 7.9479, Val Loss: 6.7484, SORS:\n2.5520', '\\n', 'Epoch 25/50, Train Loss: 7.9509, Val Loss: 6.7513, SORS:\n2.5522', '\\n', 'Epoch 26/50, Train Loss: 7.9456, Val Loss: 6.7512, SORS:\n2.5520', '\\n', 'Epoch 27/50, Train Loss: 7.9506, Val Loss: 6.7540, SORS:\n2.5522', '\\n', 'Epoch 28/50, Train Loss: 7.9462, Val Loss: 6.7547, SORS:\n2.5521', '\\n', 'Epoch 29/50, Train Loss: 7.9507, Val Loss: 6.7568, SORS:\n2.5522', '\\n', 'Epoch 30/50, Train Loss: 7.9447, Val Loss: 6.7570, SORS:\n2.5521', '\\n', 'Epoch 31/50, Train Loss: 7.9492, Val Loss: 6.7589, SORS:\n2.5521', '\\n', 'Epoch 32/50, Train Loss: 7.9477, Val Loss: 6.7593, SORS:\n2.5519', '\\n', 'Epoch 33/50, Train Loss: 7.9443, Val Loss: 6.7596, SORS:\n2.5517', '\\n', 'Epoch 34/50, Train Loss: 7.9460, Val Loss: 6.7605, SORS:\n2.5516', '\\n', 'Epoch 35/50, Train Loss: 7.9424, Val Loss: 6.7610, SORS:\n2.5515', '\\n', 'Epoch 36/50, Train Loss: 7.9436, Val Loss: 6.7620, SORS:\n2.5515', '\\n', 'Epoch 37/50, Train Loss: 7.9401, Val Loss: 6.7619, SORS:\n2.5512', '\\n', 'Epoch 38/50, Train Loss: 7.9420, Val Loss: 6.7635, SORS:\n2.5513', '\\n', 'Epoch 39/50, Train Loss: 7.9333, Val Loss: 6.7633, SORS:\n2.5512', '\\n', 'Epoch 40/50, Train Loss: 7.9390, Val Loss: 6.7651, SORS:\n2.5511', '\\n', 'Epoch 41/50, Train Loss: 7.9349, Val Loss: 6.7653, SORS:\n2.5510', '\\n', 'Epoch 42/50, Train Loss: 7.9352, Val Loss: 6.7653, SORS:\n2.5508', '\\n', 'Epoch 43/50, Train Loss: 7.9356, Val Loss: 6.7664, SORS:\n2.5507', '\\n', 'Epoch 44/50, Train Loss: 7.9338, Val Loss: 6.7665, SORS:\n2.5506', '\\n', 'Epoch 45/50, Train Loss: 7.9343, Val Loss: 6.7676, SORS:\n2.5506', '\\n', 'Epoch 46/50, Train Loss: 7.9346, Val Loss: 6.7680, SORS:\n2.5505', '\\n', 'Epoch 47/50, Train Loss: 7.9324, Val Loss: 6.7681, SORS:\n2.5502', '\\n', 'Epoch 48/50, Train Loss: 7.9291, Val Loss: 6.7675, SORS:\n2.5500', '\\n', 'Epoch 49/50, Train Loss: 7.9273, Val Loss: 6.7692, SORS:\n2.5501', '\\n', 'Epoch 50/50, Train Loss: 7.9270, Val Loss: 6.7695, SORS:\n2.5499', '\\n', 'Training with batch size: 32', '\\n', 'Epoch 1/50, Train Loss:\n14.3365, Val Loss: 11.7606, SORS: 2.5926', '\\n', 'Epoch 2/50, Train Loss:\n12.0995, Val Loss: 9.9417, SORS: 2.5798', '\\n', 'Epoch 3/50, Train Loss: 9.6011,\nVal Loss: 8.0917, SORS: 2.5636', '\\n', 'Epoch 4/50, Train Loss: 7.7438, Val\nLoss: 6.9581, SORS: 2.5477', '\\n', 'Epoch 5/50, Train Loss: 6.9846, Val Loss:\n6.6668, SORS: 2.5386', '\\n', 'Epoch 6/50, Train Loss: 6.8387, Val Loss: 6.6432,\nSORS: 2.5366', '\\n', 'Epoch 7/50, Train Loss: 6.8488, Val Loss: 6.6457, SORS:\n2.5372', '\\n', 'Epoch 8/50, Train Loss: 6.8652, Val Loss: 6.6489, SORS: 2.5378',\n'\\n', 'Epoch 9/50, Train Loss: 6.8722, Val Loss: 6.6510, SORS: 2.5382', '\\n',\n'Epoch 10/50, Train Loss: 6.8770, Val Loss: 6.6529, SORS: 2.5386', '\\n', 'Epoch\n11/50, Train Loss: 6.8821, Val Loss: 6.6549, SORS: 2.5391', '\\n', 'Epoch 12/50,\nTrain Loss: 6.8875, Val Loss: 6.6570, SORS: 2.5395', '\\n', 'Epoch 13/50, Train\nLoss: 6.8928, Val Loss: 6.6591, SORS: 2.5399', '\\n', 'Epoch 14/50, Train Loss:\n6.8979, Val Loss: 6.6612, SORS: 2.5403', '\\n', 'Epoch 15/50, Train Loss: 6.9031,\nVal Loss: 6.6634, SORS: 2.5407', '\\n', 'Epoch 16/50, Train Loss: 6.9084, Val\nLoss: 6.6656, SORS: 2.5411', '\\n', 'Epoch 17/50, Train Loss: 6.9137, Val Loss:\n6.6679, SORS: 2.5414', '\\n', 'Epoch 18/50, Train Loss: 6.9189, Val Loss: 6.6702,\nSORS: 2.5418', '\\n', 'Epoch 19/50, Train Loss: 6.9242, Val Loss: 6.6725, SORS:\n2.5422', '\\n', 'Epoch 20/50, Train Loss: 6.9297, Val Loss: 6.6749, SORS:\n2.5426', '\\n', 'Epoch 21/50, Train Loss: 6.9350, Val Loss: 6.6773, SORS:\n2.5429', '\\n', 'Epoch 22/50, Train Loss: 6.9402, Val Loss: 6.6796, SORS:\n2.5432', '\\n', 'Epoch 23/50, Train Loss: 6.9461, Val Loss: 6.6821, SORS:\n2.5436', '\\n', 'Epoch 24/50, Train Loss: 6.9522, Val Loss: 6.6845, SORS:\n2.5439', '\\n', 'Epoch 25/50, Train Loss: 6.9580, Val Loss: 6.6870, SORS:\n2.5443', '\\n', 'Epoch 26/50, Train Loss: 6.9635, Val Loss: 6.6894, SORS:\n2.5446', '\\n', 'Epoch 27/50, Train Loss: 6.9688, Val Loss: 6.6919, SORS:\n2.5449', '\\n', 'Epoch 28/50, Train Loss: 6.9740, Val Loss: 6.6943, SORS:\n2.5453', '\\n', 'Epoch 29/50, Train Loss: 6.9790, Val Loss: 6.6967, SORS:\n2.5456', '\\n', 'Epoch 30/50, Train Loss: 6.9843, Val Loss: 6.6991, SORS:\n2.5459', '\\n', 'Epoch 31/50, Train Loss: 6.9893, Val Loss: 6.7015, SORS:\n2.5461', '\\n', 'Epoch 32/50, Train Loss: 6.9946, Val Loss: 6.7039, SORS:\n2.5464', '\\n', 'Epoch 33/50, Train Loss: 6.9995, Val Loss: 6.7063, SORS:\n2.5467', '\\n', 'Epoch 34/50, Train Loss: 7.0045, Val Loss: 6.7087, SORS:\n2.5470', '\\n', 'Epoch 35/50, Train Loss: 7.0093, Val Loss: 6.7111, SORS:\n2.5473', '\\n', 'Epoch 36/50, Train Loss: 7.0142, Val Loss: 6.7134, SORS:\n2.5475', '\\n', 'Epoch 37/50, Train Loss: 7.0188, Val Loss: 6.7157, SORS:\n2.5478', '\\n', 'Epoch 38/50, Train Loss: 7.0244, Val Loss: 6.7180, SORS:\n2.5480', '\\n', 'Epoch 39/50, Train Loss: 7.0290, Val Loss: 6.7204, SORS:\n2.5483', '\\n', 'Epoch 40/50, Train Loss: 7.0340, Val Loss: 6.7227, SORS:\n2.5485', '\\n', 'Epoch 41/50, Train Loss: 7.0383, Val Loss: 6.7247, SORS:\n2.5487', '\\n', 'Epoch 42/50, Train Loss: 7.0429, Val Loss: 6.7268, SORS:\n2.5490', '\\n', 'Epoch 43/50, Train Loss: 7.0473, Val Loss: 6.7288, SORS:\n2.5492', '\\n', 'Epoch 44/50, Train Loss: 7.0515, Val Loss: 6.7307, SORS:\n2.5493', '\\n', 'Epoch 45/50, Train Loss: 7.0554, Val Loss: 6.7326, SORS:\n2.5495', '\\n', 'Epoch 46/50, Train Loss: 7.0602, Val Loss: 6.7347, SORS:\n2.5497', '\\n', 'Epoch 47/50, Train Loss: 7.0649, Val Loss: 6.7366, SORS:\n2.5499', '\\n', 'Epoch 48/50, Train Loss: 7.0697, Val Loss: 6.7387, SORS:\n2.5501', '\\n', 'Epoch 49/50, Train Loss: 7.0736, Val Loss: 6.7406, SORS:\n2.5503', '\\n', 'Epoch 50/50, Train Loss: 7.0814, Val Loss: 6.7427, SORS:\n2.5504', '\\n', 'Training with batch size: 64', '\\n', 'Epoch 1/50, Train Loss:\n13.8875, Val Loss: 11.3869, SORS: 2.5879', '\\n', 'Epoch 2/50, Train Loss:\n12.6048, Val Loss: 10.3770, SORS: 2.5813', '\\n', 'Epoch 3/50, Train Loss:\n11.3636, Val Loss: 9.4320, SORS: 2.5741', '\\n', 'Epoch 4/50, Train Loss:\n10.1719, Val Loss: 8.5642, SORS: 2.5666', '\\n', 'Epoch 5/50, Train Loss: 9.0908,\nVal Loss: 7.8196, SORS: 2.5591', '\\n', 'Epoch 6/50, Train Loss: 8.1875, Val\nLoss: 7.2556, SORS: 2.5521', '\\n', 'Epoch 7/50, Train Loss: 7.5143, Val Loss:\n6.8978, SORS: 2.5458', '\\n', 'Epoch 8/50, Train Loss: 7.0796, Val Loss: 6.7188,\nSORS: 2.5408', '\\n', 'Epoch 9/50, Train Loss: 6.8407, Val Loss: 6.6531, SORS:\n2.5376', '\\n', 'Epoch 10/50, Train Loss: 6.7310, Val Loss: 6.6364, SORS:\n2.5359', '\\n', 'Epoch 11/50, Train Loss: 6.6936, Val Loss: 6.6340, SORS:\n2.5354', '\\n', 'Epoch 12/50, Train Loss: 6.6897, Val Loss: 6.6346, SORS:\n2.5355', '\\n', 'Epoch 13/50, Train Loss: 6.6974, Val Loss: 6.6359, SORS:\n2.5359', '\\n', 'Epoch 14/50, Train Loss: 6.7060, Val Loss: 6.6373, SORS:\n2.5362', '\\n', 'Epoch 15/50, Train Loss: 6.7122, Val Loss: 6.6386, SORS:\n2.5364', '\\n', 'Epoch 16/50, Train Loss: 6.7162, Val Loss: 6.6397, SORS:\n2.5367', '\\n', 'Epoch 17/50, Train Loss: 6.7191, Val Loss: 6.6407, SORS:\n2.5369', '\\n', 'Epoch 18/50, Train Loss: 6.7217, Val Loss: 6.6417, SORS:\n2.5371', '\\n', 'Epoch 19/50, Train Loss: 6.7243, Val Loss: 6.6428, SORS:\n2.5373', '\\n', 'Epoch 20/50, Train Loss: 6.7271, Val Loss: 6.6438, SORS:\n2.5375', '\\n', 'Epoch 21/50, Train Loss: 6.7299, Val Loss: 6.6449, SORS:\n2.5377', '\\n', 'Epoch 22/50, Train Loss: 6.7330, Val Loss: 6.6461, SORS:\n2.5380', '\\n', 'Epoch 23/50, Train Loss: 6.7360, Val Loss: 6.6472, SORS:\n2.5382', '\\n', 'Epoch 24/50, Train Loss: 6.7393, Val Loss: 6.6481, SORS:\n2.5384', '\\n', 'Epoch 25/50, Train Loss: 6.7436, Val Loss: 6.6489, SORS:\n2.5385', '\\n', 'Epoch 26/50, Train Loss: 6.7490, Val Loss: 6.6498, SORS:\n2.5387', '\\n', 'Epoch 27/50, Train Loss: 6.7548, Val Loss: 6.6501, SORS:\n2.5388', '\\n', 'Epoch 28/50, Train Loss: 6.7668, Val Loss: 6.6510, SORS:\n2.5389', '\\n', 'Epoch 29/50, Train Loss: 6.7809, Val Loss: 6.6527, SORS:\n2.5391', '\\n', 'Epoch 30/50, Train Loss: 6.7921, Val Loss: 6.6559, SORS:\n2.5396', '\\n', 'Epoch 31/50, Train Loss: 6.7937, Val Loss: 6.6571, SORS:\n2.5398', '\\n', 'Epoch 32/50, Train Loss: 6.7924, Val Loss: 6.6576, SORS:\n2.5398', '\\n', 'Epoch 33/50, Train Loss: 6.7960, Val Loss: 6.6589, SORS:\n2.5400', '\\n', 'Epoch 34/50, Train Loss: 6.8015, Val Loss: 6.6603, SORS:\n2.5402', '\\n', 'Epoch 35/50, Train Loss: 6.8050, Val Loss: 6.6615, SORS:\n2.5404', '\\n', 'Epoch 36/50, Train Loss: 6.8096, Val Loss: 6.6630, SORS:\n2.5406', '\\n', 'Epoch 37/50, Train Loss: 6.8128, Val Loss: 6.6641, SORS:\n2.5407', '\\n', 'Epoch 38/50, Train Loss: 6.8156, Val Loss: 6.6652, SORS:\n2.5409', '\\n', 'Epoch 39/50, Train Loss: 6.8194, Val Loss: 6.6665, SORS:\n2.5410', '\\n', 'Epoch 40/50, Train Loss: 6.8231, Val Loss: 6.6678, SORS:\n2.5412', '\\n', 'Epoch 41/50, Train Loss: 6.8263, Val Loss: 6.6689, SORS:\n2.5413', '\\n', 'Epoch 42/50, Train Loss: 6.8296, Val Loss: 6.6701, SORS:\n2.5415', '\\n', 'Epoch 43/50, Train Loss: 6.8335, Val Loss: 6.6716, SORS:\n2.5417', '\\n', 'Epoch 44/50, Train Loss: 6.8360, Val Loss: 6.6726, SORS:\n2.5418', '\\n', 'Epoch 45/50, Train Loss: 6.8389, Val Loss: 6.6737, SORS:\n2.5419', '\\n', 'Epoch 46/50, Train Loss: 6.8422, Val Loss: 6.6748, SORS:\n2.5420', '\\n', 'Epoch 47/50, Train Loss: 6.8444, Val Loss: 6.6758, SORS:\n2.5422', '\\n', 'Epoch 48/50, Train Loss: 6.8481, Val Loss: 6.6771, SORS:\n2.5423', '\\n', 'Epoch 49/50, Train Loss: 6.8508, Val Loss: 6.6782, SORS:\n2.5424', '\\n', 'Epoch 50/50, Train Loss: 6.8535, Val Loss: 6.6793, SORS:\n2.5426', '\\n', 'Training with batch size: 128', '\\n', 'Epoch 1/50, Train Loss:\n16.1173, Val Loss: 13.1897, SORS: 2.6203', '\\n', 'Epoch 2/50, Train Loss:\n15.3856, Val Loss: 12.5908, SORS: 2.6079', '\\n', 'Epoch 3/50, Train Loss:\n14.6425, Val Loss: 11.9925, SORS: 2.6047', '\\n', 'Epoch 4/50, Train Loss:\n13.8808, Val Loss: 11.3887, SORS: 2.6020', '\\n', 'Epoch 5/50, Train Loss:\n13.1028, Val Loss: 10.7782, SORS: 2.5989', '\\n', 'Epoch 6/50, Train Loss:\n12.3059, Val Loss: 10.1647, SORS: 2.5953', '\\n', 'Epoch 7/50, Train Loss:\n11.4986, Val Loss: 9.5588, SORS: 2.5914', '\\n', 'Epoch 8/50, Train Loss:\n10.7013, Val Loss: 8.9748, SORS: 2.5872', '\\n', 'Epoch 9/50, Train Loss: 9.9258,\nVal Loss: 8.4325, SORS: 2.5827', '\\n', 'Epoch 10/50, Train Loss: 9.1981, Val\nLoss: 7.9533, SORS: 2.5782', '\\n', 'Epoch 11/50, Train Loss: 8.5545, Val Loss:\n7.5556, SORS: 2.5745', '\\n', 'Epoch 12/50, Train Loss: 8.0047, Val Loss: 7.2476,\nSORS: 2.5713', '\\n', 'Epoch 13/50, Train Loss: 7.5475, Val Loss: 7.0282, SORS:\n2.5686', '\\n', 'Epoch 14/50, Train Loss: 7.1784, Val Loss: 6.8890, SORS:\n2.5660', '\\n', 'Epoch 15/50, Train Loss: 6.9113, Val Loss: 6.8141, SORS:\n2.5639', '\\n', 'Epoch 16/50, Train Loss: 6.7322, Val Loss: 6.7842, SORS:\n2.5623', '\\n', 'Epoch 17/50, Train Loss: 6.6258, Val Loss: 6.7784, SORS:\n2.5613', '\\n', 'Epoch 18/50, Train Loss: 6.5677, Val Loss: 6.7805, SORS:\n2.5607', '\\n', 'Epoch 19/50, Train Loss: 6.5421, Val Loss: 6.7829, SORS:\n2.5604', '\\n', 'Epoch 20/50, Train Loss: 6.5357, Val Loss: 6.7834, SORS:\n2.5603', '\\n', 'Epoch 21/50, Train Loss: 6.5399, Val Loss: 6.7826, SORS:\n2.5603', '\\n', 'Epoch 22/50, Train Loss: 6.5486, Val Loss: 6.7814, SORS:\n2.5604', '\\n', 'Epoch 23/50, Train Loss: 6.5579, Val Loss: 6.7804, SORS:\n2.5605', '\\n', 'Epoch 24/50, Train Loss: 6.5658, Val Loss: 6.7796, SORS:\n2.5606', '\\n', 'Epoch 25/50, Train Loss: 6.5716, Val Loss: 6.7791, SORS:\n2.5606', '\\n', 'Epoch 26/50, Train Loss: 6.5753, Val Loss: 6.7787, SORS:\n2.5607', '\\n', 'Epoch 27/50, Train Loss: 6.5773, Val Loss: 6.7785, SORS:\n2.5607', '\\n', 'Epoch 28/50, Train Loss: 6.5782, Val Loss: 6.7783, SORS:\n2.5606', '\\n', 'Epoch 29/50, Train Loss: 6.5785, Val Loss: 6.7782, SORS:\n2.5606', '\\n', 'Epoch 30/50, Train Loss: 6.5786, Val Loss: 6.7781, SORS:\n2.5606', '\\n', 'Epoch 31/50, Train Loss: 6.5786, Val Loss: 6.7780, SORS:\n2.5606', '\\n', 'Epoch 32/50, Train Loss: 6.5788, Val Loss: 6.7779, SORS:\n2.5605', '\\n', 'Epoch 33/50, Train Loss: 6.5795, Val Loss: 6.7777, SORS:\n2.5605', '\\n', 'Epoch 34/50, Train Loss: 6.5803, Val Loss: 6.7773, SORS:\n2.5605', '\\n', 'Epoch 35/50, Train Loss: 6.5812, Val Loss: 6.7767, SORS:\n2.5604', '\\n', 'Epoch 36/50, Train Loss: 6.5819, Val Loss: 6.7761, SORS:\n2.5603', '\\n', 'Epoch 37/50, Train Loss: 6.5825, Val Loss: 6.7756, SORS:\n2.5602', '\\n', 'Epoch 38/50, Train Loss: 6.5824, Val Loss: 6.7753, SORS:\n2.5602', '\\n', 'Epoch 39/50, Train Loss: 6.5819, Val Loss: 6.7752, SORS:\n2.5601', '\\n', 'Epoch 40/50, Train Loss: 6.5814, Val Loss: 6.7750, SORS:\n2.5601', '\\n', 'Epoch 41/50, Train Loss: 6.5812, Val Loss: 6.7748, SORS:\n2.5600', '\\n', 'Epoch 42/50, Train Loss: 6.5813, Val Loss: 6.7746, SORS:\n2.5600', '\\n', 'Epoch 43/50, Train Loss: 6.5818, Val Loss: 6.7744, SORS:\n2.5599', '\\n', 'Epoch 44/50, Train Loss: 6.5825, Val Loss: 6.7742, SORS:\n2.5599', '\\n', 'Epoch 45/50, Train Loss: 6.5832, Val Loss: 6.7740, SORS:\n2.5598', '\\n', 'Epoch 46/50, Train Loss: 6.5840, Val Loss: 6.7737, SORS:\n2.5598', '\\n', 'Epoch 47/50, Train Loss: 6.5847, Val Loss: 6.7734, SORS:\n2.5597', '\\n', 'Epoch 48/50, Train Loss: 6.5852, Val Loss: 6.7732, SORS:\n2.5597', '\\n', 'Epoch 49/50, Train Loss: 6.5856, Val Loss: 6.7730, SORS:\n2.5596', '\\n', 'Epoch 50/50, Train Loss: 6.5863, Val Loss: 6.7728, SORS:\n2.5596', '\\n', 'Training with batch size: 256', '\\n', 'Epoch 1/50, Train Loss:\n17.5704, Val Loss: 14.4827, SORS: 2.7601', '\\n', 'Epoch 2/50, Train Loss:\n17.2791, Val Loss: 14.2464, SORS: 2.7212', '\\n', 'Epoch 3/50, Train Loss:\n17.0118, Val Loss: 14.0319, SORS: 2.6890', '\\n', 'Epoch 4/50, Train Loss:\n16.7710, Val Loss: 13.8366, SORS: 2.6642', '\\n', 'Epoch 5/50, Train Loss:\n16.5519, Val Loss: 13.6588, SORS: 2.6451', '\\n', 'Epoch 6/50, Train Loss:\n16.3522, Val Loss: 13.4943, SORS: 2.6307', '\\n', 'Epoch 7/50, Train Loss:\n16.1685, Val Loss: 13.3397, SORS: 2.6202', '\\n', 'Epoch 8/50, Train Loss:\n15.9948, Val Loss: 13.1915, SORS: 2.6130', '\\n', 'Epoch 9/50, Train Loss:\n15.8308, Val Loss: 13.0475, SORS: 2.6079', '\\n', 'Epoch 10/50, Train Loss:\n15.6719, Val Loss: 12.9055, SORS: 2.6045', '\\n', 'Epoch 11/50, Train Loss:\n15.5111, Val Loss: 12.7625, SORS: 2.6018', '\\n', 'Epoch 12/50, Train Loss:\n15.3436, Val Loss: 12.6165, SORS: 2.5996', '\\n', 'Epoch 13/50, Train Loss:\n15.1675, Val Loss: 12.4648, SORS: 2.5976', '\\n', 'Epoch 14/50, Train Loss:\n14.9805, Val Loss: 12.3043, SORS: 2.5957', '\\n', 'Epoch 15/50, Train Loss:\n14.7817, Val Loss: 12.1342, SORS: 2.5943', '\\n', 'Epoch 16/50, Train Loss:\n14.5681, Val Loss: 11.9534, SORS: 2.5934', '\\n', 'Epoch 17/50, Train Loss:\n14.3392, Val Loss: 11.7613, SORS: 2.5926', '\\n', 'Epoch 18/50, Train Loss:\n14.0954, Val Loss: 11.5577, SORS: 2.5917', '\\n', 'Epoch 19/50, Train Loss:\n13.8381, Val Loss: 11.3433, SORS: 2.5906', '\\n', 'Epoch 20/50, Train Loss:\n13.5698, Val Loss: 11.1205, SORS: 2.5894', '\\n', 'Epoch 21/50, Train Loss:\n13.2891, Val Loss: 10.8910, SORS: 2.5883', '\\n', 'Epoch 22/50, Train Loss:\n12.9999, Val Loss: 10.6565, SORS: 2.5872', '\\n', 'Epoch 23/50, Train Loss:\n12.7026, Val Loss: 10.4184, SORS: 2.5860', '\\n', 'Epoch 24/50, Train Loss:\n12.4006, Val Loss: 10.1784, SORS: 2.5846', '\\n', 'Epoch 25/50, Train Loss:\n12.0962, Val Loss: 9.9384, SORS: 2.5833', '\\n', 'Epoch 26/50, Train Loss:\n11.7910, Val Loss: 9.6998, SORS: 2.5819', '\\n', 'Epoch 27/50, Train Loss:\n11.4863, Val Loss: 9.4641, SORS: 2.5804', '\\n', 'Epoch 28/50, Train Loss:\n11.1838, Val Loss: 9.2326, SORS: 2.5788', '\\n', 'Epoch 29/50, Train Loss:\n10.8850, Val Loss: 9.0068, SORS: 2.5772', '\\n', 'Epoch 30/50, Train Loss:\n10.5915, Val Loss: 8.7880, SORS: 2.5756', '\\n', 'Epoch 31/50, Train Loss:\n10.3047, Val Loss: 8.5774, SORS: 2.5739', '\\n', 'Epoch 32/50, Train Loss:\n10.0260, Val Loss: 8.3761, SORS: 2.5722', '\\n', 'Epoch 33/50, Train Loss:\n9.7566, Val Loss: 8.1850, SORS: 2.5705', '\\n', 'Epoch 34/50, Train Loss: 9.4975,\nVal Loss: 8.0051, SORS: 2.5689', '\\n', 'Epoch 35/50, Train Loss: 9.2499, Val\nLoss: 7.8369, SORS: 2.5672', '\\n', 'Epoch 36/50, Train Loss: 9.0147, Val Loss:\n7.6809, SORS: 2.5655', '\\n', 'Epoch 37/50, Train Loss: 8.7927, Val Loss: 7.5378,\nSORS: 2.5638', '\\n', 'Epoch 38/50, Train Loss: 8.5845, Val Loss: 7.4074, SORS:\n2.5622', '\\n', 'Epoch 39/50, Train Loss: 8.3904, Val Loss: 7.2899, SORS:\n2.5606', '\\n', 'Epoch 40/50, Train Loss: 8.2107, Val Loss: 7.1852, SORS:\n2.5590', '\\n', 'Epoch 41/50, Train Loss: 8.0454, Val Loss: 7.0929, SORS:\n2.5575', '\\n', 'Epoch 42/50, Train Loss: 7.8944, Val Loss: 7.0124, SORS:\n2.5560', '\\n', 'Epoch 43/50, Train Loss: 7.7573, Val Loss: 6.9432, SORS:\n2.5546', '\\n', 'Epoch 44/50, Train Loss: 7.6337, Val Loss: 6.8845, SORS:\n2.5533', '\\n', 'Epoch 45/50, Train Loss: 7.5230, Val Loss: 6.8353, SORS:\n2.5520', '\\n', 'Epoch 46/50, Train Loss: 7.4244, Val Loss: 6.7948, SORS:\n2.5508', '\\n', 'Epoch 47/50, Train Loss: 7.3372, Val Loss: 6.7620, SORS:\n2.5497', '\\n', 'Epoch 48/50, Train Loss: 7.2607, Val Loss: 6.7359, SORS:\n2.5486', '\\n', 'Epoch 49/50, Train Loss: 7.1938, Val Loss: 6.7156, SORS:\n2.5477', '\\n', 'Epoch 50/50, Train Loss: 7.1358, Val Loss: 6.7001, SORS:\n2.5468', '\\n', 'Evaluating dataset_3', '\\n', 'Training with batch size: 16',\n'\\n', 'Epoch 1/50, Train Loss: 9.9039, Val Loss: 9.5975, SORS: 2.3512', '\\n',\n'Epoch 2/50, Train Loss: 7.2321, Val Loss: 7.0976, SORS: 2.4580', '\\n', 'Epoch\n3/50, Train Loss: 6.7618, Val Loss: 6.7091, SORS: 2.5446', '\\n', 'Epoch 4/50,\nTrain Loss: 6.8152, Val Loss: 6.7567, SORS: 2.5549', '\\n', 'Epoch 5/50, Train\nLoss: 6.8169, Val Loss: 6.7524, SORS: 2.5543', '\\n', 'Epoch 6/50, Train Loss:\n6.8217, Val Loss: 6.7514, SORS: 2.5543', '\\n', 'Epoch 7/50, Train Loss: 6.8258,\nVal Loss: 6.7500, SORS: 2.5541', '\\n', 'Epoch 8/50, Train Loss: 6.8299, Val\nLoss: 6.7492, SORS: 2.5541', '\\n', 'Epoch 9/50, Train Loss: 6.8351, Val Loss:\n6.7478, SORS: 2.5539', '\\n', 'Epoch 10/50, Train Loss: 6.8389, Val Loss: 6.7468,\nSORS: 2.5537', '\\n', 'Epoch 11/50, Train Loss: 6.8421, Val Loss: 6.7460, SORS:\n2.5536', '\\n', 'Epoch 12/50, Train Loss: 6.8472, Val Loss: 6.7451, SORS:\n2.5535', '\\n', 'Epoch 13/50, Train Loss: 6.8480, Val Loss: 6.7447, SORS:\n2.5534', '\\n', 'Epoch 14/50, Train Loss: 6.8533, Val Loss: 6.7437, SORS:\n2.5531', '\\n', 'Epoch 15/50, Train Loss: 6.8502, Val Loss: 6.7343, SORS:\n2.5514', '\\n', 'Epoch 16/50, Train Loss: 6.8625, Val Loss: 6.7401, SORS:\n2.5523', '\\n', 'Epoch 17/50, Train Loss: 6.8681, Val Loss: 6.7411, SORS:\n2.5523', '\\n', 'Epoch 18/50, Train Loss: 6.8711, Val Loss: 6.7392, SORS:\n2.5518', '\\n', 'Epoch 19/50, Train Loss: 6.8735, Val Loss: 6.7384, SORS:\n2.5516', '\\n', 'Epoch 20/50, Train Loss: 6.8793, Val Loss: 6.7383, SORS:\n2.5513', '\\n', 'Epoch 21/50, Train Loss: 6.8861, Val Loss: 6.7368, SORS:\n2.5509', '\\n', 'Epoch 22/50, Train Loss: 6.8829, Val Loss: 6.7379, SORS:\n2.5508', '\\n', 'Epoch 23/50, Train Loss: 6.8935, Val Loss: 6.7365, SORS:\n2.5503', '\\n', 'Epoch 24/50, Train Loss: 6.8972, Val Loss: 6.7368, SORS:\n2.5501', '\\n', 'Epoch 25/50, Train Loss: 6.8984, Val Loss: 6.7342, SORS:\n2.5494', '\\n', 'Epoch 26/50, Train Loss: 6.9008, Val Loss: 6.7345, SORS:\n2.5492', '\\n', 'Epoch 27/50, Train Loss: 6.9065, Val Loss: 6.7338, SORS:\n2.5487', '\\n', 'Epoch 28/50, Train Loss: 6.9118, Val Loss: 6.7341, SORS:\n2.5485', '\\n', 'Epoch 29/50, Train Loss: 6.9166, Val Loss: 6.7320, SORS:\n2.5478', '\\n', 'Epoch 30/50, Train Loss: 6.9240, Val Loss: 6.7325, SORS:\n2.5477', '\\n', 'Epoch 31/50, Train Loss: 6.9293, Val Loss: 6.7342, SORS:\n2.5478', '\\n', 'Epoch 32/50, Train Loss: 6.9365, Val Loss: 6.7353, SORS:\n2.5477', '\\n', 'Epoch 33/50, Train Loss: 6.9387, Val Loss: 6.7345, SORS:\n2.5473', '\\n', 'Epoch 34/50, Train Loss: 6.9462, Val Loss: 6.7325, SORS:\n2.5466', '\\n', 'Epoch 35/50, Train Loss: 6.9484, Val Loss: 6.7331, SORS:\n2.5464', '\\n', 'Epoch 36/50, Train Loss: 6.9517, Val Loss: 6.7341, SORS:\n2.5464', '\\n', 'Epoch 37/50, Train Loss: 6.9582, Val Loss: 6.7343, SORS:\n2.5462', '\\n', 'Epoch 38/50, Train Loss: 6.9608, Val Loss: 6.7351, SORS:\n2.5461', '\\n', 'Epoch 39/50, Train Loss: 6.9649, Val Loss: 6.7358, SORS:\n2.5459', '\\n', 'Epoch 40/50, Train Loss: 6.9681, Val Loss: 6.7360, SORS:\n2.5457', '\\n', 'Epoch 41/50, Train Loss: 6.9698, Val Loss: 6.7363, SORS:\n2.5455', '\\n', 'Epoch 42/50, Train Loss: 6.9755, Val Loss: 6.7359, SORS:\n2.5451', '\\n', 'Epoch 43/50, Train Loss: 6.9743, Val Loss: 6.7360, SORS:\n2.5449', '\\n', 'Epoch 44/50, Train Loss: 6.9878, Val Loss: 6.7385, SORS:\n2.5450', '\\n', 'Epoch 45/50, Train Loss: 6.9794, Val Loss: 6.7369, SORS:\n2.5445', '\\n', 'Epoch 46/50, Train Loss: 6.9865, Val Loss: 6.7382, SORS:\n2.5445', '\\n', 'Epoch 47/50, Train Loss: 6.9889, Val Loss: 6.7366, SORS:\n2.5439', '\\n', 'Epoch 48/50, Train Loss: 6.9909, Val Loss: 6.7379, SORS:\n2.5438', '\\n', 'Epoch 49/50, Train Loss: 6.9933, Val Loss: 6.7375, SORS:\n2.5434', '\\n', 'Epoch 50/50, Train Loss: 6.9957, Val Loss: 6.7368, SORS:\n2.5429', '\\n', 'Training with batch size: 32', '\\n', 'Epoch 1/50, Train Loss:\n12.1654, Val Loss: 9.4027, SORS: 2.3600', '\\n', 'Epoch 2/50, Train Loss:\n10.0614, Val Loss: 7.9494, SORS: 2.4179', '\\n', 'Epoch 3/50, Train Loss: 8.2813,\nVal Loss: 6.9555, SORS: 2.4839', '\\n', 'Epoch 4/50, Train Loss: 7.3752, Val\nLoss: 6.7196, SORS: 2.5391', '\\n', 'Epoch 5/50, Train Loss: 7.1373, Val Loss:\n6.7931, SORS: 2.5646', '\\n', 'Epoch 6/50, Train Loss: 7.1028, Val Loss: 6.8150,\nSORS: 2.5686', '\\n', 'Epoch 7/50, Train Loss: 7.1003, Val Loss: 6.8076, SORS:\n2.5674', '\\n', 'Epoch 8/50, Train Loss: 7.0957, Val Loss: 6.8029, SORS: 2.5665',\n'\\n', 'Epoch 9/50, Train Loss: 7.0884, Val Loss: 6.8009, SORS: 2.5662', '\\n',\n'Epoch 10/50, Train Loss: 7.0808, Val Loss: 6.7991, SORS: 2.5659', '\\n', 'Epoch\n11/50, Train Loss: 7.0736, Val Loss: 6.7974, SORS: 2.5655', '\\n', 'Epoch 12/50,\nTrain Loss: 7.0684, Val Loss: 6.7957, SORS: 2.5652', '\\n', 'Epoch 13/50, Train\nLoss: 7.0616, Val Loss: 6.7947, SORS: 2.5650', '\\n', 'Epoch 14/50, Train Loss:\n7.0548, Val Loss: 6.7937, SORS: 2.5647', '\\n', 'Epoch 15/50, Train Loss: 7.0490,\nVal Loss: 6.7920, SORS: 2.5643', '\\n', 'Epoch 16/50, Train Loss: 7.0434, Val\nLoss: 6.7904, SORS: 2.5640', '\\n', 'Epoch 17/50, Train Loss: 7.0380, Val Loss:\n6.7889, SORS: 2.5636', '\\n', 'Epoch 18/50, Train Loss: 7.0330, Val Loss: 6.7878,\nSORS: 2.5633', '\\n', 'Epoch 19/50, Train Loss: 7.0285, Val Loss: 6.7864, SORS:\n2.5629', '\\n', 'Epoch 20/50, Train Loss: 7.0236, Val Loss: 6.7852, SORS:\n2.5626', '\\n', 'Epoch 21/50, Train Loss: 7.0171, Val Loss: 6.7849, SORS:\n2.5624', '\\n', 'Epoch 22/50, Train Loss: 7.0117, Val Loss: 6.7839, SORS:\n2.5621', '\\n', 'Epoch 23/50, Train Loss: 7.0064, Val Loss: 6.7829, SORS:\n2.5618', '\\n', 'Epoch 24/50, Train Loss: 7.0002, Val Loss: 6.7830, SORS:\n2.5618', '\\n', 'Epoch 25/50, Train Loss: 6.9970, Val Loss: 6.7809, SORS:\n2.5612', '\\n', 'Epoch 26/50, Train Loss: 6.9914, Val Loss: 6.7808, SORS:\n2.5611', '\\n', 'Epoch 27/50, Train Loss: 6.9872, Val Loss: 6.7792, SORS:\n2.5607', '\\n', 'Epoch 28/50, Train Loss: 6.9843, Val Loss: 6.7780, SORS:\n2.5603', '\\n', 'Epoch 29/50, Train Loss: 6.9797, Val Loss: 6.7771, SORS:\n2.5600', '\\n', 'Epoch 30/50, Train Loss: 6.9748, Val Loss: 6.7763, SORS:\n2.5598', '\\n', 'Epoch 31/50, Train Loss: 6.9715, Val Loss: 6.7750, SORS:\n2.5594', '\\n', 'Epoch 32/50, Train Loss: 6.9679, Val Loss: 6.7741, SORS:\n2.5591', '\\n', 'Epoch 33/50, Train Loss: 6.9639, Val Loss: 6.7733, SORS:\n2.5588', '\\n', 'Epoch 34/50, Train Loss: 6.9598, Val Loss: 6.7722, SORS:\n2.5585', '\\n', 'Epoch 35/50, Train Loss: 6.9563, Val Loss: 6.7713, SORS:\n2.5582', '\\n', 'Epoch 36/50, Train Loss: 6.9529, Val Loss: 6.7703, SORS:\n2.5578', '\\n', 'Epoch 37/50, Train Loss: 6.9484, Val Loss: 6.7696, SORS:\n2.5576', '\\n', 'Epoch 38/50, Train Loss: 6.9443, Val Loss: 6.7690, SORS:\n2.5574', '\\n', 'Epoch 39/50, Train Loss: 6.9409, Val Loss: 6.7678, SORS:\n2.5570', '\\n', 'Epoch 40/50, Train Loss: 6.9367, Val Loss: 6.7677, SORS:\n2.5568', '\\n', 'Epoch 41/50, Train Loss: 6.9320, Val Loss: 6.7671, SORS:\n2.5566', '\\n', 'Epoch 42/50, Train Loss: 6.9289, Val Loss: 6.7662, SORS:\n2.5563', '\\n', 'Epoch 43/50, Train Loss: 6.9238, Val Loss: 6.7658, SORS:\n2.5560', '\\n', 'Epoch 44/50, Train Loss: 6.9199, Val Loss: 6.7652, SORS:\n2.5558', '\\n', 'Epoch 45/50, Train Loss: 6.9159, Val Loss: 6.7644, SORS:\n2.5555', '\\n', 'Epoch 46/50, Train Loss: 6.9121, Val Loss: 6.7637, SORS:\n2.5552', '\\n', 'Epoch 47/50, Train Loss: 6.9066, Val Loss: 6.7633, SORS:\n2.5550', '\\n', 'Epoch 48/50, Train Loss: 6.9022, Val Loss: 6.7633, SORS:\n2.5548', '\\n', 'Epoch 49/50, Train Loss: 6.8961, Val Loss: 6.7620, SORS:\n2.5545', '\\n', 'Epoch 50/50, Train Loss: 6.8941, Val Loss: 6.7615, SORS:\n2.5542', '\\n', 'Training with batch size: 64', '\\n', 'Epoch 1/50, Train Loss:\n15.5753, Val Loss: 12.0186, SORS: 2.3624', '\\n', 'Epoch 2/50, Train Loss:\n13.9012, Val Loss: 10.7789, SORS: 2.3274', '\\n', 'Epoch 3/50, Train Loss:\n12.3276, Val Loss: 9.6501, SORS: 2.3577', '\\n', 'Epoch 4/50, Train Loss:\n10.8212, Val Loss: 8.6233, SORS: 2.3913', '\\n', 'Epoch 5/50, Train Loss: 9.4501,\nVal Loss: 7.7602, SORS: 2.4281', '\\n', 'Epoch 6/50, Train Loss: 8.3238, Val\nLoss: 7.1474, SORS: 2.4662', '\\n', 'Epoch 7/50, Train Loss: 7.5182, Val Loss:\n6.8177, SORS: 2.5019', '\\n', 'Epoch 8/50, Train Loss: 7.0341, Val Loss: 6.7253,\nSORS: 2.5316', '\\n', 'Epoch 9/50, Train Loss: 6.7967, Val Loss: 6.7558, SORS:\n2.5520', '\\n', 'Epoch 10/50, Train Loss: 6.7023, Val Loss: 6.8037, SORS:\n2.5629', '\\n', 'Epoch 11/50, Train Loss: 6.6733, Val Loss: 6.8255, SORS:\n2.5667', '\\n', 'Epoch 12/50, Train Loss: 6.6697, Val Loss: 6.8263, SORS:\n2.5668', '\\n', 'Epoch 13/50, Train Loss: 6.6737, Val Loss: 6.8204, SORS:\n2.5659', '\\n', 'Epoch 14/50, Train Loss: 6.6772, Val Loss: 6.8152, SORS:\n2.5650', '\\n', 'Epoch 15/50, Train Loss: 6.6783, Val Loss: 6.8124, SORS:\n2.5645', '\\n', 'Epoch 16/50, Train Loss: 6.6776, Val Loss: 6.8112, SORS:\n2.5643', '\\n', 'Epoch 17/50, Train Loss: 6.6762, Val Loss: 6.8106, SORS:\n2.5642', '\\n', 'Epoch 18/50, Train Loss: 6.6746, Val Loss: 6.8102, SORS:\n2.5642', '\\n', 'Epoch 19/50, Train Loss: 6.6731, Val Loss: 6.8097, SORS:\n2.5641', '\\n', 'Epoch 20/50, Train Loss: 6.6717, Val Loss: 6.8090, SORS:\n2.5640', '\\n', 'Epoch 21/50, Train Loss: 6.6704, Val Loss: 6.8084, SORS:\n2.5639', '\\n', 'Epoch 22/50, Train Loss: 6.6691, Val Loss: 6.8077, SORS:\n2.5637', '\\n', 'Epoch 23/50, Train Loss: 6.6680, Val Loss: 6.8071, SORS:\n2.5636', '\\n', 'Epoch 24/50, Train Loss: 6.6670, Val Loss: 6.8065, SORS:\n2.5635', '\\n', 'Epoch 25/50, Train Loss: 6.6660, Val Loss: 6.8059, SORS:\n2.5634', '\\n', 'Epoch 26/50, Train Loss: 6.6650, Val Loss: 6.8053, SORS:\n2.5633', '\\n', 'Epoch 27/50, Train Loss: 6.6643, Val Loss: 6.8047, SORS:\n2.5632', '\\n', 'Epoch 28/50, Train Loss: 6.6636, Val Loss: 6.8042, SORS:\n2.5631', '\\n', 'Epoch 29/50, Train Loss: 6.6631, Val Loss: 6.8037, SORS:\n2.5630', '\\n', 'Epoch 30/50, Train Loss: 6.6626, Val Loss: 6.8031, SORS:\n2.5629', '\\n', 'Epoch 31/50, Train Loss: 6.6620, Val Loss: 6.8026, SORS:\n2.5628', '\\n', 'Epoch 32/50, Train Loss: 6.6616, Val Loss: 6.8020, SORS:\n2.5626', '\\n', 'Epoch 33/50, Train Loss: 6.6610, Val Loss: 6.8016, SORS:\n2.5625', '\\n', 'Epoch 34/50, Train Loss: 6.6604, Val Loss: 6.8012, SORS:\n2.5624', '\\n', 'Epoch 35/50, Train Loss: 6.6600, Val Loss: 6.8007, SORS:\n2.5623', '\\n', 'Epoch 36/50, Train Loss: 6.6596, Val Loss: 6.8002, SORS:\n2.5622', '\\n', 'Epoch 37/50, Train Loss: 6.6591, Val Loss: 6.7997, SORS:\n2.5621', '\\n', 'Epoch 38/50, Train Loss: 6.6587, Val Loss: 6.7992, SORS:\n2.5620', '\\n', 'Epoch 39/50, Train Loss: 6.6581, Val Loss: 6.7988, SORS:\n2.5619', '\\n', 'Epoch 40/50, Train Loss: 6.6575, Val Loss: 6.7983, SORS:\n2.5618', '\\n', 'Epoch 41/50, Train Loss: 6.6569, Val Loss: 6.7980, SORS:\n2.5617', '\\n', 'Epoch 42/50, Train Loss: 6.6564, Val Loss: 6.7977, SORS:\n2.5616', '\\n', 'Epoch 43/50, Train Loss: 6.6559, Val Loss: 6.7974, SORS:\n2.5615', '\\n', 'Epoch 44/50, Train Loss: 6.6555, Val Loss: 6.7971, SORS:\n2.5614', '\\n', 'Epoch 45/50, Train Loss: 6.6551, Val Loss: 6.7967, SORS:\n2.5613', '\\n', 'Epoch 46/50, Train Loss: 6.6547, Val Loss: 6.7963, SORS:\n2.5612', '\\n', 'Epoch 47/50, Train Loss: 6.6543, Val Loss: 6.7960, SORS:\n2.5611', '\\n', 'Epoch 48/50, Train Loss: 6.6539, Val Loss: 6.7957, SORS:\n2.5610', '\\n', 'Epoch 49/50, Train Loss: 6.6534, Val Loss: 6.7954, SORS:\n2.5609', '\\n', 'Epoch 50/50, Train Loss: 6.6529, Val Loss: 6.7952, SORS:\n2.5608', '\\n', 'Training with batch size: 128', '\\n', 'Epoch 1/50, Train Loss:\n14.5782, Val Loss: 11.1625, SORS: 2.3236', '\\n', 'Epoch 2/50, Train Loss:\n13.8703, Val Loss: 10.6226, SORS: 2.3350', '\\n', 'Epoch 3/50, Train Loss:\n13.1443, Val Loss: 10.0882, SORS: 2.3500', '\\n', 'Epoch 4/50, Train Loss:\n12.4024, Val Loss: 9.5581, SORS: 2.3668', '\\n', 'Epoch 5/50, Train Loss:\n11.6520, Val Loss: 9.0313, SORS: 2.3846', '\\n', 'Epoch 6/50, Train Loss:\n10.9043, Val Loss: 8.5165, SORS: 2.4039', '\\n', 'Epoch 7/50, Train Loss:\n10.1620, Val Loss: 8.0308, SORS: 2.4249', '\\n', 'Epoch 8/50, Train Loss: 9.4482,\nVal Loss: 7.5944, SORS: 2.4474', '\\n', 'Epoch 9/50, Train Loss: 8.7884, Val\nLoss: 7.2359, SORS: 2.4710', '\\n', 'Epoch 10/50, Train Loss: 8.2169, Val Loss:\n6.9774, SORS: 2.4952', '\\n', 'Epoch 11/50, Train Loss: 7.7612, Val Loss: 6.8243,\nSORS: 2.5184', '\\n', 'Epoch 12/50, Train Loss: 7.4321, Val Loss: 6.7685, SORS:\n2.5394', '\\n', 'Epoch 13/50, Train Loss: 7.2172, Val Loss: 6.7836, SORS:\n2.5572', '\\n', 'Epoch 14/50, Train Loss: 7.0923, Val Loss: 6.8317, SORS:\n2.5704', '\\n', 'Epoch 15/50, Train Loss: 7.0269, Val Loss: 6.8797, SORS:\n2.5790', '\\n', 'Epoch 16/50, Train Loss: 6.9953, Val Loss: 6.9092, SORS:\n2.5833', '\\n', 'Epoch 17/50, Train Loss: 6.9812, Val Loss: 6.9179, SORS:\n2.5845', '\\n', 'Epoch 18/50, Train Loss: 6.9762, Val Loss: 6.9125, SORS:\n2.5838', '\\n', 'Epoch 19/50, Train Loss: 6.9755, Val Loss: 6.9012, SORS:\n2.5822', '\\n', 'Epoch 20/50, Train Loss: 6.9758, Val Loss: 6.8896, SORS:\n2.5805', '\\n', 'Epoch 21/50, Train Loss: 6.9753, Val Loss: 6.8803, SORS:\n2.5792', '\\n', 'Epoch 22/50, Train Loss: 6.9727, Val Loss: 6.8740, SORS:\n2.5782', '\\n', 'Epoch 23/50, Train Loss: 6.9682, Val Loss: 6.8703, SORS:\n2.5777', '\\n', 'Epoch 24/50, Train Loss: 6.9621, Val Loss: 6.8684, SORS:\n2.5774', '\\n', 'Epoch 25/50, Train Loss: 6.9551, Val Loss: 6.8675, SORS:\n2.5772', '\\n', 'Epoch 26/50, Train Loss: 6.9478, Val Loss: 6.8669, SORS:\n2.5771', '\\n', 'Epoch 27/50, Train Loss: 6.9405, Val Loss: 6.8662, SORS:\n2.5770', '\\n', 'Epoch 28/50, Train Loss: 6.9334, Val Loss: 6.8653, SORS:\n2.5769', '\\n', 'Epoch 29/50, Train Loss: 6.9265, Val Loss: 6.8640, SORS:\n2.5767', '\\n', 'Epoch 30/50, Train Loss: 6.9199, Val Loss: 6.8626, SORS:\n2.5765', '\\n', 'Epoch 31/50, Train Loss: 6.9134, Val Loss: 6.8610, SORS:\n2.5762', '\\n', 'Epoch 32/50, Train Loss: 6.9070, Val Loss: 6.8594, SORS:\n2.5759', '\\n', 'Epoch 33/50, Train Loss: 6.9006, Val Loss: 6.8578, SORS:\n2.5757', '\\n', 'Epoch 34/50, Train Loss: 6.8942, Val Loss: 6.8563, SORS:\n2.5754', '\\n', 'Epoch 35/50, Train Loss: 6.8879, Val Loss: 6.8547, SORS:\n2.5752', '\\n', 'Epoch 36/50, Train Loss: 6.8815, Val Loss: 6.8532, SORS:\n2.5749', '\\n', 'Epoch 37/50, Train Loss: 6.8750, Val Loss: 6.8518, SORS:\n2.5746', '\\n', 'Epoch 38/50, Train Loss: 6.8686, Val Loss: 6.8504, SORS:\n2.5744', '\\n', 'Epoch 39/50, Train Loss: 6.8622, Val Loss: 6.8490, SORS:\n2.5742', '\\n', 'Epoch 40/50, Train Loss: 6.8557, Val Loss: 6.8476, SORS:\n2.5739', '\\n', 'Epoch 41/50, Train Loss: 6.8493, Val Loss: 6.8462, SORS:\n2.5737', '\\n', 'Epoch 42/50, Train Loss: 6.8428, Val Loss: 6.8448, SORS:\n2.5734', '\\n', 'Epoch 43/50, Train Loss: 6.8363, Val Loss: 6.8435, SORS:\n2.5732', '\\n', 'Epoch 44/50, Train Loss: 6.8297, Val Loss: 6.8421, SORS:\n2.5729', '\\n', 'Epoch 45/50, Train Loss: 6.8230, Val Loss: 6.8408, SORS:\n2.5727', '\\n', 'Epoch 46/50, Train Loss: 6.8162, Val Loss: 6.8395, SORS:\n2.5724', '\\n', 'Epoch 47/50, Train Loss: 6.8093, Val Loss: 6.8382, SORS:\n2.5722', '\\n', 'Epoch 48/50, Train Loss: 6.8023, Val Loss: 6.8368, SORS:\n2.5719', '\\n', 'Epoch 49/50, Train Loss: 6.7953, Val Loss: 6.8353, SORS:\n2.5716', '\\n', 'Epoch 50/50, Train Loss: 6.7886, Val Loss: 6.8337, SORS:\n2.5713', '\\n', 'Training with batch size: 256', '\\n', 'Epoch 1/50, Train Loss:\n17.2999, Val Loss: 13.2222, SORS: 2.5608', '\\n', 'Epoch 2/50, Train Loss:\n16.9190, Val Loss: 12.9275, SORS: 2.5039', '\\n', 'Epoch 3/50, Train Loss:\n16.5429, Val Loss: 12.6383, SORS: 2.4490', '\\n', 'Epoch 4/50, Train Loss:\n16.1749, Val Loss: 12.3529, SORS: 2.4011', '\\n', 'Epoch 5/50, Train Loss:\n15.8057, Val Loss: 12.0704, SORS: 2.3616', '\\n', 'Epoch 6/50, Train Loss:\n15.4338, Val Loss: 11.7899, SORS: 2.3352', '\\n', 'Epoch 7/50, Train Loss:\n15.0607, Val Loss: 11.5107, SORS: 2.3214', '\\n', 'Epoch 8/50, Train Loss:\n14.6853, Val Loss: 11.2298, SORS: 2.3138', '\\n', 'Epoch 9/50, Train Loss:\n14.3120, Val Loss: 10.9464, SORS: 2.3139', '\\n', 'Epoch 10/50, Train Loss:\n13.9327, Val Loss: 10.6587, SORS: 2.3182', '\\n', 'Epoch 11/50, Train Loss:\n13.5438, Val Loss: 10.3667, SORS: 2.3251', '\\n', 'Epoch 12/50, Train Loss:\n13.1479, Val Loss: 10.0707, SORS: 2.3325', '\\n', 'Epoch 13/50, Train Loss:\n12.7447, Val Loss: 9.7737, SORS: 2.3404', '\\n', 'Epoch 14/50, Train Loss:\n12.3418, Val Loss: 9.4755, SORS: 2.3484', '\\n', 'Epoch 15/50, Train Loss:\n11.9320, Val Loss: 9.1797, SORS: 2.3569', '\\n', 'Epoch 16/50, Train Loss:\n11.5165, Val Loss: 8.8901, SORS: 2.3664', '\\n', 'Epoch 17/50, Train Loss:\n11.1050, Val Loss: 8.6096, SORS: 2.3764', '\\n', 'Epoch 18/50, Train Loss:\n10.7015, Val Loss: 8.3410, SORS: 2.3867', '\\n', 'Epoch 19/50, Train Loss:\n10.3047, Val Loss: 8.0866, SORS: 2.3974', '\\n', 'Epoch 20/50, Train Loss:\n9.9212, Val Loss: 7.8487, SORS: 2.4083', '\\n', 'Epoch 21/50, Train Loss: 9.5556,\nVal Loss: 7.6293, SORS: 2.4193', '\\n', 'Epoch 22/50, Train Loss: 9.2085, Val\nLoss: 7.4300, SORS: 2.4305', '\\n', 'Epoch 23/50, Train Loss: 8.8819, Val Loss:\n7.2533, SORS: 2.4417', '\\n', 'Epoch 24/50, Train Loss: 8.5790, Val Loss: 7.0999,\nSORS: 2.4528', '\\n', 'Epoch 25/50, Train Loss: 8.3032, Val Loss: 6.9699, SORS:\n2.4637', '\\n', 'Epoch 26/50, Train Loss: 8.0546, Val Loss: 6.8642, SORS:\n2.4745', '\\n', 'Epoch 27/50, Train Loss: 7.8338, Val Loss: 6.7819, SORS:\n2.4848', '\\n', 'Epoch 28/50, Train Loss: 7.6407, Val Loss: 6.7213, SORS:\n2.4947', '\\n', 'Epoch 29/50, Train Loss: 7.4742, Val Loss: 6.6807, SORS:\n2.5041', '\\n', 'Epoch 30/50, Train Loss: 7.3333, Val Loss: 6.6577, SORS:\n2.5129', '\\n', 'Epoch 31/50, Train Loss: 7.2162, Val Loss: 6.6492, SORS:\n2.5210', '\\n', 'Epoch 32/50, Train Loss: 7.1204, Val Loss: 6.6521, SORS:\n2.5284', '\\n', 'Epoch 33/50, Train Loss: 7.0434, Val Loss: 6.6632, SORS:\n2.5350', '\\n', 'Epoch 34/50, Train Loss: 6.9823, Val Loss: 6.6797, SORS:\n2.5408', '\\n', 'Epoch 35/50, Train Loss: 6.9346, Val Loss: 6.6987, SORS:\n2.5457', '\\n', 'Epoch 36/50, Train Loss: 6.8977, Val Loss: 6.7182, SORS:\n2.5499', '\\n', 'Epoch 37/50, Train Loss: 6.8694, Val Loss: 6.7364, SORS:\n2.5533', '\\n', 'Epoch 38/50, Train Loss: 6.8478, Val Loss: 6.7524, SORS:\n2.5560', '\\n', 'Epoch 39/50, Train Loss: 6.8314, Val Loss: 6.7654, SORS:\n2.5580', '\\n', 'Epoch 40/50, Train Loss: 6.8189, Val Loss: 6.7754, SORS:\n2.5595', '\\n', 'Epoch 41/50, Train Loss: 6.8093, Val Loss: 6.7827, SORS:\n2.5605', '\\n', 'Epoch 42/50, Train Loss: 6.8020, Val Loss: 6.7875, SORS:\n2.5612', '\\n', 'Epoch 43/50, Train Loss: 6.7967, Val Loss: 6.7904, SORS:\n2.5615', '\\n', 'Epoch 44/50, Train Loss: 6.7918, Val Loss: 6.7919, SORS:\n2.5617', '\\n', 'Epoch 45/50, Train Loss: 6.7882, Val Loss: 6.7921, SORS:\n2.5618', '\\n', 'Epoch 46/50, Train Loss: 6.7850, Val Loss: 6.7914, SORS:\n2.5617', '\\n', 'Epoch 47/50, Train Loss: 6.7823, Val Loss: 6.7902, SORS:\n2.5615', '\\n', 'Epoch 48/50, Train Loss: 6.7797, Val Loss: 6.7887, SORS:\n2.5613', '\\n', 'Epoch 49/50, Train Loss: 6.7772, Val Loss: 6.7870, SORS:\n2.5610', '\\n', 'Epoch 50/50, Train Loss: 6.7747, Val Loss: 6.7853, SORS:\n2.5608', '\\n', 'Execution time: 18 seconds seconds (time limit is 10 minutes).']", "['Using device: cuda', '\\n', 'Training full_dataset with batch size: 16', '\\n',\n'Epoch 1/50, Train Loss: 9.9592, Val Loss: 8.7622, SORS: 2.4666', '\\n', 'Epoch\n2/50, Train Loss: 7.0277, Val Loss: 6.3445, SORS: 2.4516', '\\n', 'Epoch 3/50,\nTrain Loss: 6.7200, Val Loss: 6.1832, SORS: 2.4465', '\\n', 'Epoch 4/50, Train\nLoss: 6.6892, Val Loss: 6.1759, SORS: 2.4451', '\\n', 'Epoch 5/50, Train Loss:\n6.6577, Val Loss: 6.1693, SORS: 2.4437', '\\n', 'Epoch 6/50, Train Loss: 6.6252,\nVal Loss: 6.1637, SORS: 2.4425', '\\n', 'Epoch 7/50, Train Loss: 6.5943, Val\nLoss: 6.1582, SORS: 2.4412', '\\n', 'Epoch 8/50, Train Loss: 6.5650, Val Loss:\n6.1531, SORS: 2.4400', '\\n', 'Epoch 9/50, Train Loss: 6.5368, Val Loss: 6.1482,\nSORS: 2.4387', '\\n', 'Epoch 10/50, Train Loss: 6.5090, Val Loss: 6.1436, SORS:\n2.4375', '\\n', 'Epoch 11/50, Train Loss: 6.4829, Val Loss: 6.1395, SORS:\n2.4363', '\\n', 'Epoch 12/50, Train Loss: 6.4575, Val Loss: 6.1358, SORS:\n2.4352', '\\n', 'Epoch 13/50, Train Loss: 6.4326, Val Loss: 6.1324, SORS:\n2.4341', '\\n', 'Epoch 14/50, Train Loss: 6.4087, Val Loss: 6.1294, SORS:\n2.4330', '\\n', 'Epoch 15/50, Train Loss: 6.3862, Val Loss: 6.1265, SORS:\n2.4320', '\\n', 'Epoch 16/50, Train Loss: 6.3635, Val Loss: 6.1242, SORS:\n2.4311', '\\n', 'Epoch 17/50, Train Loss: 6.3417, Val Loss: 6.1218, SORS:\n2.4301', '\\n', 'Epoch 18/50, Train Loss: 6.3206, Val Loss: 6.1203, SORS:\n2.4294', '\\n', 'Epoch 19/50, Train Loss: 6.2981, Val Loss: 6.1189, SORS:\n2.4286', '\\n', 'Epoch 20/50, Train Loss: 6.2786, Val Loss: 6.1181, SORS:\n2.4279', '\\n', 'Epoch 21/50, Train Loss: 6.2578, Val Loss: 6.1169, SORS:\n2.4272', '\\n', 'Epoch 22/50, Train Loss: 6.2397, Val Loss: 6.1161, SORS:\n2.4266', '\\n', 'Epoch 23/50, Train Loss: 6.2199, Val Loss: 6.1152, SORS:\n2.4260', '\\n', 'Epoch 24/50, Train Loss: 6.2034, Val Loss: 6.1150, SORS:\n2.4255', '\\n', 'Epoch 25/50, Train Loss: 6.1860, Val Loss: 6.1154, SORS:\n2.4250', '\\n', 'Epoch 26/50, Train Loss: 6.1692, Val Loss: 6.1150, SORS:\n2.4246', '\\n', 'Epoch 27/50, Train Loss: 6.1513, Val Loss: 6.1153, SORS:\n2.4241', '\\n', 'Epoch 28/50, Train Loss: 6.1386, Val Loss: 6.1153, SORS:\n2.4237', '\\n', 'Epoch 29/50, Train Loss: 6.1208, Val Loss: 6.1147, SORS:\n2.4232', '\\n', 'Epoch 30/50, Train Loss: 6.1061, Val Loss: 6.1145, SORS:\n2.4228', '\\n', 'Epoch 31/50, Train Loss: 6.0913, Val Loss: 6.1151, SORS:\n2.4225', '\\n', 'Epoch 32/50, Train Loss: 6.0763, Val Loss: 6.1153, SORS:\n2.4222', '\\n', 'Epoch 33/50, Train Loss: 6.0599, Val Loss: 6.1152, SORS:\n2.4218', '\\n', 'Epoch 34/50, Train Loss: 6.0464, Val Loss: 6.1162, SORS:\n2.4216', '\\n', 'Epoch 35/50, Train Loss: 6.0345, Val Loss: 6.1149, SORS:\n2.4209', '\\n', 'Epoch 36/50, Train Loss: 6.0220, Val Loss: 6.1158, SORS:\n2.4207', '\\n', 'Epoch 37/50, Train Loss: 6.0093, Val Loss: 6.1169, SORS:\n2.4205', '\\n', 'Epoch 38/50, Train Loss: 5.9939, Val Loss: 6.1171, SORS:\n2.4202', '\\n', 'Epoch 39/50, Train Loss: 5.9770, Val Loss: 6.1192, SORS:\n2.4201', '\\n', 'Epoch 40/50, Train Loss: 5.9619, Val Loss: 6.1201, SORS:\n2.4200', '\\n', 'Epoch 41/50, Train Loss: 5.9463, Val Loss: 6.1204, SORS:\n2.4197', '\\n', 'Epoch 42/50, Train Loss: 5.9417, Val Loss: 6.1209, SORS:\n2.4195', '\\n', 'Epoch 43/50, Train Loss: 5.9276, Val Loss: 6.1212, SORS:\n2.4193', '\\n', 'Epoch 44/50, Train Loss: 5.9132, Val Loss: 6.1217, SORS:\n2.4190', '\\n', 'Epoch 45/50, Train Loss: 5.8990, Val Loss: 6.1211, SORS:\n2.4186', '\\n', 'Epoch 46/50, Train Loss: 5.8868, Val Loss: 6.1207, SORS:\n2.4184', '\\n', 'Epoch 47/50, Train Loss: 5.8734, Val Loss: 6.1208, SORS:\n2.4180', '\\n', 'Epoch 48/50, Train Loss: 5.8633, Val Loss: 6.1209, SORS:\n2.4178', '\\n', 'Epoch 49/50, Train Loss: 5.8518, Val Loss: 6.1207, SORS:\n2.4174', '\\n', 'Epoch 50/50, Train Loss: 5.8437, Val Loss: 6.1211, SORS:\n2.4173', '\\n', 'Training full_dataset with batch size: 32', '\\n', 'Epoch 1/50,\nTrain Loss: 10.1707, Val Loss: 10.1217, SORS: 2.4759', '\\n', 'Epoch 2/50, Train\nLoss: 8.5165, Val Loss: 8.3449, SORS: 2.4685', '\\n', 'Epoch 3/50, Train Loss:\n7.2613, Val Loss: 6.9286, SORS: 2.4595', '\\n', 'Epoch 4/50, Train Loss: 6.7853,\nVal Loss: 6.2893, SORS: 2.4513', '\\n', 'Epoch 5/50, Train Loss: 6.7926, Val\nLoss: 6.1950, SORS: 2.4460', '\\n', 'Epoch 6/50, Train Loss: 6.8027, Val Loss:\n6.1917, SORS: 2.4442', '\\n', 'Epoch 7/50, Train Loss: 6.7769, Val Loss: 6.1858,\nSORS: 2.4435', '\\n', 'Epoch 8/50, Train Loss: 6.7549, Val Loss: 6.1809, SORS:\n2.4428', '\\n', 'Epoch 9/50, Train Loss: 6.7367, Val Loss: 6.1768, SORS: 2.4420',\n'\\n', 'Epoch 10/50, Train Loss: 6.7198, Val Loss: 6.1731, SORS: 2.4412', '\\n',\n'Epoch 11/50, Train Loss: 6.7031, Val Loss: 6.1696, SORS: 2.4404', '\\n', 'Epoch\n12/50, Train Loss: 6.6869, Val Loss: 6.1662, SORS: 2.4397', '\\n', 'Epoch 13/50,\nTrain Loss: 6.6709, Val Loss: 6.1631, SORS: 2.4390', '\\n', 'Epoch 14/50, Train\nLoss: 6.6551, Val Loss: 6.1603, SORS: 2.4383', '\\n', 'Epoch 15/50, Train Loss:\n6.6401, Val Loss: 6.1577, SORS: 2.4376', '\\n', 'Epoch 16/50, Train Loss: 6.6255,\nVal Loss: 6.1553, SORS: 2.4370', '\\n', 'Epoch 17/50, Train Loss: 6.6112, Val\nLoss: 6.1531, SORS: 2.4364', '\\n', 'Epoch 18/50, Train Loss: 6.5976, Val Loss:\n6.1512, SORS: 2.4358', '\\n', 'Epoch 19/50, Train Loss: 6.5842, Val Loss: 6.1494,\nSORS: 2.4352', '\\n', 'Epoch 20/50, Train Loss: 6.5714, Val Loss: 6.1477, SORS:\n2.4346', '\\n', 'Epoch 21/50, Train Loss: 6.5588, Val Loss: 6.1461, SORS:\n2.4341', '\\n', 'Epoch 22/50, Train Loss: 6.5469, Val Loss: 6.1447, SORS:\n2.4336', '\\n', 'Epoch 23/50, Train Loss: 6.5350, Val Loss: 6.1434, SORS:\n2.4331', '\\n', 'Epoch 24/50, Train Loss: 6.5238, Val Loss: 6.1423, SORS:\n2.4326', '\\n', 'Epoch 25/50, Train Loss: 6.5124, Val Loss: 6.1412, SORS:\n2.4321', '\\n', 'Epoch 26/50, Train Loss: 6.5018, Val Loss: 6.1403, SORS:\n2.4316', '\\n', 'Epoch 27/50, Train Loss: 6.4911, Val Loss: 6.1393, SORS:\n2.4312', '\\n', 'Epoch 28/50, Train Loss: 6.4807, Val Loss: 6.1386, SORS:\n2.4308', '\\n', 'Epoch 29/50, Train Loss: 6.4710, Val Loss: 6.1379, SORS:\n2.4304', '\\n', 'Epoch 30/50, Train Loss: 6.4616, Val Loss: 6.1373, SORS:\n2.4300', '\\n', 'Epoch 31/50, Train Loss: 6.4523, Val Loss: 6.1368, SORS:\n2.4296', '\\n', 'Epoch 32/50, Train Loss: 6.4435, Val Loss: 6.1364, SORS:\n2.4292', '\\n', 'Epoch 33/50, Train Loss: 6.4349, Val Loss: 6.1363, SORS:\n2.4289', '\\n', 'Epoch 34/50, Train Loss: 6.4266, Val Loss: 6.1361, SORS:\n2.4286', '\\n', 'Epoch 35/50, Train Loss: 6.4178, Val Loss: 6.1364, SORS:\n2.4283', '\\n', 'Epoch 36/50, Train Loss: 6.4092, Val Loss: 6.1363, SORS:\n2.4280', '\\n', 'Epoch 37/50, Train Loss: 6.4007, Val Loss: 6.1364, SORS:\n2.4278', '\\n', 'Epoch 38/50, Train Loss: 6.3924, Val Loss: 6.1367, SORS:\n2.4275', '\\n', 'Epoch 39/50, Train Loss: 6.3841, Val Loss: 6.1372, SORS:\n2.4273', '\\n', 'Epoch 40/50, Train Loss: 6.3767, Val Loss: 6.1375, SORS:\n2.4271', '\\n', 'Epoch 41/50, Train Loss: 6.3695, Val Loss: 6.1377, SORS:\n2.4269', '\\n', 'Epoch 42/50, Train Loss: 6.3627, Val Loss: 6.1378, SORS:\n2.4267', '\\n', 'Epoch 43/50, Train Loss: 6.3569, Val Loss: 6.1379, SORS:\n2.4265', '\\n', 'Epoch 44/50, Train Loss: 6.3508, Val Loss: 6.1380, SORS:\n2.4263', '\\n', 'Epoch 45/50, Train Loss: 6.3455, Val Loss: 6.1379, SORS:\n2.4261', '\\n', 'Epoch 46/50, Train Loss: 6.3401, Val Loss: 6.1381, SORS:\n2.4259', '\\n', 'Epoch 47/50, Train Loss: 6.3351, Val Loss: 6.1380, SORS:\n2.4257', '\\n', 'Epoch 48/50, Train Loss: 6.3302, Val Loss: 6.1385, SORS:\n2.4256', '\\n', 'Epoch 49/50, Train Loss: 6.3252, Val Loss: 6.1385, SORS:\n2.4255', '\\n', 'Epoch 50/50, Train Loss: 6.3211, Val Loss: 6.1391, SORS:\n2.4254', '\\n', 'Training full_dataset with batch size: 64', '\\n', 'Epoch 1/50,\nTrain Loss: 11.9955, Val Loss: 12.2566, SORS: 2.4905', '\\n', 'Epoch 2/50, Train\nLoss: 11.2798, Val Loss: 11.4991, SORS: 2.4775', '\\n', 'Epoch 3/50, Train Loss:\n10.5719, Val Loss: 10.7524, SORS: 2.4750', '\\n', 'Epoch 4/50, Train Loss:\n9.8045, Val Loss: 9.9522, SORS: 2.4739', '\\n', 'Epoch 5/50, Train Loss: 8.9488,\nVal Loss: 9.0651, SORS: 2.4716', '\\n', 'Epoch 6/50, Train Loss: 8.0737, Val\nLoss: 8.1449, SORS: 2.4685', '\\n', 'Epoch 7/50, Train Loss: 7.3464, Val Loss:\n7.3325, SORS: 2.4650', '\\n', 'Epoch 8/50, Train Loss: 6.8703, Val Loss: 6.7480,\nSORS: 2.4614', '\\n', 'Epoch 9/50, Train Loss: 6.6518, Val Loss: 6.4180, SORS:\n2.4584', '\\n', 'Epoch 10/50, Train Loss: 6.6103, Val Loss: 6.2806, SORS:\n2.4559', '\\n', 'Epoch 11/50, Train Loss: 6.6407, Val Loss: 6.2440, SORS:\n2.4541', '\\n', 'Epoch 12/50, Train Loss: 6.6698, Val Loss: 6.2395, SORS:\n2.4530', '\\n', 'Epoch 13/50, Train Loss: 6.6774, Val Loss: 6.2389, SORS:\n2.4524', '\\n', 'Epoch 14/50, Train Loss: 6.6710, Val Loss: 6.2371, SORS:\n2.4520', '\\n', 'Epoch 15/50, Train Loss: 6.6602, Val Loss: 6.2350, SORS:\n2.4517', '\\n', 'Epoch 16/50, Train Loss: 6.6496, Val Loss: 6.2329, SORS:\n2.4513', '\\n', 'Epoch 17/50, Train Loss: 6.6405, Val Loss: 6.2309, SORS:\n2.4509', '\\n', 'Epoch 18/50, Train Loss: 6.6323, Val Loss: 6.2291, SORS:\n2.4505', '\\n', 'Epoch 19/50, Train Loss: 6.6245, Val Loss: 6.2273, SORS:\n2.4501', '\\n', 'Epoch 20/50, Train Loss: 6.6169, Val Loss: 6.2255, SORS:\n2.4497', '\\n', 'Epoch 21/50, Train Loss: 6.6092, Val Loss: 6.2238, SORS:\n2.4492', '\\n', 'Epoch 22/50, Train Loss: 6.6014, Val Loss: 6.2220, SORS:\n2.4488', '\\n', 'Epoch 23/50, Train Loss: 6.5935, Val Loss: 6.2203, SORS:\n2.4484', '\\n', 'Epoch 24/50, Train Loss: 6.5855, Val Loss: 6.2186, SORS:\n2.4480', '\\n', 'Epoch 25/50, Train Loss: 6.5776, Val Loss: 6.2169, SORS:\n2.4475', '\\n', 'Epoch 26/50, Train Loss: 6.5696, Val Loss: 6.2152, SORS:\n2.4471', '\\n', 'Epoch 27/50, Train Loss: 6.5616, Val Loss: 6.2136, SORS:\n2.4467', '\\n', 'Epoch 28/50, Train Loss: 6.5537, Val Loss: 6.2120, SORS:\n2.4462', '\\n', 'Epoch 29/50, Train Loss: 6.5457, Val Loss: 6.2103, SORS:\n2.4458', '\\n', 'Epoch 30/50, Train Loss: 6.5380, Val Loss: 6.2087, SORS:\n2.4453', '\\n', 'Epoch 31/50, Train Loss: 6.5303, Val Loss: 6.2071, SORS:\n2.4449', '\\n', 'Epoch 32/50, Train Loss: 6.5226, Val Loss: 6.2055, SORS:\n2.4444', '\\n', 'Epoch 33/50, Train Loss: 6.5150, Val Loss: 6.2039, SORS:\n2.4440', '\\n', 'Epoch 34/50, Train Loss: 6.5075, Val Loss: 6.2024, SORS:\n2.4435', '\\n', 'Epoch 35/50, Train Loss: 6.5000, Val Loss: 6.2008, SORS:\n2.4431', '\\n', 'Epoch 36/50, Train Loss: 6.4923, Val Loss: 6.1994, SORS:\n2.4427', '\\n', 'Epoch 37/50, Train Loss: 6.4847, Val Loss: 6.1979, SORS:\n2.4422', '\\n', 'Epoch 38/50, Train Loss: 6.4771, Val Loss: 6.1965, SORS:\n2.4418', '\\n', 'Epoch 39/50, Train Loss: 6.4693, Val Loss: 6.1951, SORS:\n2.4413', '\\n', 'Epoch 40/50, Train Loss: 6.4619, Val Loss: 6.1937, SORS:\n2.4409', '\\n', 'Epoch 41/50, Train Loss: 6.4549, Val Loss: 6.1923, SORS:\n2.4405', '\\n', 'Epoch 42/50, Train Loss: 6.4479, Val Loss: 6.1910, SORS:\n2.4400', '\\n', 'Epoch 43/50, Train Loss: 6.4408, Val Loss: 6.1897, SORS:\n2.4396', '\\n', 'Epoch 44/50, Train Loss: 6.4337, Val Loss: 6.1885, SORS:\n2.4392', '\\n', 'Epoch 45/50, Train Loss: 6.4267, Val Loss: 6.1872, SORS:\n2.4388', '\\n', 'Epoch 46/50, Train Loss: 6.4199, Val Loss: 6.1860, SORS:\n2.4383', '\\n', 'Epoch 47/50, Train Loss: 6.4132, Val Loss: 6.1848, SORS:\n2.4379', '\\n', 'Epoch 48/50, Train Loss: 6.4065, Val Loss: 6.1837, SORS:\n2.4375', '\\n', 'Epoch 49/50, Train Loss: 6.3998, Val Loss: 6.1826, SORS:\n2.4371', '\\n', 'Epoch 50/50, Train Loss: 6.3934, Val Loss: 6.1815, SORS:\n2.4367', '\\n', 'Training full_dataset with batch size: 128', '\\n', 'Epoch 1/50,\nTrain Loss: 11.0955, Val Loss: 11.3447, SORS: 2.4872', '\\n', 'Epoch 2/50, Train\nLoss: 10.5948, Val Loss: 10.8394, SORS: 2.4863', '\\n', 'Epoch 3/50, Train Loss:\n10.1126, Val Loss: 10.3477, SORS: 2.4849', '\\n', 'Epoch 4/50, Train Loss:\n9.6378, Val Loss: 9.8638, SORS: 2.4834', '\\n', 'Epoch 5/50, Train Loss: 9.1758,\nVal Loss: 9.3842, SORS: 2.4816', '\\n', 'Epoch 6/50, Train Loss: 8.7260, Val\nLoss: 8.9090, SORS: 2.4799', '\\n', 'Epoch 7/50, Train Loss: 8.2874, Val Loss:\n8.4412, SORS: 2.4781', '\\n', 'Epoch 8/50, Train Loss: 7.8796, Val Loss: 7.9923,\nSORS: 2.4764', '\\n', 'Epoch 9/50, Train Loss: 7.5071, Val Loss: 7.5725, SORS:\n2.4741', '\\n', 'Epoch 10/50, Train Loss: 7.1819, Val Loss: 7.1921, SORS:\n2.4711', '\\n', 'Epoch 11/50, Train Loss: 6.9258, Val Loss: 6.8696, SORS:\n2.4677', '\\n', 'Epoch 12/50, Train Loss: 6.7444, Val Loss: 6.6172, SORS:\n2.4646', '\\n', 'Epoch 13/50, Train Loss: 6.6385, Val Loss: 6.4419, SORS:\n2.4622', '\\n', 'Epoch 14/50, Train Loss: 6.5926, Val Loss: 6.3338, SORS:\n2.4601', '\\n', 'Epoch 15/50, Train Loss: 6.5904, Val Loss: 6.2782, SORS:\n2.4583', '\\n', 'Epoch 16/50, Train Loss: 6.6111, Val Loss: 6.2565, SORS:\n2.4568', '\\n', 'Epoch 17/50, Train Loss: 6.6346, Val Loss: 6.2521, SORS:\n2.4558', '\\n', 'Epoch 18/50, Train Loss: 6.6497, Val Loss: 6.2531, SORS:\n2.4551', '\\n', 'Epoch 19/50, Train Loss: 6.6528, Val Loss: 6.2537, SORS:\n2.4546', '\\n', 'Epoch 20/50, Train Loss: 6.6462, Val Loss: 6.2527, SORS:\n2.4542', '\\n', 'Epoch 21/50, Train Loss: 6.6349, Val Loss: 6.2505, SORS:\n2.4539', '\\n', 'Epoch 22/50, Train Loss: 6.6216, Val Loss: 6.2479, SORS:\n2.4536', '\\n', 'Epoch 23/50, Train Loss: 6.6088, Val Loss: 6.2454, SORS:\n2.4532', '\\n', 'Epoch 24/50, Train Loss: 6.5970, Val Loss: 6.2430, SORS:\n2.4528', '\\n', 'Epoch 25/50, Train Loss: 6.5863, Val Loss: 6.2409, SORS:\n2.4524', '\\n', 'Epoch 26/50, Train Loss: 6.5766, Val Loss: 6.2389, SORS:\n2.4520', '\\n', 'Epoch 27/50, Train Loss: 6.5677, Val Loss: 6.2371, SORS:\n2.4516', '\\n', 'Epoch 28/50, Train Loss: 6.5591, Val Loss: 6.2353, SORS:\n2.4511', '\\n', 'Epoch 29/50, Train Loss: 6.5509, Val Loss: 6.2336, SORS:\n2.4507', '\\n', 'Epoch 30/50, Train Loss: 6.5423, Val Loss: 6.2319, SORS:\n2.4502', '\\n', 'Epoch 31/50, Train Loss: 6.5333, Val Loss: 6.2300, SORS:\n2.4497', '\\n', 'Epoch 32/50, Train Loss: 6.5232, Val Loss: 6.2280, SORS:\n2.4492', '\\n', 'Epoch 33/50, Train Loss: 6.5120, Val Loss: 6.2258, SORS:\n2.4487', '\\n', 'Epoch 34/50, Train Loss: 6.5003, Val Loss: 6.2236, SORS:\n2.4481', '\\n', 'Epoch 35/50, Train Loss: 6.4888, Val Loss: 6.2215, SORS:\n2.4476', '\\n', 'Epoch 36/50, Train Loss: 6.4773, Val Loss: 6.2196, SORS:\n2.4471', '\\n', 'Epoch 37/50, Train Loss: 6.4661, Val Loss: 6.2177, SORS:\n2.4466', '\\n', 'Epoch 38/50, Train Loss: 6.4553, Val Loss: 6.2159, SORS:\n2.4461', '\\n', 'Epoch 39/50, Train Loss: 6.4447, Val Loss: 6.2141, SORS:\n2.4455', '\\n', 'Epoch 40/50, Train Loss: 6.4343, Val Loss: 6.2123, SORS:\n2.4450', '\\n', 'Epoch 41/50, Train Loss: 6.4239, Val Loss: 6.2105, SORS:\n2.4445', '\\n', 'Epoch 42/50, Train Loss: 6.4137, Val Loss: 6.2088, SORS:\n2.4439', '\\n', 'Epoch 43/50, Train Loss: 6.4035, Val Loss: 6.2071, SORS:\n2.4434', '\\n', 'Epoch 44/50, Train Loss: 6.3934, Val Loss: 6.2054, SORS:\n2.4429', '\\n', 'Epoch 45/50, Train Loss: 6.3833, Val Loss: 6.2037, SORS:\n2.4423', '\\n', 'Epoch 46/50, Train Loss: 6.3734, Val Loss: 6.2021, SORS:\n2.4418', '\\n', 'Epoch 47/50, Train Loss: 6.3632, Val Loss: 6.2005, SORS:\n2.4413', '\\n', 'Epoch 48/50, Train Loss: 6.3531, Val Loss: 6.1989, SORS:\n2.4407', '\\n', 'Epoch 49/50, Train Loss: 6.3430, Val Loss: 6.1974, SORS:\n2.4402', '\\n', 'Epoch 50/50, Train Loss: 6.3330, Val Loss: 6.1958, SORS:\n2.4397', '\\n', 'Training full_dataset with batch size: 256', '\\n', 'Epoch 1/50,\nTrain Loss: 12.2534, Val Loss: 12.3903, SORS: 2.4964', '\\n', 'Epoch 2/50, Train\nLoss: 12.0336, Val Loss: 12.1734, SORS: 2.4882', '\\n', 'Epoch 3/50, Train Loss:\n11.8116, Val Loss: 11.9537, SORS: 2.4854', '\\n', 'Epoch 4/50, Train Loss:\n11.5856, Val Loss: 11.7286, SORS: 2.4842', '\\n', 'Epoch 5/50, Train Loss:\n11.3532, Val Loss: 11.4972, SORS: 2.4836', '\\n', 'Epoch 6/50, Train Loss:\n11.1188, Val Loss: 11.2588, SORS: 2.4834', '\\n', 'Epoch 7/50, Train Loss:\n10.8754, Val Loss: 11.0118, SORS: 2.4832', '\\n', 'Epoch 8/50, Train Loss:\n10.6256, Val Loss: 10.7554, SORS: 2.4830', '\\n', 'Epoch 9/50, Train Loss:\n10.3692, Val Loss: 10.4896, SORS: 2.4829', '\\n', 'Epoch 10/50, Train Loss:\n10.1024, Val Loss: 10.2119, SORS: 2.4826', '\\n', 'Epoch 11/50, Train Loss:\n9.8220, Val Loss: 9.9228, SORS: 2.4822', '\\n', 'Epoch 12/50, Train Loss: 9.5310,\nVal Loss: 9.6240, SORS: 2.4815', '\\n', 'Epoch 13/50, Train Loss: 9.2361, Val\nLoss: 9.3182, SORS: 2.4807', '\\n', 'Epoch 14/50, Train Loss: 8.9412, Val Loss:\n9.0085, SORS: 2.4799', '\\n', 'Epoch 15/50, Train Loss: 8.6514, Val Loss: 8.6988,\nSORS: 2.4790', '\\n', 'Epoch 16/50, Train Loss: 8.3676, Val Loss: 8.3929, SORS:\n2.4780', '\\n', 'Epoch 17/50, Train Loss: 8.0894, Val Loss: 8.0936, SORS:\n2.4765', '\\n', 'Epoch 18/50, Train Loss: 7.8246, Val Loss: 7.8076, SORS:\n2.4751', '\\n', 'Epoch 19/50, Train Loss: 7.5769, Val Loss: 7.5405, SORS:\n2.4738', '\\n', 'Epoch 20/50, Train Loss: 7.3516, Val Loss: 7.2937, SORS:\n2.4723', '\\n', 'Epoch 21/50, Train Loss: 7.1531, Val Loss: 7.0717, SORS:\n2.4707', '\\n', 'Epoch 22/50, Train Loss: 6.9863, Val Loss: 6.8785, SORS:\n2.4692', '\\n', 'Epoch 23/50, Train Loss: 6.8512, Val Loss: 6.7160, SORS:\n2.4678', '\\n', 'Epoch 24/50, Train Loss: 6.7502, Val Loss: 6.5834, SORS:\n2.4664', '\\n', 'Epoch 25/50, Train Loss: 6.6788, Val Loss: 6.4797, SORS:\n2.4649', '\\n', 'Epoch 26/50, Train Loss: 6.6341, Val Loss: 6.4028, SORS:\n2.4634', '\\n', 'Epoch 27/50, Train Loss: 6.6105, Val Loss: 6.3488, SORS:\n2.4621', '\\n', 'Epoch 28/50, Train Loss: 6.6031, Val Loss: 6.3132, SORS:\n2.4609', '\\n', 'Epoch 29/50, Train Loss: 6.6067, Val Loss: 6.2911, SORS:\n2.4598', '\\n', 'Epoch 30/50, Train Loss: 6.6149, Val Loss: 6.2785, SORS:\n2.4588', '\\n', 'Epoch 31/50, Train Loss: 6.6241, Val Loss: 6.2720, SORS:\n2.4580', '\\n', 'Epoch 32/50, Train Loss: 6.6314, Val Loss: 6.2687, SORS:\n2.4574', '\\n', 'Epoch 33/50, Train Loss: 6.6352, Val Loss: 6.2670, SORS:\n2.4568', '\\n', 'Epoch 34/50, Train Loss: 6.6351, Val Loss: 6.2657, SORS:\n2.4564', '\\n', 'Epoch 35/50, Train Loss: 6.6316, Val Loss: 6.2645, SORS:\n2.4560', '\\n', 'Epoch 36/50, Train Loss: 6.6252, Val Loss: 6.2632, SORS:\n2.4557', '\\n', 'Epoch 37/50, Train Loss: 6.6169, Val Loss: 6.2617, SORS:\n2.4554', '\\n', 'Epoch 38/50, Train Loss: 6.6075, Val Loss: 6.2603, SORS:\n2.4551', '\\n', 'Epoch 39/50, Train Loss: 6.5975, Val Loss: 6.2589, SORS:\n2.4548', '\\n', 'Epoch 40/50, Train Loss: 6.5875, Val Loss: 6.2575, SORS:\n2.4546', '\\n', 'Epoch 41/50, Train Loss: 6.5776, Val Loss: 6.2562, SORS:\n2.4543', '\\n', 'Epoch 42/50, Train Loss: 6.5679, Val Loss: 6.2550, SORS:\n2.4540', '\\n', 'Epoch 43/50, Train Loss: 6.5586, Val Loss: 6.2537, SORS:\n2.4537', '\\n', 'Epoch 44/50, Train Loss: 6.5495, Val Loss: 6.2524, SORS:\n2.4534', '\\n', 'Epoch 45/50, Train Loss: 6.5405, Val Loss: 6.2511, SORS:\n2.4530', '\\n', 'Epoch 46/50, Train Loss: 6.5319, Val Loss: 6.2496, SORS:\n2.4526', '\\n', 'Epoch 47/50, Train Loss: 6.5230, Val Loss: 6.2481, SORS:\n2.4522', '\\n', 'Epoch 48/50, Train Loss: 6.5140, Val Loss: 6.2465, SORS:\n2.4518', '\\n', 'Epoch 49/50, Train Loss: 6.5051, Val Loss: 6.2448, SORS:\n2.4513', '\\n', 'Epoch 50/50, Train Loss: 6.4958, Val Loss: 6.2430, SORS:\n2.4509', '\\n', 'Training pca_5d with batch size: 16', '\\n', 'Epoch 1/50, Train\nLoss: 11.9054, Val Loss: 10.3307, SORS: 2.4736', '\\n', 'Epoch 2/50, Train Loss:\n10.4597, Val Loss: 8.9241, SORS: 2.4741', '\\n', 'Epoch 3/50, Train Loss: 9.1862,\nVal Loss: 7.7175, SORS: 2.4723', '\\n', 'Epoch 4/50, Train Loss: 8.2369, Val\nLoss: 6.9064, SORS: 2.4692', '\\n', 'Epoch 5/50, Train Loss: 7.6584, Val Loss:\n6.5309, SORS: 2.4664', '\\n', 'Epoch 6/50, Train Loss: 7.3572, Val Loss: 6.4180,\nSORS: 2.4639', '\\n', 'Epoch 7/50, Train Loss: 7.1812, Val Loss: 6.3947, SORS:\n2.4619', '\\n', 'Epoch 8/50, Train Loss: 7.0542, Val Loss: 6.3900, SORS: 2.4602',\n'\\n', 'Epoch 9/50, Train Loss: 6.9526, Val Loss: 6.3888, SORS: 2.4590', '\\n',\n'Epoch 10/50, Train Loss: 6.8702, Val Loss: 6.3889, SORS: 2.4580', '\\n', 'Epoch\n11/50, Train Loss: 6.8014, Val Loss: 6.3901, SORS: 2.4572', '\\n', 'Epoch 12/50,\nTrain Loss: 6.7442, Val Loss: 6.3922, SORS: 2.4567', '\\n', 'Epoch 13/50, Train\nLoss: 6.6960, Val Loss: 6.3946, SORS: 2.4563', '\\n', 'Epoch 14/50, Train Loss:\n6.6557, Val Loss: 6.3974, SORS: 2.4559', '\\n', 'Epoch 15/50, Train Loss: 6.6220,\nVal Loss: 6.4001, SORS: 2.4557', '\\n', 'Epoch 16/50, Train Loss: 6.5930, Val\nLoss: 6.4028, SORS: 2.4555', '\\n', 'Epoch 17/50, Train Loss: 6.5683, Val Loss:\n6.4053, SORS: 2.4554', '\\n', 'Epoch 18/50, Train Loss: 6.5462, Val Loss: 6.4077,\nSORS: 2.4553', '\\n', 'Epoch 19/50, Train Loss: 6.5271, Val Loss: 6.4101, SORS:\n2.4553', '\\n', 'Epoch 20/50, Train Loss: 6.5105, Val Loss: 6.4127, SORS:\n2.4554', '\\n', 'Epoch 21/50, Train Loss: 6.4959, Val Loss: 6.4151, SORS:\n2.4555', '\\n', 'Epoch 22/50, Train Loss: 6.4835, Val Loss: 6.4173, SORS:\n2.4556', '\\n', 'Epoch 23/50, Train Loss: 6.4728, Val Loss: 6.4194, SORS:\n2.4557', '\\n', 'Epoch 24/50, Train Loss: 6.4633, Val Loss: 6.4216, SORS:\n2.4559', '\\n', 'Epoch 25/50, Train Loss: 6.4551, Val Loss: 6.4234, SORS:\n2.4561', '\\n', 'Epoch 26/50, Train Loss: 6.4481, Val Loss: 6.4252, SORS:\n2.4563', '\\n', 'Epoch 27/50, Train Loss: 6.4411, Val Loss: 6.4270, SORS:\n2.4564', '\\n', 'Epoch 28/50, Train Loss: 6.4352, Val Loss: 6.4285, SORS:\n2.4566', '\\n', 'Epoch 29/50, Train Loss: 6.4297, Val Loss: 6.4302, SORS:\n2.4567', '\\n', 'Epoch 30/50, Train Loss: 6.4241, Val Loss: 6.4317, SORS:\n2.4569', '\\n', 'Epoch 31/50, Train Loss: 6.4183, Val Loss: 6.4333, SORS:\n2.4571', '\\n', 'Epoch 32/50, Train Loss: 6.4134, Val Loss: 6.4350, SORS:\n2.4574', '\\n', 'Epoch 33/50, Train Loss: 6.4080, Val Loss: 6.4366, SORS:\n2.4576', '\\n', 'Epoch 34/50, Train Loss: 6.4033, Val Loss: 6.4386, SORS:\n2.4579', '\\n', 'Epoch 35/50, Train Loss: 6.4002, Val Loss: 6.4399, SORS:\n2.4582', '\\n', 'Epoch 36/50, Train Loss: 6.3974, Val Loss: 6.4415, SORS:\n2.4584', '\\n', 'Epoch 37/50, Train Loss: 6.3950, Val Loss: 6.4428, SORS:\n2.4587', '\\n', 'Epoch 38/50, Train Loss: 6.3922, Val Loss: 6.4443, SORS:\n2.4589', '\\n', 'Epoch 39/50, Train Loss: 6.3903, Val Loss: 6.4452, SORS:\n2.4591', '\\n', 'Epoch 40/50, Train Loss: 6.3874, Val Loss: 6.4461, SORS:\n2.4592', '\\n', 'Epoch 41/50, Train Loss: 6.3847, Val Loss: 6.4476, SORS:\n2.4595', '\\n', 'Epoch 42/50, Train Loss: 6.3811, Val Loss: 6.4485, SORS:\n2.4596', '\\n', 'Epoch 43/50, Train Loss: 6.3780, Val Loss: 6.4498, SORS:\n2.4599', '\\n', 'Epoch 44/50, Train Loss: 6.3755, Val Loss: 6.4510, SORS:\n2.4601', '\\n', 'Epoch 45/50, Train Loss: 6.3726, Val Loss: 6.4520, SORS:\n2.4603', '\\n', 'Epoch 46/50, Train Loss: 6.3704, Val Loss: 6.4535, SORS:\n2.4606', '\\n', 'Epoch 47/50, Train Loss: 6.3674, Val Loss: 6.4544, SORS:\n2.4607', '\\n', 'Epoch 48/50, Train Loss: 6.3654, Val Loss: 6.4555, SORS:\n2.4609', '\\n', 'Epoch 49/50, Train Loss: 6.3633, Val Loss: 6.4569, SORS:\n2.4613', '\\n', 'Epoch 50/50, Train Loss: 6.3612, Val Loss: 6.4576, SORS:\n2.4614', '\\n', 'Training pca_5d with batch size: 32', '\\n', 'Epoch 1/50, Train\nLoss: 11.4491, Val Loss: 11.6912, SORS: 2.4819', '\\n', 'Epoch 2/50, Train Loss:\n10.7620, Val Loss: 10.9611, SORS: 2.4802', '\\n', 'Epoch 3/50, Train Loss:\n10.0815, Val Loss: 10.2481, SORS: 2.4803', '\\n', 'Epoch 4/50, Train Loss:\n9.4019, Val Loss: 9.5449, SORS: 2.4803', '\\n', 'Epoch 5/50, Train Loss: 8.7340,\nVal Loss: 8.8654, SORS: 2.4807', '\\n', 'Epoch 6/50, Train Loss: 8.1040, Val\nLoss: 8.2322, SORS: 2.4809', '\\n', 'Epoch 7/50, Train Loss: 7.5423, Val Loss:\n7.6751, SORS: 2.4807', '\\n', 'Epoch 8/50, Train Loss: 7.0881, Val Loss: 7.2258,\nSORS: 2.4806', '\\n', 'Epoch 9/50, Train Loss: 6.7574, Val Loss: 6.8960, SORS:\n2.4798', '\\n', 'Epoch 10/50, Train Loss: 6.5488, Val Loss: 6.6840, SORS:\n2.4786', '\\n', 'Epoch 11/50, Train Loss: 6.4342, Val Loss: 6.5671, SORS:\n2.4774', '\\n', 'Epoch 12/50, Train Loss: 6.3829, Val Loss: 6.5118, SORS:\n2.4760', '\\n', 'Epoch 13/50, Train Loss: 6.3603, Val Loss: 6.4882, SORS:\n2.4743', '\\n', 'Epoch 14/50, Train Loss: 6.3496, Val Loss: 6.4783, SORS:\n2.4726', '\\n', 'Epoch 15/50, Train Loss: 6.3416, Val Loss: 6.4731, SORS:\n2.4710', '\\n', 'Epoch 16/50, Train Loss: 6.3331, Val Loss: 6.4693, SORS:\n2.4696', '\\n', 'Epoch 17/50, Train Loss: 6.3242, Val Loss: 6.4657, SORS:\n2.4683', '\\n', 'Epoch 18/50, Train Loss: 6.3158, Val Loss: 6.4623, SORS:\n2.4672', '\\n', 'Epoch 19/50, Train Loss: 6.3076, Val Loss: 6.4591, SORS:\n2.4662', '\\n', 'Epoch 20/50, Train Loss: 6.2997, Val Loss: 6.4562, SORS:\n2.4654', '\\n', 'Epoch 21/50, Train Loss: 6.2923, Val Loss: 6.4536, SORS:\n2.4646', '\\n', 'Epoch 22/50, Train Loss: 6.2858, Val Loss: 6.4513, SORS:\n2.4639', '\\n', 'Epoch 23/50, Train Loss: 6.2798, Val Loss: 6.4493, SORS:\n2.4634', '\\n', 'Epoch 24/50, Train Loss: 6.2745, Val Loss: 6.4477, SORS:\n2.4629', '\\n', 'Epoch 25/50, Train Loss: 6.2700, Val Loss: 6.4465, SORS:\n2.4625', '\\n', 'Epoch 26/50, Train Loss: 6.2660, Val Loss: 6.4455, SORS:\n2.4622', '\\n', 'Epoch 27/50, Train Loss: 6.2621, Val Loss: 6.4448, SORS:\n2.4619', '\\n', 'Epoch 28/50, Train Loss: 6.2586, Val Loss: 6.4442, SORS:\n2.4616', '\\n', 'Epoch 29/50, Train Loss: 6.2554, Val Loss: 6.4438, SORS:\n2.4615', '\\n', 'Epoch 30/50, Train Loss: 6.2524, Val Loss: 6.4434, SORS:\n2.4613', '\\n', 'Epoch 31/50, Train Loss: 6.2493, Val Loss: 6.4430, SORS:\n2.4611', '\\n', 'Epoch 32/50, Train Loss: 6.2465, Val Loss: 6.4426, SORS:\n2.4610', '\\n', 'Epoch 33/50, Train Loss: 6.2439, Val Loss: 6.4423, SORS:\n2.4608', '\\n', 'Epoch 34/50, Train Loss: 6.2417, Val Loss: 6.4421, SORS:\n2.4607', '\\n', 'Epoch 35/50, Train Loss: 6.2397, Val Loss: 6.4419, SORS:\n2.4607', '\\n', 'Epoch 36/50, Train Loss: 6.2377, Val Loss: 6.4418, SORS:\n2.4606', '\\n', 'Epoch 37/50, Train Loss: 6.2358, Val Loss: 6.4419, SORS:\n2.4605', '\\n', 'Epoch 38/50, Train Loss: 6.2338, Val Loss: 6.4419, SORS:\n2.4605', '\\n', 'Epoch 39/50, Train Loss: 6.2319, Val Loss: 6.4419, SORS:\n2.4605', '\\n', 'Epoch 40/50, Train Loss: 6.2304, Val Loss: 6.4419, SORS:\n2.4604', '\\n', 'Epoch 41/50, Train Loss: 6.2288, Val Loss: 6.4419, SORS:\n2.4604', '\\n', 'Epoch 42/50, Train Loss: 6.2272, Val Loss: 6.4419, SORS:\n2.4603', '\\n', 'Epoch 43/50, Train Loss: 6.2255, Val Loss: 6.4418, SORS:\n2.4603', '\\n', 'Epoch 44/50, Train Loss: 6.2237, Val Loss: 6.4417, SORS:\n2.4602', '\\n', 'Epoch 45/50, Train Loss: 6.2219, Val Loss: 6.4416, SORS:\n2.4601', '\\n', 'Epoch 46/50, Train Loss: 6.2201, Val Loss: 6.4414, SORS:\n2.4600', '\\n', 'Epoch 47/50, Train Loss: 6.2183, Val Loss: 6.4413, SORS:\n2.4600', '\\n', 'Epoch 48/50, Train Loss: 6.2163, Val Loss: 6.4410, SORS:\n2.4599', '\\n', 'Epoch 49/50, Train Loss: 6.2143, Val Loss: 6.4407, SORS:\n2.4598', '\\n', 'Epoch 50/50, Train Loss: 6.2121, Val Loss: 6.4405, SORS:\n2.4597', '\\n', 'Training pca_5d with batch size: 64', '\\n', 'Epoch 1/50, Train\nLoss: 12.7110, Val Loss: 12.9090, SORS: 2.5447', '\\n', 'Epoch 2/50, Train Loss:\n12.2161, Val Loss: 12.4215, SORS: 2.4993', '\\n', 'Epoch 3/50, Train Loss:\n11.7341, Val Loss: 11.9473, SORS: 2.4875', '\\n', 'Epoch 4/50, Train Loss:\n11.2557, Val Loss: 11.4767, SORS: 2.4866', '\\n', 'Epoch 5/50, Train Loss:\n10.7750, Val Loss: 11.0039, SORS: 2.4863', '\\n', 'Epoch 6/50, Train Loss:\n10.2924, Val Loss: 10.5277, SORS: 2.4862', '\\n', 'Epoch 7/50, Train Loss:\n9.8094, Val Loss: 10.0523, SORS: 2.4860', '\\n', 'Epoch 8/50, Train Loss: 9.3310,\nVal Loss: 9.5840, SORS: 2.4856', '\\n', 'Epoch 9/50, Train Loss: 8.8654, Val\nLoss: 9.1284, SORS: 2.4851', '\\n', 'Epoch 10/50, Train Loss: 8.4193, Val Loss:\n8.6940, SORS: 2.4844', '\\n', 'Epoch 11/50, Train Loss: 8.0026, Val Loss: 8.2882,\nSORS: 2.4833', '\\n', 'Epoch 12/50, Train Loss: 7.6226, Val Loss: 7.9176, SORS:\n2.4817', '\\n', 'Epoch 13/50, Train Loss: 7.2855, Val Loss: 7.5883, SORS:\n2.4796', '\\n', 'Epoch 14/50, Train Loss: 6.9972, Val Loss: 7.3059, SORS:\n2.4774', '\\n', 'Epoch 15/50, Train Loss: 6.7575, Val Loss: 7.0727, SORS:\n2.4750', '\\n', 'Epoch 16/50, Train Loss: 6.5666, Val Loss: 6.8871, SORS:\n2.4726', '\\n', 'Epoch 17/50, Train Loss: 6.4211, Val Loss: 6.7464, SORS:\n2.4704', '\\n', 'Epoch 18/50, Train Loss: 6.3160, Val Loss: 6.6439, SORS:\n2.4682', '\\n', 'Epoch 19/50, Train Loss: 6.2432, Val Loss: 6.5727, SORS:\n2.4661', '\\n', 'Epoch 20/50, Train Loss: 6.1957, Val Loss: 6.5254, SORS:\n2.4642', '\\n', 'Epoch 21/50, Train Loss: 6.1661, Val Loss: 6.4953, SORS:\n2.4627', '\\n', 'Epoch 22/50, Train Loss: 6.1477, Val Loss: 6.4765, SORS:\n2.4613', '\\n', 'Epoch 23/50, Train Loss: 6.1362, Val Loss: 6.4647, SORS:\n2.4602', '\\n', 'Epoch 24/50, Train Loss: 6.1287, Val Loss: 6.4570, SORS:\n2.4593', '\\n', 'Epoch 25/50, Train Loss: 6.1237, Val Loss: 6.4515, SORS:\n2.4584', '\\n', 'Epoch 26/50, Train Loss: 6.1200, Val Loss: 6.4472, SORS:\n2.4577', '\\n', 'Epoch 27/50, Train Loss: 6.1164, Val Loss: 6.4437, SORS:\n2.4571', '\\n', 'Epoch 28/50, Train Loss: 6.1130, Val Loss: 6.4407, SORS:\n2.4565', '\\n', 'Epoch 29/50, Train Loss: 6.1096, Val Loss: 6.4378, SORS:\n2.4560', '\\n', 'Epoch 30/50, Train Loss: 6.1059, Val Loss: 6.4353, SORS:\n2.4556', '\\n', 'Epoch 31/50, Train Loss: 6.1020, Val Loss: 6.4330, SORS:\n2.4552', '\\n', 'Epoch 32/50, Train Loss: 6.0981, Val Loss: 6.4309, SORS:\n2.4548', '\\n', 'Epoch 33/50, Train Loss: 6.0943, Val Loss: 6.4290, SORS:\n2.4545', '\\n', 'Epoch 34/50, Train Loss: 6.0906, Val Loss: 6.4273, SORS:\n2.4542', '\\n', 'Epoch 35/50, Train Loss: 6.0871, Val Loss: 6.4259, SORS:\n2.4540', '\\n', 'Epoch 36/50, Train Loss: 6.0837, Val Loss: 6.4246, SORS:\n2.4538', '\\n', 'Epoch 37/50, Train Loss: 6.0802, Val Loss: 6.4235, SORS:\n2.4536', '\\n', 'Epoch 38/50, Train Loss: 6.0767, Val Loss: 6.4224, SORS:\n2.4534', '\\n', 'Epoch 39/50, Train Loss: 6.0733, Val Loss: 6.4214, SORS:\n2.4532', '\\n', 'Epoch 40/50, Train Loss: 6.0699, Val Loss: 6.4206, SORS:\n2.4530', '\\n', 'Epoch 41/50, Train Loss: 6.0666, Val Loss: 6.4199, SORS:\n2.4529', '\\n', 'Epoch 42/50, Train Loss: 6.0634, Val Loss: 6.4193, SORS:\n2.4528', '\\n', 'Epoch 43/50, Train Loss: 6.0602, Val Loss: 6.4188, SORS:\n2.4526', '\\n', 'Epoch 44/50, Train Loss: 6.0570, Val Loss: 6.4184, SORS:\n2.4526', '\\n', 'Epoch 45/50, Train Loss: 6.0538, Val Loss: 6.4181, SORS:\n2.4525', '\\n', 'Epoch 46/50, Train Loss: 6.0504, Val Loss: 6.4179, SORS:\n2.4524', '\\n', 'Epoch 47/50, Train Loss: 6.0467, Val Loss: 6.4178, SORS:\n2.4524', '\\n', 'Epoch 48/50, Train Loss: 6.0426, Val Loss: 6.4180, SORS:\n2.4525', '\\n', 'Epoch 49/50, Train Loss: 6.0384, Val Loss: 6.4183, SORS:\n2.4525', '\\n', 'Epoch 50/50, Train Loss: 6.0342, Val Loss: 6.4188, SORS:\n2.4526', '\\n', 'Training pca_5d with batch size: 128', '\\n', 'Epoch 1/50, Train\nLoss: 11.9778, Val Loss: 12.2530, SORS: 2.4961', '\\n', 'Epoch 2/50, Train Loss:\n11.7595, Val Loss: 12.0215, SORS: 2.4903', '\\n', 'Epoch 3/50, Train Loss:\n11.5456, Val Loss: 11.7949, SORS: 2.4878', '\\n', 'Epoch 4/50, Train Loss:\n11.3359, Val Loss: 11.5723, SORS: 2.4867', '\\n', 'Epoch 5/50, Train Loss:\n11.1290, Val Loss: 11.3526, SORS: 2.4858', '\\n', 'Epoch 6/50, Train Loss:\n10.9236, Val Loss: 11.1347, SORS: 2.4853', '\\n', 'Epoch 7/50, Train Loss:\n10.7186, Val Loss: 10.9173, SORS: 2.4848', '\\n', 'Epoch 8/50, Train Loss:\n10.5123, Val Loss: 10.6995, SORS: 2.4843', '\\n', 'Epoch 9/50, Train Loss:\n10.3048, Val Loss: 10.4808, SORS: 2.4836', '\\n', 'Epoch 10/50, Train Loss:\n10.0966, Val Loss: 10.2612, SORS: 2.4829', '\\n', 'Epoch 11/50, Train Loss:\n9.8876, Val Loss: 10.0403, SORS: 2.4821', '\\n', 'Epoch 12/50, Train Loss:\n9.6778, Val Loss: 9.8181, SORS: 2.4812', '\\n', 'Epoch 13/50, Train Loss: 9.4669,\nVal Loss: 9.5958, SORS: 2.4802', '\\n', 'Epoch 14/50, Train Loss: 9.2546, Val\nLoss: 9.3736, SORS: 2.4791', '\\n', 'Epoch 15/50, Train Loss: 9.0414, Val Loss:\n9.1523, SORS: 2.4780', '\\n', 'Epoch 16/50, Train Loss: 8.8276, Val Loss: 8.9334,\nSORS: 2.4769', '\\n', 'Epoch 17/50, Train Loss: 8.6155, Val Loss: 8.7173, SORS:\n2.4758', '\\n', 'Epoch 18/50, Train Loss: 8.4077, Val Loss: 8.5059, SORS:\n2.4745', '\\n', 'Epoch 19/50, Train Loss: 8.2036, Val Loss: 8.3007, SORS:\n2.4733', '\\n', 'Epoch 20/50, Train Loss: 8.0042, Val Loss: 8.1021, SORS:\n2.4719', '\\n', 'Epoch 21/50, Train Loss: 7.8104, Val Loss: 7.9108, SORS:\n2.4704', '\\n', 'Epoch 22/50, Train Loss: 7.6231, Val Loss: 7.7291, SORS:\n2.4688', '\\n', 'Epoch 23/50, Train Loss: 7.4424, Val Loss: 7.5582, SORS:\n2.4671', '\\n', 'Epoch 24/50, Train Loss: 7.2703, Val Loss: 7.3992, SORS:\n2.4655', '\\n', 'Epoch 25/50, Train Loss: 7.1102, Val Loss: 7.2529, SORS:\n2.4640', '\\n', 'Epoch 26/50, Train Loss: 6.9627, Val Loss: 7.1197, SORS:\n2.4624', '\\n', 'Epoch 27/50, Train Loss: 6.8291, Val Loss: 7.0001, SORS:\n2.4608', '\\n', 'Epoch 28/50, Train Loss: 6.7090, Val Loss: 6.8941, SORS:\n2.4592', '\\n', 'Epoch 29/50, Train Loss: 6.6014, Val Loss: 6.8016, SORS:\n2.4576', '\\n', 'Epoch 30/50, Train Loss: 6.5061, Val Loss: 6.7220, SORS:\n2.4561', '\\n', 'Epoch 31/50, Train Loss: 6.4223, Val Loss: 6.6547, SORS:\n2.4547', '\\n', 'Epoch 32/50, Train Loss: 6.3498, Val Loss: 6.5990, SORS:\n2.4534', '\\n', 'Epoch 33/50, Train Loss: 6.2868, Val Loss: 6.5536, SORS:\n2.4522', '\\n', 'Epoch 34/50, Train Loss: 6.2334, Val Loss: 6.5173, SORS:\n2.4511', '\\n', 'Epoch 35/50, Train Loss: 6.1888, Val Loss: 6.4889, SORS:\n2.4501', '\\n', 'Epoch 36/50, Train Loss: 6.1521, Val Loss: 6.4675, SORS:\n2.4492', '\\n', 'Epoch 37/50, Train Loss: 6.1215, Val Loss: 6.4517, SORS:\n2.4485', '\\n', 'Epoch 38/50, Train Loss: 6.0957, Val Loss: 6.4405, SORS:\n2.4478', '\\n', 'Epoch 39/50, Train Loss: 6.0739, Val Loss: 6.4328, SORS:\n2.4473', '\\n', 'Epoch 40/50, Train Loss: 6.0556, Val Loss: 6.4278, SORS:\n2.4468', '\\n', 'Epoch 41/50, Train Loss: 6.0402, Val Loss: 6.4249, SORS:\n2.4464', '\\n', 'Epoch 42/50, Train Loss: 6.0269, Val Loss: 6.4234, SORS:\n2.4460', '\\n', 'Epoch 43/50, Train Loss: 6.0152, Val Loss: 6.4230, SORS:\n2.4458', '\\n', 'Epoch 44/50, Train Loss: 6.0046, Val Loss: 6.4234, SORS:\n2.4456', '\\n', 'Epoch 45/50, Train Loss: 5.9951, Val Loss: 6.4242, SORS:\n2.4454', '\\n', 'Epoch 46/50, Train Loss: 5.9864, Val Loss: 6.4252, SORS:\n2.4453', '\\n', 'Epoch 47/50, Train Loss: 5.9784, Val Loss: 6.4264, SORS:\n2.4452', '\\n', 'Epoch 48/50, Train Loss: 5.9708, Val Loss: 6.4277, SORS:\n2.4452', '\\n', 'Epoch 49/50, Train Loss: 5.9637, Val Loss: 6.4289, SORS:\n2.4452', '\\n', 'Epoch 50/50, Train Loss: 5.9569, Val Loss: 6.4302, SORS:\n2.4452', '\\n', 'Training pca_5d with batch size: 256', '\\n', 'Epoch 1/50, Train\nLoss: 11.1479, Val Loss: 11.3527, SORS: 2.4726', '\\n', 'Epoch 2/50, Train Loss:\n11.0147, Val Loss: 11.2190, SORS: 2.4715', '\\n', 'Epoch 3/50, Train Loss:\n10.8830, Val Loss: 11.0869, SORS: 2.4707', '\\n', 'Epoch 4/50, Train Loss:\n10.7528, Val Loss: 10.9564, SORS: 2.4701', '\\n', 'Epoch 5/50, Train Loss:\n10.6239, Val Loss: 10.8274, SORS: 2.4695', '\\n', 'Epoch 6/50, Train Loss:\n10.4962, Val Loss: 10.6998, SORS: 2.4689', '\\n', 'Epoch 7/50, Train Loss:\n10.3696, Val Loss: 10.5733, SORS: 2.4683', '\\n', 'Epoch 8/50, Train Loss:\n10.2435, Val Loss: 10.4479, SORS: 2.4676', '\\n', 'Epoch 9/50, Train Loss:\n10.1180, Val Loss: 10.3234, SORS: 2.4669', '\\n', 'Epoch 10/50, Train Loss:\n9.9926, Val Loss: 10.1995, SORS: 2.4663', '\\n', 'Epoch 11/50, Train Loss:\n9.8674, Val Loss: 10.0760, SORS: 2.4656', '\\n', 'Epoch 12/50, Train Loss:\n9.7420, Val Loss: 9.9528, SORS: 2.4649', '\\n', 'Epoch 13/50, Train Loss: 9.6159,\nVal Loss: 9.8298, SORS: 2.4642', '\\n', 'Epoch 14/50, Train Loss: 9.4885, Val\nLoss: 9.7070, SORS: 2.4635', '\\n', 'Epoch 15/50, Train Loss: 9.3600, Val Loss:\n9.5844, SORS: 2.4627', '\\n', 'Epoch 16/50, Train Loss: 9.2310, Val Loss: 9.4620,\nSORS: 2.4620', '\\n', 'Epoch 17/50, Train Loss: 9.1016, Val Loss: 9.3397, SORS:\n2.4612', '\\n', 'Epoch 18/50, Train Loss: 8.9716, Val Loss: 9.2177, SORS:\n2.4603', '\\n', 'Epoch 19/50, Train Loss: 8.8407, Val Loss: 9.0962, SORS:\n2.4595', '\\n', 'Epoch 20/50, Train Loss: 8.7092, Val Loss: 8.9753, SORS:\n2.4587', '\\n', 'Epoch 21/50, Train Loss: 8.5774, Val Loss: 8.8553, SORS:\n2.4579', '\\n', 'Epoch 22/50, Train Loss: 8.4448, Val Loss: 8.7363, SORS:\n2.4570', '\\n', 'Epoch 23/50, Train Loss: 8.3125, Val Loss: 8.6183, SORS:\n2.4561', '\\n', 'Epoch 24/50, Train Loss: 8.1806, Val Loss: 8.5016, SORS:\n2.4553', '\\n', 'Epoch 25/50, Train Loss: 8.0494, Val Loss: 8.3865, SORS:\n2.4544', '\\n', 'Epoch 26/50, Train Loss: 7.9195, Val Loss: 8.2732, SORS:\n2.4535', '\\n', 'Epoch 27/50, Train Loss: 7.7912, Val Loss: 8.1621, SORS:\n2.4526', '\\n', 'Epoch 28/50, Train Loss: 7.6647, Val Loss: 8.0535, SORS:\n2.4517', '\\n', 'Epoch 29/50, Train Loss: 7.5401, Val Loss: 7.9476, SORS:\n2.4508', '\\n', 'Epoch 30/50, Train Loss: 7.4172, Val Loss: 7.8446, SORS:\n2.4499', '\\n', 'Epoch 31/50, Train Loss: 7.2969, Val Loss: 7.7445, SORS:\n2.4491', '\\n', 'Epoch 32/50, Train Loss: 7.1793, Val Loss: 7.6476, SORS:\n2.4482', '\\n', 'Epoch 33/50, Train Loss: 7.0643, Val Loss: 7.5542, SORS:\n2.4473', '\\n', 'Epoch 34/50, Train Loss: 6.9526, Val Loss: 7.4644, SORS:\n2.4465', '\\n', 'Epoch 35/50, Train Loss: 6.8450, Val Loss: 7.3786, SORS:\n2.4457', '\\n', 'Epoch 36/50, Train Loss: 6.7417, Val Loss: 7.2967, SORS:\n2.4449', '\\n', 'Epoch 37/50, Train Loss: 6.6429, Val Loss: 7.2192, SORS:\n2.4441', '\\n', 'Epoch 38/50, Train Loss: 6.5489, Val Loss: 7.1462, SORS:\n2.4433', '\\n', 'Epoch 39/50, Train Loss: 6.4598, Val Loss: 7.0779, SORS:\n2.4427', '\\n', 'Epoch 40/50, Train Loss: 6.3754, Val Loss: 7.0141, SORS:\n2.4420', '\\n', 'Epoch 41/50, Train Loss: 6.2958, Val Loss: 6.9550, SORS:\n2.4414', '\\n', 'Epoch 42/50, Train Loss: 6.2210, Val Loss: 6.9004, SORS:\n2.4408', '\\n', 'Epoch 43/50, Train Loss: 6.1511, Val Loss: 6.8501, SORS:\n2.4402', '\\n', 'Epoch 44/50, Train Loss: 6.0862, Val Loss: 6.8041, SORS:\n2.4397', '\\n', 'Epoch 45/50, Train Loss: 6.0260, Val Loss: 6.7623, SORS:\n2.4391', '\\n', 'Epoch 46/50, Train Loss: 5.9705, Val Loss: 6.7245, SORS:\n2.4385', '\\n', 'Epoch 47/50, Train Loss: 5.9193, Val Loss: 6.6907, SORS:\n2.4380', '\\n', 'Epoch 48/50, Train Loss: 5.8728, Val Loss: 6.6606, SORS:\n2.4375', '\\n', 'Epoch 49/50, Train Loss: 5.8306, Val Loss: 6.6341, SORS:\n2.4371', '\\n', 'Epoch 50/50, Train Loss: 5.7923, Val Loss: 6.6109, SORS:\n2.4367', '\\n', 'Training pca_3d with batch size: 16', '\\n', 'Epoch 1/50, Train\nLoss: 12.3977, Val Loss: 10.9648, SORS: 2.4817', '\\n', 'Epoch 2/50, Train Loss:\n10.8163, Val Loss: 9.5053, SORS: 2.4765', '\\n', 'Epoch 3/50, Train Loss: 9.4395,\nVal Loss: 8.2628, SORS: 2.4704', '\\n', 'Epoch 4/50, Train Loss: 8.3738, Val\nLoss: 7.3385, SORS: 2.4625', '\\n', 'Epoch 5/50, Train Loss: 7.6663, Val Loss:\n6.7891, SORS: 2.4545', '\\n', 'Epoch 6/50, Train Loss: 7.2795, Val Loss: 6.5446,\nSORS: 2.4483', '\\n', 'Epoch 7/50, Train Loss: 7.1006, Val Loss: 6.4637, SORS:\n2.4451', '\\n', 'Epoch 8/50, Train Loss: 7.0220, Val Loss: 6.4381, SORS: 2.4437',\n'\\n', 'Epoch 9/50, Train Loss: 6.9876, Val Loss: 6.4274, SORS: 2.4435', '\\n',\n'Epoch 10/50, Train Loss: 6.9700, Val Loss: 6.4206, SORS: 2.4438', '\\n', 'Epoch\n11/50, Train Loss: 6.9595, Val Loss: 6.4154, SORS: 2.4442', '\\n', 'Epoch 12/50,\nTrain Loss: 6.9531, Val Loss: 6.4112, SORS: 2.4447', '\\n', 'Epoch 13/50, Train\nLoss: 6.9490, Val Loss: 6.4078, SORS: 2.4450', '\\n', 'Epoch 14/50, Train Loss:\n6.9465, Val Loss: 6.4051, SORS: 2.4454', '\\n', 'Epoch 15/50, Train Loss: 6.9448,\nVal Loss: 6.4029, SORS: 2.4457', '\\n', 'Epoch 16/50, Train Loss: 6.9428, Val\nLoss: 6.4010, SORS: 2.4459', '\\n', 'Epoch 17/50, Train Loss: 6.9411, Val Loss:\n6.3996, SORS: 2.4462', '\\n', 'Epoch 18/50, Train Loss: 6.9394, Val Loss: 6.3982,\nSORS: 2.4463', '\\n', 'Epoch 19/50, Train Loss: 6.9384, Val Loss: 6.3972, SORS:\n2.4465', '\\n', 'Epoch 20/50, Train Loss: 6.9380, Val Loss: 6.3964, SORS:\n2.4467', '\\n', 'Epoch 21/50, Train Loss: 6.9371, Val Loss: 6.3956, SORS:\n2.4468', '\\n', 'Epoch 22/50, Train Loss: 6.9363, Val Loss: 6.3945, SORS:\n2.4469', '\\n', 'Epoch 23/50, Train Loss: 6.9354, Val Loss: 6.3939, SORS:\n2.4470', '\\n', 'Epoch 24/50, Train Loss: 6.9348, Val Loss: 6.3933, SORS:\n2.4471', '\\n', 'Epoch 25/50, Train Loss: 6.9327, Val Loss: 6.3929, SORS:\n2.4471', '\\n', 'Epoch 26/50, Train Loss: 6.9303, Val Loss: 6.3924, SORS:\n2.4472', '\\n', 'Epoch 27/50, Train Loss: 6.9279, Val Loss: 6.3920, SORS:\n2.4472', '\\n', 'Epoch 28/50, Train Loss: 6.9254, Val Loss: 6.3917, SORS:\n2.4472', '\\n', 'Epoch 29/50, Train Loss: 6.9234, Val Loss: 6.3915, SORS:\n2.4473', '\\n', 'Epoch 30/50, Train Loss: 6.9215, Val Loss: 6.3912, SORS:\n2.4473', '\\n', 'Epoch 31/50, Train Loss: 6.9194, Val Loss: 6.3911, SORS:\n2.4473', '\\n', 'Epoch 32/50, Train Loss: 6.9174, Val Loss: 6.3911, SORS:\n2.4474', '\\n', 'Epoch 33/50, Train Loss: 6.9154, Val Loss: 6.3910, SORS:\n2.4474', '\\n', 'Epoch 34/50, Train Loss: 6.9133, Val Loss: 6.3910, SORS:\n2.4474', '\\n', 'Epoch 35/50, Train Loss: 6.9111, Val Loss: 6.3910, SORS:\n2.4475', '\\n', 'Epoch 36/50, Train Loss: 6.9090, Val Loss: 6.3912, SORS:\n2.4475', '\\n', 'Epoch 37/50, Train Loss: 6.9072, Val Loss: 6.3914, SORS:\n2.4476', '\\n', 'Epoch 38/50, Train Loss: 6.9049, Val Loss: 6.3916, SORS:\n2.4477', '\\n', 'Epoch 39/50, Train Loss: 6.9031, Val Loss: 6.3917, SORS:\n2.4477', '\\n', 'Epoch 40/50, Train Loss: 6.9012, Val Loss: 6.3918, SORS:\n2.4478', '\\n', 'Epoch 41/50, Train Loss: 6.8993, Val Loss: 6.3920, SORS:\n2.4478', '\\n', 'Epoch 42/50, Train Loss: 6.8984, Val Loss: 6.3920, SORS:\n2.4478', '\\n', 'Epoch 43/50, Train Loss: 6.8981, Val Loss: 6.3921, SORS:\n2.4479', '\\n', 'Epoch 44/50, Train Loss: 6.8979, Val Loss: 6.3922, SORS:\n2.4479', '\\n', 'Epoch 45/50, Train Loss: 6.8988, Val Loss: 6.3924, SORS:\n2.4480', '\\n', 'Epoch 46/50, Train Loss: 6.8987, Val Loss: 6.3930, SORS:\n2.4481', '\\n', 'Epoch 47/50, Train Loss: 6.8994, Val Loss: 6.3937, SORS:\n2.4483', '\\n', 'Epoch 48/50, Train Loss: 6.9000, Val Loss: 6.3945, SORS:\n2.4485', '\\n', 'Epoch 49/50, Train Loss: 6.9002, Val Loss: 6.3953, SORS:\n2.4487', '\\n', 'Epoch 50/50, Train Loss: 6.9007, Val Loss: 6.3960, SORS:\n2.4488', '\\n', 'Training pca_3d with batch size: 32', '\\n', 'Epoch 1/50, Train\nLoss: 11.5824, Val Loss: 11.7642, SORS: 2.4859', '\\n', 'Epoch 2/50, Train Loss:\n10.7960, Val Loss: 10.9479, SORS: 2.4856', '\\n', 'Epoch 3/50, Train Loss:\n10.0574, Val Loss: 10.1824, SORS: 2.4875', '\\n', 'Epoch 4/50, Train Loss:\n9.3608, Val Loss: 9.4648, SORS: 2.4892', '\\n', 'Epoch 5/50, Train Loss: 8.7167,\nVal Loss: 8.8023, SORS: 2.4905', '\\n', 'Epoch 6/50, Train Loss: 8.1337, Val\nLoss: 8.2078, SORS: 2.4908', '\\n', 'Epoch 7/50, Train Loss: 7.6375, Val Loss:\n7.6959, SORS: 2.4896', '\\n', 'Epoch 8/50, Train Loss: 7.2373, Val Loss: 7.2835,\nSORS: 2.4875', '\\n', 'Epoch 9/50, Train Loss: 6.9335, Val Loss: 6.9763, SORS:\n2.4847', '\\n', 'Epoch 10/50, Train Loss: 6.7255, Val Loss: 6.7679, SORS:\n2.4817', '\\n', 'Epoch 11/50, Train Loss: 6.5973, Val Loss: 6.6375, SORS:\n2.4784', '\\n', 'Epoch 12/50, Train Loss: 6.5289, Val Loss: 6.5620, SORS:\n2.4751', '\\n', 'Epoch 13/50, Train Loss: 6.4962, Val Loss: 6.5206, SORS:\n2.4721', '\\n', 'Epoch 14/50, Train Loss: 6.4818, Val Loss: 6.4973, SORS:\n2.4695', '\\n', 'Epoch 15/50, Train Loss: 6.4759, Val Loss: 6.4829, SORS:\n2.4672', '\\n', 'Epoch 16/50, Train Loss: 6.4734, Val Loss: 6.4729, SORS:\n2.4652', '\\n', 'Epoch 17/50, Train Loss: 6.4724, Val Loss: 6.4651, SORS:\n2.4636', '\\n', 'Epoch 18/50, Train Loss: 6.4725, Val Loss: 6.4588, SORS:\n2.4624', '\\n', 'Epoch 19/50, Train Loss: 6.4734, Val Loss: 6.4536, SORS:\n2.4613', '\\n', 'Epoch 20/50, Train Loss: 6.4745, Val Loss: 6.4491, SORS:\n2.4604', '\\n', 'Epoch 21/50, Train Loss: 6.4753, Val Loss: 6.4448, SORS:\n2.4596', '\\n', 'Epoch 22/50, Train Loss: 6.4754, Val Loss: 6.4407, SORS:\n2.4587', '\\n', 'Epoch 23/50, Train Loss: 6.4748, Val Loss: 6.4371, SORS:\n2.4580', '\\n', 'Epoch 24/50, Train Loss: 6.4740, Val Loss: 6.4336, SORS:\n2.4572', '\\n', 'Epoch 25/50, Train Loss: 6.4731, Val Loss: 6.4305, SORS:\n2.4566', '\\n', 'Epoch 26/50, Train Loss: 6.4721, Val Loss: 6.4274, SORS:\n2.4558', '\\n', 'Epoch 27/50, Train Loss: 6.4708, Val Loss: 6.4248, SORS:\n2.4552', '\\n', 'Epoch 28/50, Train Loss: 6.4669, Val Loss: 6.4225, SORS:\n2.4547', '\\n', 'Epoch 29/50, Train Loss: 6.4611, Val Loss: 6.4202, SORS:\n2.4541', '\\n', 'Epoch 30/50, Train Loss: 6.4560, Val Loss: 6.4181, SORS:\n2.4536', '\\n', 'Epoch 31/50, Train Loss: 6.4508, Val Loss: 6.4163, SORS:\n2.4531', '\\n', 'Epoch 32/50, Train Loss: 6.4458, Val Loss: 6.4149, SORS:\n2.4527', '\\n', 'Epoch 33/50, Train Loss: 6.4400, Val Loss: 6.4135, SORS:\n2.4523', '\\n', 'Epoch 34/50, Train Loss: 6.4352, Val Loss: 6.4123, SORS:\n2.4520', '\\n', 'Epoch 35/50, Train Loss: 6.4304, Val Loss: 6.4113, SORS:\n2.4517', '\\n', 'Epoch 36/50, Train Loss: 6.4261, Val Loss: 6.4106, SORS:\n2.4515', '\\n', 'Epoch 37/50, Train Loss: 6.4228, Val Loss: 6.4100, SORS:\n2.4513', '\\n', 'Epoch 38/50, Train Loss: 6.4195, Val Loss: 6.4094, SORS:\n2.4511', '\\n', 'Epoch 39/50, Train Loss: 6.4162, Val Loss: 6.4092, SORS:\n2.4510', '\\n', 'Epoch 40/50, Train Loss: 6.4130, Val Loss: 6.4090, SORS:\n2.4509', '\\n', 'Epoch 41/50, Train Loss: 6.4101, Val Loss: 6.4088, SORS:\n2.4507', '\\n', 'Epoch 42/50, Train Loss: 6.4069, Val Loss: 6.4086, SORS:\n2.4506', '\\n', 'Epoch 43/50, Train Loss: 6.4038, Val Loss: 6.4085, SORS:\n2.4505', '\\n', 'Epoch 44/50, Train Loss: 6.4012, Val Loss: 6.4085, SORS:\n2.4504', '\\n', 'Epoch 45/50, Train Loss: 6.3991, Val Loss: 6.4086, SORS:\n2.4504', '\\n', 'Epoch 46/50, Train Loss: 6.3970, Val Loss: 6.4089, SORS:\n2.4504', '\\n', 'Epoch 47/50, Train Loss: 6.3960, Val Loss: 6.4093, SORS:\n2.4504', '\\n', 'Epoch 48/50, Train Loss: 6.3955, Val Loss: 6.4097, SORS:\n2.4505', '\\n', 'Epoch 49/50, Train Loss: 6.3952, Val Loss: 6.4101, SORS:\n2.4505', '\\n', 'Epoch 50/50, Train Loss: 6.3940, Val Loss: 6.4104, SORS:\n2.4505', '\\n', 'Training pca_3d with batch size: 64', '\\n', 'Epoch 1/50, Train\nLoss: 12.2621, Val Loss: 12.3818, SORS: 2.5026', '\\n', 'Epoch 2/50, Train Loss:\n11.7805, Val Loss: 11.8827, SORS: 2.4863', '\\n', 'Epoch 3/50, Train Loss:\n11.3186, Val Loss: 11.4028, SORS: 2.4821', '\\n', 'Epoch 4/50, Train Loss:\n10.8704, Val Loss: 10.9357, SORS: 2.4813', '\\n', 'Epoch 5/50, Train Loss:\n10.4331, Val Loss: 10.4786, SORS: 2.4807', '\\n', 'Epoch 6/50, Train Loss:\n10.0053, Val Loss: 10.0310, SORS: 2.4800', '\\n', 'Epoch 7/50, Train Loss:\n9.5885, Val Loss: 9.5945, SORS: 2.4792', '\\n', 'Epoch 8/50, Train Loss: 9.1858,\nVal Loss: 9.1725, SORS: 2.4784', '\\n', 'Epoch 9/50, Train Loss: 8.8011, Val\nLoss: 8.7687, SORS: 2.4776', '\\n', 'Epoch 10/50, Train Loss: 8.4394, Val Loss:\n8.3870, SORS: 2.4766', '\\n', 'Epoch 11/50, Train Loss: 8.1060, Val Loss: 8.0329,\nSORS: 2.4756', '\\n', 'Epoch 12/50, Train Loss: 7.8038, Val Loss: 7.7095, SORS:\n2.4743', '\\n', 'Epoch 13/50, Train Loss: 7.5372, Val Loss: 7.4211, SORS:\n2.4728', '\\n', 'Epoch 14/50, Train Loss: 7.3087, Val Loss: 7.1709, SORS:\n2.4711', '\\n', 'Epoch 15/50, Train Loss: 7.1190, Val Loss: 6.9612, SORS:\n2.4693', '\\n', 'Epoch 16/50, Train Loss: 6.9673, Val Loss: 6.7915, SORS:\n2.4673', '\\n', 'Epoch 17/50, Train Loss: 6.8502, Val Loss: 6.6604, SORS:\n2.4652', '\\n', 'Epoch 18/50, Train Loss: 6.7641, Val Loss: 6.5645, SORS:\n2.4632', '\\n', 'Epoch 19/50, Train Loss: 6.7030, Val Loss: 6.4980, SORS:\n2.4613', '\\n', 'Epoch 20/50, Train Loss: 6.6608, Val Loss: 6.4539, SORS:\n2.4594', '\\n', 'Epoch 21/50, Train Loss: 6.6307, Val Loss: 6.4269, SORS:\n2.4577', '\\n', 'Epoch 22/50, Train Loss: 6.6084, Val Loss: 6.4111, SORS:\n2.4561', '\\n', 'Epoch 23/50, Train Loss: 6.5905, Val Loss: 6.4025, SORS:\n2.4546', '\\n', 'Epoch 24/50, Train Loss: 6.5748, Val Loss: 6.3979, SORS:\n2.4533', '\\n', 'Epoch 25/50, Train Loss: 6.5602, Val Loss: 6.3953, SORS:\n2.4521', '\\n', 'Epoch 26/50, Train Loss: 6.5462, Val Loss: 6.3938, SORS:\n2.4511', '\\n', 'Epoch 27/50, Train Loss: 6.5327, Val Loss: 6.3927, SORS:\n2.4501', '\\n', 'Epoch 28/50, Train Loss: 6.5200, Val Loss: 6.3919, SORS:\n2.4493', '\\n', 'Epoch 29/50, Train Loss: 6.5081, Val Loss: 6.3910, SORS:\n2.4486', '\\n', 'Epoch 30/50, Train Loss: 6.4970, Val Loss: 6.3900, SORS:\n2.4479', '\\n', 'Epoch 31/50, Train Loss: 6.4867, Val Loss: 6.3891, SORS:\n2.4472', '\\n', 'Epoch 32/50, Train Loss: 6.4770, Val Loss: 6.3881, SORS:\n2.4467', '\\n', 'Epoch 33/50, Train Loss: 6.4669, Val Loss: 6.3873, SORS:\n2.4462', '\\n', 'Epoch 34/50, Train Loss: 6.4564, Val Loss: 6.3863, SORS:\n2.4457', '\\n', 'Epoch 35/50, Train Loss: 6.4466, Val Loss: 6.3853, SORS:\n2.4452', '\\n', 'Epoch 36/50, Train Loss: 6.4372, Val Loss: 6.3843, SORS:\n2.4448', '\\n', 'Epoch 37/50, Train Loss: 6.4285, Val Loss: 6.3833, SORS:\n2.4444', '\\n', 'Epoch 38/50, Train Loss: 6.4203, Val Loss: 6.3824, SORS:\n2.4440', '\\n', 'Epoch 39/50, Train Loss: 6.4129, Val Loss: 6.3815, SORS:\n2.4437', '\\n', 'Epoch 40/50, Train Loss: 6.4062, Val Loss: 6.3807, SORS:\n2.4434', '\\n', 'Epoch 41/50, Train Loss: 6.3997, Val Loss: 6.3799, SORS:\n2.4431', '\\n', 'Epoch 42/50, Train Loss: 6.3932, Val Loss: 6.3792, SORS:\n2.4428', '\\n', 'Epoch 43/50, Train Loss: 6.3868, Val Loss: 6.3785, SORS:\n2.4426', '\\n', 'Epoch 44/50, Train Loss: 6.3806, Val Loss: 6.3779, SORS:\n2.4423', '\\n', 'Epoch 45/50, Train Loss: 6.3745, Val Loss: 6.3775, SORS:\n2.4421', '\\n', 'Epoch 46/50, Train Loss: 6.3690, Val Loss: 6.3771, SORS:\n2.4419', '\\n', 'Epoch 47/50, Train Loss: 6.3643, Val Loss: 6.3767, SORS:\n2.4417', '\\n', 'Epoch 48/50, Train Loss: 6.3605, Val Loss: 6.3762, SORS:\n2.4415', '\\n', 'Epoch 49/50, Train Loss: 6.3568, Val Loss: 6.3757, SORS:\n2.4413', '\\n', 'Epoch 50/50, Train Loss: 6.3532, Val Loss: 6.3752, SORS:\n2.4411', '\\n', 'Training pca_3d with batch size: 128', '\\n', 'Epoch 1/50, Train\nLoss: 12.3029, Val Loss: 12.4946, SORS: 2.5019', '\\n', 'Epoch 2/50, Train Loss:\n12.0654, Val Loss: 12.2494, SORS: 2.4868', '\\n', 'Epoch 3/50, Train Loss:\n11.8344, Val Loss: 12.0111, SORS: 2.4796', '\\n', 'Epoch 4/50, Train Loss:\n11.6099, Val Loss: 11.7790, SORS: 2.4769', '\\n', 'Epoch 5/50, Train Loss:\n11.3910, Val Loss: 11.5522, SORS: 2.4768', '\\n', 'Epoch 6/50, Train Loss:\n11.1760, Val Loss: 11.3294, SORS: 2.4767', '\\n', 'Epoch 7/50, Train Loss:\n10.9644, Val Loss: 11.1096, SORS: 2.4765', '\\n', 'Epoch 8/50, Train Loss:\n10.7559, Val Loss: 10.8921, SORS: 2.4763', '\\n', 'Epoch 9/50, Train Loss:\n10.5486, Val Loss: 10.6763, SORS: 2.4760', '\\n', 'Epoch 10/50, Train Loss:\n10.3434, Val Loss: 10.4624, SORS: 2.4756', '\\n', 'Epoch 11/50, Train Loss:\n10.1394, Val Loss: 10.2499, SORS: 2.4752', '\\n', 'Epoch 12/50, Train Loss:\n9.9370, Val Loss: 10.0387, SORS: 2.4748', '\\n', 'Epoch 13/50, Train Loss:\n9.7357, Val Loss: 9.8290, SORS: 2.4743', '\\n', 'Epoch 14/50, Train Loss: 9.5362,\nVal Loss: 9.6207, SORS: 2.4737', '\\n', 'Epoch 15/50, Train Loss: 9.3386, Val\nLoss: 9.4141, SORS: 2.4730', '\\n', 'Epoch 16/50, Train Loss: 9.1429, Val Loss:\n9.2096, SORS: 2.4724', '\\n', 'Epoch 17/50, Train Loss: 8.9492, Val Loss: 9.0077,\nSORS: 2.4716', '\\n', 'Epoch 18/50, Train Loss: 8.7587, Val Loss: 8.8089, SORS:\n2.4707', '\\n', 'Epoch 19/50, Train Loss: 8.5727, Val Loss: 8.6142, SORS:\n2.4698', '\\n', 'Epoch 20/50, Train Loss: 8.3918, Val Loss: 8.4244, SORS:\n2.4689', '\\n', 'Epoch 21/50, Train Loss: 8.2158, Val Loss: 8.2405, SORS:\n2.4679', '\\n', 'Epoch 22/50, Train Loss: 8.0463, Val Loss: 8.0627, SORS:\n2.4669', '\\n', 'Epoch 23/50, Train Loss: 7.8834, Val Loss: 7.8921, SORS:\n2.4659', '\\n', 'Epoch 24/50, Train Loss: 7.7280, Val Loss: 7.7295, SORS:\n2.4648', '\\n', 'Epoch 25/50, Train Loss: 7.5814, Val Loss: 7.5758, SORS:\n2.4637', '\\n', 'Epoch 26/50, Train Loss: 7.4434, Val Loss: 7.4319, SORS:\n2.4626', '\\n', 'Epoch 27/50, Train Loss: 7.3143, Val Loss: 7.2983, SORS:\n2.4615', '\\n', 'Epoch 28/50, Train Loss: 7.1946, Val Loss: 7.1754, SORS:\n2.4605', '\\n', 'Epoch 29/50, Train Loss: 7.0824, Val Loss: 7.0633, SORS:\n2.4595', '\\n', 'Epoch 30/50, Train Loss: 6.9797, Val Loss: 6.9621, SORS:\n2.4585', '\\n', 'Epoch 31/50, Train Loss: 6.8872, Val Loss: 6.8718, SORS:\n2.4577', '\\n', 'Epoch 32/50, Train Loss: 6.8051, Val Loss: 6.7922, SORS:\n2.4568', '\\n', 'Epoch 33/50, Train Loss: 6.7320, Val Loss: 6.7228, SORS:\n2.4560', '\\n', 'Epoch 34/50, Train Loss: 6.6679, Val Loss: 6.6628, SORS:\n2.4551', '\\n', 'Epoch 35/50, Train Loss: 6.6125, Val Loss: 6.6115, SORS:\n2.4543', '\\n', 'Epoch 36/50, Train Loss: 6.5649, Val Loss: 6.5685, SORS:\n2.4535', '\\n', 'Epoch 37/50, Train Loss: 6.5244, Val Loss: 6.5331, SORS:\n2.4527', '\\n', 'Epoch 38/50, Train Loss: 6.4904, Val Loss: 6.5042, SORS:\n2.4519', '\\n', 'Epoch 39/50, Train Loss: 6.4621, Val Loss: 6.4810, SORS:\n2.4512', '\\n', 'Epoch 40/50, Train Loss: 6.4387, Val Loss: 6.4626, SORS:\n2.4505', '\\n', 'Epoch 41/50, Train Loss: 6.4196, Val Loss: 6.4484, SORS:\n2.4498', '\\n', 'Epoch 42/50, Train Loss: 6.4039, Val Loss: 6.4376, SORS:\n2.4491', '\\n', 'Epoch 43/50, Train Loss: 6.3913, Val Loss: 6.4297, SORS:\n2.4485', '\\n', 'Epoch 44/50, Train Loss: 6.3810, Val Loss: 6.4238, SORS:\n2.4480', '\\n', 'Epoch 45/50, Train Loss: 6.3726, Val Loss: 6.4197, SORS:\n2.4474', '\\n', 'Epoch 46/50, Train Loss: 6.3654, Val Loss: 6.4168, SORS:\n2.4469', '\\n', 'Epoch 47/50, Train Loss: 6.3592, Val Loss: 6.4148, SORS:\n2.4465', '\\n', 'Epoch 48/50, Train Loss: 6.3540, Val Loss: 6.4134, SORS:\n2.4460', '\\n', 'Epoch 49/50, Train Loss: 6.3498, Val Loss: 6.4125, SORS:\n2.4456', '\\n', 'Epoch 50/50, Train Loss: 6.3461, Val Loss: 6.4119, SORS:\n2.4452', '\\n', 'Training pca_3d with batch size: 256', '\\n', 'Epoch 1/50, Train\nLoss: 13.9109, Val Loss: 14.1824, SORS: 2.7652', '\\n', 'Epoch 2/50, Train Loss:\n13.7899, Val Loss: 14.0563, SORS: 2.7422', '\\n', 'Epoch 3/50, Train Loss:\n13.6716, Val Loss: 13.9330, SORS: 2.7195', '\\n', 'Epoch 4/50, Train Loss:\n13.5561, Val Loss: 13.8126, SORS: 2.6971', '\\n', 'Epoch 5/50, Train Loss:\n13.4434, Val Loss: 13.6949, SORS: 2.6751', '\\n', 'Epoch 6/50, Train Loss:\n13.3330, Val Loss: 13.5796, SORS: 2.6537', '\\n', 'Epoch 7/50, Train Loss:\n13.2249, Val Loss: 13.4665, SORS: 2.6332', '\\n', 'Epoch 8/50, Train Loss:\n13.1190, Val Loss: 13.3554, SORS: 2.6141', '\\n', 'Epoch 9/50, Train Loss:\n13.0151, Val Loss: 13.2461, SORS: 2.5963', '\\n', 'Epoch 10/50, Train Loss:\n12.9126, Val Loss: 13.1383, SORS: 2.5795', '\\n', 'Epoch 11/50, Train Loss:\n12.8116, Val Loss: 13.0318, SORS: 2.5634', '\\n', 'Epoch 12/50, Train Loss:\n12.7114, Val Loss: 12.9263, SORS: 2.5488', '\\n', 'Epoch 13/50, Train Loss:\n12.6112, Val Loss: 12.8217, SORS: 2.5354', '\\n', 'Epoch 14/50, Train Loss:\n12.5115, Val Loss: 12.7176, SORS: 2.5234', '\\n', 'Epoch 15/50, Train Loss:\n12.4125, Val Loss: 12.6141, SORS: 2.5131', '\\n', 'Epoch 16/50, Train Loss:\n12.3139, Val Loss: 12.5108, SORS: 2.5050', '\\n', 'Epoch 17/50, Train Loss:\n12.2150, Val Loss: 12.4075, SORS: 2.4983', '\\n', 'Epoch 18/50, Train Loss:\n12.1159, Val Loss: 12.3039, SORS: 2.4935', '\\n', 'Epoch 19/50, Train Loss:\n12.0167, Val Loss: 12.2001, SORS: 2.4896', '\\n', 'Epoch 20/50, Train Loss:\n11.9174, Val Loss: 12.0958, SORS: 2.4873', '\\n', 'Epoch 21/50, Train Loss:\n11.8179, Val Loss: 11.9909, SORS: 2.4865', '\\n', 'Epoch 22/50, Train Loss:\n11.7181, Val Loss: 11.8853, SORS: 2.4861', '\\n', 'Epoch 23/50, Train Loss:\n11.6174, Val Loss: 11.7787, SORS: 2.4857', '\\n', 'Epoch 24/50, Train Loss:\n11.5160, Val Loss: 11.6711, SORS: 2.4855', '\\n', 'Epoch 25/50, Train Loss:\n11.4139, Val Loss: 11.5627, SORS: 2.4854', '\\n', 'Epoch 26/50, Train Loss:\n11.3113, Val Loss: 11.4530, SORS: 2.4852', '\\n', 'Epoch 27/50, Train Loss:\n11.2080, Val Loss: 11.3422, SORS: 2.4850', '\\n', 'Epoch 28/50, Train Loss:\n11.1034, Val Loss: 11.2303, SORS: 2.4849', '\\n', 'Epoch 29/50, Train Loss:\n10.9975, Val Loss: 11.1171, SORS: 2.4846', '\\n', 'Epoch 30/50, Train Loss:\n10.8904, Val Loss: 11.0024, SORS: 2.4843', '\\n', 'Epoch 31/50, Train Loss:\n10.7822, Val Loss: 10.8865, SORS: 2.4841', '\\n', 'Epoch 32/50, Train Loss:\n10.6730, Val Loss: 10.7688, SORS: 2.4838', '\\n', 'Epoch 33/50, Train Loss:\n10.5617, Val Loss: 10.6499, SORS: 2.4834', '\\n', 'Epoch 34/50, Train Loss:\n10.4482, Val Loss: 10.5296, SORS: 2.4830', '\\n', 'Epoch 35/50, Train Loss:\n10.3342, Val Loss: 10.4083, SORS: 2.4826', '\\n', 'Epoch 36/50, Train Loss:\n10.2191, Val Loss: 10.2860, SORS: 2.4821', '\\n', 'Epoch 37/50, Train Loss:\n10.1032, Val Loss: 10.1628, SORS: 2.4817', '\\n', 'Epoch 38/50, Train Loss:\n9.9871, Val Loss: 10.0387, SORS: 2.4811', '\\n', 'Epoch 39/50, Train Loss:\n9.8702, Val Loss: 9.9141, SORS: 2.4806', '\\n', 'Epoch 40/50, Train Loss: 9.7522,\nVal Loss: 9.7889, SORS: 2.4800', '\\n', 'Epoch 41/50, Train Loss: 9.6331, Val\nLoss: 9.6634, SORS: 2.4793', '\\n', 'Epoch 42/50, Train Loss: 9.5142, Val Loss:\n9.5381, SORS: 2.4786', '\\n', 'Epoch 43/50, Train Loss: 9.3952, Val Loss: 9.4132,\nSORS: 2.4780', '\\n', 'Epoch 44/50, Train Loss: 9.2759, Val Loss: 9.2888, SORS:\n2.4773', '\\n', 'Epoch 45/50, Train Loss: 9.1564, Val Loss: 9.1649, SORS:\n2.4767', '\\n', 'Epoch 46/50, Train Loss: 9.0372, Val Loss: 9.0419, SORS:\n2.4760', '\\n', 'Epoch 47/50, Train Loss: 8.9185, Val Loss: 8.9200, SORS:\n2.4753', '\\n', 'Epoch 48/50, Train Loss: 8.8006, Val Loss: 8.7994, SORS:\n2.4746', '\\n', 'Epoch 49/50, Train Loss: 8.6827, Val Loss: 8.6805, SORS:\n2.4740', '\\n', 'Epoch 50/50, Train Loss: 8.5661, Val Loss: 8.5632, SORS:\n2.4733', '\\n', 'Training pca_2d with batch size: 16', '\\n', 'Epoch 1/50, Train\nLoss: 13.1415, Val Loss: 11.5859, SORS: 2.4804', '\\n', 'Epoch 2/50, Train Loss:\n10.9529, Val Loss: 9.6028, SORS: 2.4811', '\\n', 'Epoch 3/50, Train Loss: 9.2171,\nVal Loss: 8.0783, SORS: 2.4818', '\\n', 'Epoch 4/50, Train Loss: 8.0838, Val\nLoss: 7.1325, SORS: 2.4821', '\\n', 'Epoch 5/50, Train Loss: 7.5367, Val Loss:\n6.7145, SORS: 2.4822', '\\n', 'Epoch 6/50, Train Loss: 7.3519, Val Loss: 6.5909,\nSORS: 2.4819', '\\n', 'Epoch 7/50, Train Loss: 7.3097, Val Loss: 6.5641, SORS:\n2.4815', '\\n', 'Epoch 8/50, Train Loss: 7.3091, Val Loss: 6.5567, SORS: 2.4812',\n'\\n', 'Epoch 9/50, Train Loss: 7.3166, Val Loss: 6.5515, SORS: 2.4809', '\\n',\n'Epoch 10/50, Train Loss: 7.3245, Val Loss: 6.5468, SORS: 2.4807', '\\n', 'Epoch\n11/50, Train Loss: 7.3322, Val Loss: 6.5430, SORS: 2.4805', '\\n', 'Epoch 12/50,\nTrain Loss: 7.3377, Val Loss: 6.5398, SORS: 2.4803', '\\n', 'Epoch 13/50, Train\nLoss: 7.3430, Val Loss: 6.5375, SORS: 2.4802', '\\n', 'Epoch 14/50, Train Loss:\n7.3470, Val Loss: 6.5359, SORS: 2.4802', '\\n', 'Epoch 15/50, Train Loss: 7.3502,\nVal Loss: 6.5349, SORS: 2.4802', '\\n', 'Epoch 16/50, Train Loss: 7.3515, Val\nLoss: 6.5342, SORS: 2.4802', '\\n', 'Epoch 17/50, Train Loss: 7.3523, Val Loss:\n6.5337, SORS: 2.4802', '\\n', 'Epoch 18/50, Train Loss: 7.3517, Val Loss: 6.5332,\nSORS: 2.4802', '\\n', 'Epoch 19/50, Train Loss: 7.3512, Val Loss: 6.5330, SORS:\n2.4802', '\\n', 'Epoch 20/50, Train Loss: 7.3503, Val Loss: 6.5327, SORS:\n2.4801', '\\n', 'Epoch 21/50, Train Loss: 7.3479, Val Loss: 6.5327, SORS:\n2.4801', '\\n', 'Epoch 22/50, Train Loss: 7.3453, Val Loss: 6.5328, SORS:\n2.4801', '\\n', 'Epoch 23/50, Train Loss: 7.3429, Val Loss: 6.5328, SORS:\n2.4802', '\\n', 'Epoch 24/50, Train Loss: 7.3412, Val Loss: 6.5329, SORS:\n2.4802', '\\n', 'Epoch 25/50, Train Loss: 7.3390, Val Loss: 6.5332, SORS:\n2.4802', '\\n', 'Epoch 26/50, Train Loss: 7.3369, Val Loss: 6.5335, SORS:\n2.4802', '\\n', 'Epoch 27/50, Train Loss: 7.3343, Val Loss: 6.5338, SORS:\n2.4803', '\\n', 'Epoch 28/50, Train Loss: 7.3315, Val Loss: 6.5341, SORS:\n2.4803', '\\n', 'Epoch 29/50, Train Loss: 7.3288, Val Loss: 6.5344, SORS:\n2.4803', '\\n', 'Epoch 30/50, Train Loss: 7.3251, Val Loss: 6.5348, SORS:\n2.4803', '\\n', 'Epoch 31/50, Train Loss: 7.3218, Val Loss: 6.5351, SORS:\n2.4804', '\\n', 'Epoch 32/50, Train Loss: 7.3184, Val Loss: 6.5355, SORS:\n2.4804', '\\n', 'Epoch 33/50, Train Loss: 7.3149, Val Loss: 6.5358, SORS:\n2.4804', '\\n', 'Epoch 34/50, Train Loss: 7.3112, Val Loss: 6.5363, SORS:\n2.4804', '\\n', 'Epoch 35/50, Train Loss: 7.3077, Val Loss: 6.5367, SORS:\n2.4805', '\\n', 'Epoch 36/50, Train Loss: 7.3045, Val Loss: 6.5371, SORS:\n2.4805', '\\n', 'Epoch 37/50, Train Loss: 7.3011, Val Loss: 6.5375, SORS:\n2.4805', '\\n', 'Epoch 38/50, Train Loss: 7.2980, Val Loss: 6.5379, SORS:\n2.4806', '\\n', 'Epoch 39/50, Train Loss: 7.2952, Val Loss: 6.5383, SORS:\n2.4806', '\\n', 'Epoch 40/50, Train Loss: 7.2917, Val Loss: 6.5387, SORS:\n2.4806', '\\n', 'Epoch 41/50, Train Loss: 7.2878, Val Loss: 6.5392, SORS:\n2.4806', '\\n', 'Epoch 42/50, Train Loss: 7.2838, Val Loss: 6.5398, SORS:\n2.4807', '\\n', 'Epoch 43/50, Train Loss: 7.2799, Val Loss: 6.5404, SORS:\n2.4807', '\\n', 'Epoch 44/50, Train Loss: 7.2757, Val Loss: 6.5410, SORS:\n2.4808', '\\n', 'Epoch 45/50, Train Loss: 7.2718, Val Loss: 6.5415, SORS:\n2.4808', '\\n', 'Epoch 46/50, Train Loss: 7.2673, Val Loss: 6.5420, SORS:\n2.4808', '\\n', 'Epoch 47/50, Train Loss: 7.2633, Val Loss: 6.5425, SORS:\n2.4809', '\\n', 'Epoch 48/50, Train Loss: 7.2593, Val Loss: 6.5430, SORS:\n2.4809', '\\n', 'Epoch 49/50, Train Loss: 7.2556, Val Loss: 6.5435, SORS:\n2.4809', '\\n', 'Epoch 50/50, Train Loss: 7.2515, Val Loss: 6.5441, SORS:\n2.4810', '\\n', 'Training pca_2d with batch size: 32', '\\n', 'Epoch 1/50, Train\nLoss: 12.6422, Val Loss: 12.8673, SORS: 2.5420', '\\n', 'Epoch 2/50, Train Loss:\n11.8300, Val Loss: 12.0151, SORS: 2.4821', '\\n', 'Epoch 3/50, Train Loss:\n11.0553, Val Loss: 11.1975, SORS: 2.4793', '\\n', 'Epoch 4/50, Train Loss:\n10.3081, Val Loss: 10.4053, SORS: 2.4778', '\\n', 'Epoch 5/50, Train Loss:\n9.5848, Val Loss: 9.6415, SORS: 2.4758', '\\n', 'Epoch 6/50, Train Loss: 8.9052,\nVal Loss: 8.9225, SORS: 2.4738', '\\n', 'Epoch 7/50, Train Loss: 8.2901, Val\nLoss: 8.2726, SORS: 2.4720', '\\n', 'Epoch 8/50, Train Loss: 7.7688, Val Loss:\n7.7166, SORS: 2.4700', '\\n', 'Epoch 9/50, Train Loss: 7.3619, Val Loss: 7.2736,\nSORS: 2.4683', '\\n', 'Epoch 10/50, Train Loss: 7.0751, Val Loss: 6.9528, SORS:\n2.4674', '\\n', 'Epoch 11/50, Train Loss: 6.8937, Val Loss: 6.7451, SORS:\n2.4673', '\\n', 'Epoch 12/50, Train Loss: 6.7965, Val Loss: 6.6254, SORS:\n2.4675', '\\n', 'Epoch 13/50, Train Loss: 6.7544, Val Loss: 6.5641, SORS:\n2.4678', '\\n', 'Epoch 14/50, Train Loss: 6.7436, Val Loss: 6.5373, SORS:\n2.4684', '\\n', 'Epoch 15/50, Train Loss: 6.7477, Val Loss: 6.5277, SORS:\n2.4690', '\\n', 'Epoch 16/50, Train Loss: 6.7556, Val Loss: 6.5249, SORS:\n2.4697', '\\n', 'Epoch 17/50, Train Loss: 6.7633, Val Loss: 6.5244, SORS:\n2.4704', '\\n', 'Epoch 18/50, Train Loss: 6.7690, Val Loss: 6.5244, SORS:\n2.4711', '\\n', 'Epoch 19/50, Train Loss: 6.7733, Val Loss: 6.5244, SORS:\n2.4718', '\\n', 'Epoch 20/50, Train Loss: 6.7762, Val Loss: 6.5244, SORS:\n2.4725', '\\n', 'Epoch 21/50, Train Loss: 6.7791, Val Loss: 6.5242, SORS:\n2.4731', '\\n', 'Epoch 22/50, Train Loss: 6.7814, Val Loss: 6.5241, SORS:\n2.4736', '\\n', 'Epoch 23/50, Train Loss: 6.7831, Val Loss: 6.5240, SORS:\n2.4741', '\\n', 'Epoch 24/50, Train Loss: 6.7838, Val Loss: 6.5238, SORS:\n2.4745', '\\n', 'Epoch 25/50, Train Loss: 6.7844, Val Loss: 6.5238, SORS:\n2.4749', '\\n', 'Epoch 26/50, Train Loss: 6.7849, Val Loss: 6.5236, SORS:\n2.4752', '\\n', 'Epoch 27/50, Train Loss: 6.7851, Val Loss: 6.5235, SORS:\n2.4755', '\\n', 'Epoch 28/50, Train Loss: 6.7851, Val Loss: 6.5234, SORS:\n2.4757', '\\n', 'Epoch 29/50, Train Loss: 6.7849, Val Loss: 6.5233, SORS:\n2.4759', '\\n', 'Epoch 30/50, Train Loss: 6.7842, Val Loss: 6.5234, SORS:\n2.4761', '\\n', 'Epoch 31/50, Train Loss: 6.7833, Val Loss: 6.5234, SORS:\n2.4763', '\\n', 'Epoch 32/50, Train Loss: 6.7822, Val Loss: 6.5234, SORS:\n2.4764', '\\n', 'Epoch 33/50, Train Loss: 6.7810, Val Loss: 6.5233, SORS:\n2.4766', '\\n', 'Epoch 34/50, Train Loss: 6.7793, Val Loss: 6.5231, SORS:\n2.4766', '\\n', 'Epoch 35/50, Train Loss: 6.7768, Val Loss: 6.5228, SORS:\n2.4767', '\\n', 'Epoch 36/50, Train Loss: 6.7739, Val Loss: 6.5227, SORS:\n2.4767', '\\n', 'Epoch 37/50, Train Loss: 6.7716, Val Loss: 6.5228, SORS:\n2.4768', '\\n', 'Epoch 38/50, Train Loss: 6.7697, Val Loss: 6.5227, SORS:\n2.4768', '\\n', 'Epoch 39/50, Train Loss: 6.7680, Val Loss: 6.5227, SORS:\n2.4769', '\\n', 'Epoch 40/50, Train Loss: 6.7664, Val Loss: 6.5226, SORS:\n2.4769', '\\n', 'Epoch 41/50, Train Loss: 6.7643, Val Loss: 6.5225, SORS:\n2.4769', '\\n', 'Epoch 42/50, Train Loss: 6.7629, Val Loss: 6.5224, SORS:\n2.4769', '\\n', 'Epoch 43/50, Train Loss: 6.7616, Val Loss: 6.5222, SORS:\n2.4769', '\\n', 'Epoch 44/50, Train Loss: 6.7604, Val Loss: 6.5220, SORS:\n2.4769', '\\n', 'Epoch 45/50, Train Loss: 6.7590, Val Loss: 6.5219, SORS:\n2.4769', '\\n', 'Epoch 46/50, Train Loss: 6.7573, Val Loss: 6.5218, SORS:\n2.4769', '\\n', 'Epoch 47/50, Train Loss: 6.7556, Val Loss: 6.5217, SORS:\n2.4769', '\\n', 'Epoch 48/50, Train Loss: 6.7539, Val Loss: 6.5216, SORS:\n2.4768', '\\n', 'Epoch 49/50, Train Loss: 6.7521, Val Loss: 6.5216, SORS:\n2.4768', '\\n', 'Epoch 50/50, Train Loss: 6.7500, Val Loss: 6.5217, SORS:\n2.4768', '\\n', 'Training pca_2d with batch size: 64', '\\n', 'Epoch 1/50, Train\nLoss: 10.7837, Val Loss: 10.8924, SORS: 2.4814', '\\n', 'Epoch 2/50, Train Loss:\n10.3329, Val Loss: 10.4166, SORS: 2.4809', '\\n', 'Epoch 3/50, Train Loss:\n9.9041, Val Loss: 9.9633, SORS: 2.4805', '\\n', 'Epoch 4/50, Train Loss: 9.4965,\nVal Loss: 9.5305, SORS: 2.4800', '\\n', 'Epoch 5/50, Train Loss: 9.1097, Val\nLoss: 9.1178, SORS: 2.4796', '\\n', 'Epoch 6/50, Train Loss: 8.7461, Val Loss:\n8.7275, SORS: 2.4792', '\\n', 'Epoch 7/50, Train Loss: 8.4094, Val Loss: 8.3630,\nSORS: 2.4788', '\\n', 'Epoch 8/50, Train Loss: 8.1029, Val Loss: 8.0281, SORS:\n2.4783', '\\n', 'Epoch 9/50, Train Loss: 7.8299, Val Loss: 7.7266, SORS: 2.4779',\n'\\n', 'Epoch 10/50, Train Loss: 7.5917, Val Loss: 7.4611, SORS: 2.4776', '\\n',\n'Epoch 11/50, Train Loss: 7.3882, Val Loss: 7.2328, SORS: 2.4773', '\\n', 'Epoch\n12/50, Train Loss: 7.2211, Val Loss: 7.0423, SORS: 2.4770', '\\n', 'Epoch 13/50,\nTrain Loss: 7.0881, Val Loss: 6.8880, SORS: 2.4768', '\\n', 'Epoch 14/50, Train\nLoss: 6.9869, Val Loss: 6.7672, SORS: 2.4767', '\\n', 'Epoch 15/50, Train Loss:\n6.9126, Val Loss: 6.6765, SORS: 2.4766', '\\n', 'Epoch 16/50, Train Loss: 6.8613,\nVal Loss: 6.6113, SORS: 2.4765', '\\n', 'Epoch 17/50, Train Loss: 6.8285, Val\nLoss: 6.5668, SORS: 2.4764', '\\n', 'Epoch 18/50, Train Loss: 6.8086, Val Loss:\n6.5384, SORS: 2.4763', '\\n', 'Epoch 19/50, Train Loss: 6.7985, Val Loss: 6.5216,\nSORS: 2.4763', '\\n', 'Epoch 20/50, Train Loss: 6.7946, Val Loss: 6.5128, SORS:\n2.4762', '\\n', 'Epoch 21/50, Train Loss: 6.7941, Val Loss: 6.5091, SORS:\n2.4762', '\\n', 'Epoch 22/50, Train Loss: 6.7954, Val Loss: 6.5085, SORS:\n2.4761', '\\n', 'Epoch 23/50, Train Loss: 6.7970, Val Loss: 6.5093, SORS:\n2.4761', '\\n', 'Epoch 24/50, Train Loss: 6.7987, Val Loss: 6.5108, SORS:\n2.4760', '\\n', 'Epoch 25/50, Train Loss: 6.7998, Val Loss: 6.5124, SORS:\n2.4760', '\\n', 'Epoch 26/50, Train Loss: 6.8001, Val Loss: 6.5140, SORS:\n2.4760', '\\n', 'Epoch 27/50, Train Loss: 6.7999, Val Loss: 6.5152, SORS:\n2.4759', '\\n', 'Epoch 28/50, Train Loss: 6.7991, Val Loss: 6.5163, SORS:\n2.4759', '\\n', 'Epoch 29/50, Train Loss: 6.7980, Val Loss: 6.5171, SORS:\n2.4759', '\\n', 'Epoch 30/50, Train Loss: 6.7966, Val Loss: 6.5178, SORS:\n2.4759', '\\n', 'Epoch 31/50, Train Loss: 6.7951, Val Loss: 6.5183, SORS:\n2.4759', '\\n', 'Epoch 32/50, Train Loss: 6.7934, Val Loss: 6.5187, SORS:\n2.4759', '\\n', 'Epoch 33/50, Train Loss: 6.7917, Val Loss: 6.5190, SORS:\n2.4759', '\\n', 'Epoch 34/50, Train Loss: 6.7898, Val Loss: 6.5192, SORS:\n2.4759', '\\n', 'Epoch 35/50, Train Loss: 6.7879, Val Loss: 6.5194, SORS:\n2.4759', '\\n', 'Epoch 36/50, Train Loss: 6.7859, Val Loss: 6.5196, SORS:\n2.4759', '\\n', 'Epoch 37/50, Train Loss: 6.7841, Val Loss: 6.5198, SORS:\n2.4759', '\\n', 'Epoch 38/50, Train Loss: 6.7823, Val Loss: 6.5199, SORS:\n2.4759', '\\n', 'Epoch 39/50, Train Loss: 6.7805, Val Loss: 6.5200, SORS:\n2.4759', '\\n', 'Epoch 40/50, Train Loss: 6.7787, Val Loss: 6.5200, SORS:\n2.4759', '\\n', 'Epoch 41/50, Train Loss: 6.7768, Val Loss: 6.5201, SORS:\n2.4759', '\\n', 'Epoch 42/50, Train Loss: 6.7748, Val Loss: 6.5201, SORS:\n2.4759', '\\n', 'Epoch 43/50, Train Loss: 6.7726, Val Loss: 6.5201, SORS:\n2.4759', '\\n', 'Epoch 44/50, Train Loss: 6.7701, Val Loss: 6.5201, SORS:\n2.4759', '\\n', 'Epoch 45/50, Train Loss: 6.7678, Val Loss: 6.5201, SORS:\n2.4759', '\\n', 'Epoch 46/50, Train Loss: 6.7656, Val Loss: 6.5201, SORS:\n2.4759', '\\n', 'Epoch 47/50, Train Loss: 6.7634, Val Loss: 6.5201, SORS:\n2.4759', '\\n', 'Epoch 48/50, Train Loss: 6.7612, Val Loss: 6.5200, SORS:\n2.4759', '\\n', 'Epoch 49/50, Train Loss: 6.7592, Val Loss: 6.5200, SORS:\n2.4759', '\\n', 'Epoch 50/50, Train Loss: 6.7574, Val Loss: 6.5200, SORS:\n2.4759', '\\n', 'Training pca_2d with batch size: 128', '\\n', 'Epoch 1/50, Train\nLoss: 12.1825, Val Loss: 12.4421, SORS: 2.5060', '\\n', 'Epoch 2/50, Train Loss:\n11.8731, Val Loss: 12.1277, SORS: 2.4908', '\\n', 'Epoch 3/50, Train Loss:\n11.5765, Val Loss: 11.8259, SORS: 2.4860', '\\n', 'Epoch 4/50, Train Loss:\n11.2909, Val Loss: 11.5352, SORS: 2.4842', '\\n', 'Epoch 5/50, Train Loss:\n11.0156, Val Loss: 11.2546, SORS: 2.4832', '\\n', 'Epoch 6/50, Train Loss:\n10.7492, Val Loss: 10.9834, SORS: 2.4829', '\\n', 'Epoch 7/50, Train Loss:\n10.4915, Val Loss: 10.7208, SORS: 2.4830', '\\n', 'Epoch 8/50, Train Loss:\n10.2416, Val Loss: 10.4664, SORS: 2.4830', '\\n', 'Epoch 9/50, Train Loss:\n9.9994, Val Loss: 10.2194, SORS: 2.4831', '\\n', 'Epoch 10/50, Train Loss:\n9.7643, Val Loss: 9.9796, SORS: 2.4832', '\\n', 'Epoch 11/50, Train Loss: 9.5362,\nVal Loss: 9.7463, SORS: 2.4833', '\\n', 'Epoch 12/50, Train Loss: 9.3148, Val\nLoss: 9.5195, SORS: 2.4834', '\\n', 'Epoch 13/50, Train Loss: 9.0994, Val Loss:\n9.2993, SORS: 2.4835', '\\n', 'Epoch 14/50, Train Loss: 8.8907, Val Loss: 9.0857,\nSORS: 2.4836', '\\n', 'Epoch 15/50, Train Loss: 8.6886, Val Loss: 8.8789, SORS:\n2.4837', '\\n', 'Epoch 16/50, Train Loss: 8.4927, Val Loss: 8.6796, SORS:\n2.4838', '\\n', 'Epoch 17/50, Train Loss: 8.3046, Val Loss: 8.4880, SORS:\n2.4839', '\\n', 'Epoch 18/50, Train Loss: 8.1250, Val Loss: 8.3047, SORS:\n2.4840', '\\n', 'Epoch 19/50, Train Loss: 7.9546, Val Loss: 8.1298, SORS:\n2.4840', '\\n', 'Epoch 20/50, Train Loss: 7.7936, Val Loss: 7.9640, SORS:\n2.4840', '\\n', 'Epoch 21/50, Train Loss: 7.6426, Val Loss: 7.8082, SORS:\n2.4841', '\\n', 'Epoch 22/50, Train Loss: 7.5021, Val Loss: 7.6623, SORS:\n2.4841', '\\n', 'Epoch 23/50, Train Loss: 7.3721, Val Loss: 7.5265, SORS:\n2.4840', '\\n', 'Epoch 24/50, Train Loss: 7.2528, Val Loss: 7.4012, SORS:\n2.4839', '\\n', 'Epoch 25/50, Train Loss: 7.1436, Val Loss: 7.2866, SORS:\n2.4838', '\\n', 'Epoch 26/50, Train Loss: 7.0453, Val Loss: 7.1828, SORS:\n2.4836', '\\n', 'Epoch 27/50, Train Loss: 6.9579, Val Loss: 7.0894, SORS:\n2.4835', '\\n', 'Epoch 28/50, Train Loss: 6.8811, Val Loss: 7.0066, SORS:\n2.4834', '\\n', 'Epoch 29/50, Train Loss: 6.8146, Val Loss: 6.9336, SORS:\n2.4832', '\\n', 'Epoch 30/50, Train Loss: 6.7584, Val Loss: 6.8701, SORS:\n2.4830', '\\n', 'Epoch 31/50, Train Loss: 6.7116, Val Loss: 6.8155, SORS:\n2.4828', '\\n', 'Epoch 32/50, Train Loss: 6.6732, Val Loss: 6.7692, SORS:\n2.4826', '\\n', 'Epoch 33/50, Train Loss: 6.6429, Val Loss: 6.7303, SORS:\n2.4824', '\\n', 'Epoch 34/50, Train Loss: 6.6198, Val Loss: 6.6981, SORS:\n2.4822', '\\n', 'Epoch 35/50, Train Loss: 6.6025, Val Loss: 6.6718, SORS:\n2.4820', '\\n', 'Epoch 36/50, Train Loss: 6.5903, Val Loss: 6.6506, SORS:\n2.4819', '\\n', 'Epoch 37/50, Train Loss: 6.5822, Val Loss: 6.6336, SORS:\n2.4817', '\\n', 'Epoch 38/50, Train Loss: 6.5774, Val Loss: 6.6201, SORS:\n2.4815', '\\n', 'Epoch 39/50, Train Loss: 6.5752, Val Loss: 6.6095, SORS:\n2.4814', '\\n', 'Epoch 40/50, Train Loss: 6.5753, Val Loss: 6.6012, SORS:\n2.4812', '\\n', 'Epoch 41/50, Train Loss: 6.5770, Val Loss: 6.5948, SORS:\n2.4811', '\\n', 'Epoch 42/50, Train Loss: 6.5801, Val Loss: 6.5898, SORS:\n2.4809', '\\n', 'Epoch 43/50, Train Loss: 6.5841, Val Loss: 6.5860, SORS:\n2.4807', '\\n', 'Epoch 44/50, Train Loss: 6.5886, Val Loss: 6.5829, SORS:\n2.4806', '\\n', 'Epoch 45/50, Train Loss: 6.5936, Val Loss: 6.5805, SORS:\n2.4805', '\\n', 'Epoch 46/50, Train Loss: 6.5986, Val Loss: 6.5784, SORS:\n2.4803', '\\n', 'Epoch 47/50, Train Loss: 6.6037, Val Loss: 6.5766, SORS:\n2.4802', '\\n', 'Epoch 48/50, Train Loss: 6.6088, Val Loss: 6.5750, SORS:\n2.4800', '\\n', 'Epoch 49/50, Train Loss: 6.6137, Val Loss: 6.5736, SORS:\n2.4799', '\\n', 'Epoch 50/50, Train Loss: 6.6182, Val Loss: 6.5723, SORS:\n2.4798', '\\n', 'Training pca_2d with batch size: 256', '\\n', 'Epoch 1/50, Train\nLoss: 12.3633, Val Loss: 12.4842, SORS: 2.5026', '\\n', 'Epoch 2/50, Train Loss:\n12.2154, Val Loss: 12.3278, SORS: 2.4917', '\\n', 'Epoch 3/50, Train Loss:\n12.0694, Val Loss: 12.1731, SORS: 2.4863', '\\n', 'Epoch 4/50, Train Loss:\n11.9251, Val Loss: 12.0200, SORS: 2.4837', '\\n', 'Epoch 5/50, Train Loss:\n11.7826, Val Loss: 11.8685, SORS: 2.4823', '\\n', 'Epoch 6/50, Train Loss:\n11.6414, Val Loss: 11.7185, SORS: 2.4819', '\\n', 'Epoch 7/50, Train Loss:\n11.5020, Val Loss: 11.5700, SORS: 2.4817', '\\n', 'Epoch 8/50, Train Loss:\n11.3640, Val Loss: 11.4228, SORS: 2.4818', '\\n', 'Epoch 9/50, Train Loss:\n11.2276, Val Loss: 11.2770, SORS: 2.4818', '\\n', 'Epoch 10/50, Train Loss:\n11.0923, Val Loss: 11.1325, SORS: 2.4819', '\\n', 'Epoch 11/50, Train Loss:\n10.9580, Val Loss: 10.9893, SORS: 2.4820', '\\n', 'Epoch 12/50, Train Loss:\n10.8250, Val Loss: 10.8474, SORS: 2.4821', '\\n', 'Epoch 13/50, Train Loss:\n10.6932, Val Loss: 10.7064, SORS: 2.4821', '\\n', 'Epoch 14/50, Train Loss:\n10.5624, Val Loss: 10.5665, SORS: 2.4822', '\\n', 'Epoch 15/50, Train Loss:\n10.4327, Val Loss: 10.4276, SORS: 2.4824', '\\n', 'Epoch 16/50, Train Loss:\n10.3031, Val Loss: 10.2896, SORS: 2.4825', '\\n', 'Epoch 17/50, Train Loss:\n10.1742, Val Loss: 10.1524, SORS: 2.4827', '\\n', 'Epoch 18/50, Train Loss:\n10.0461, Val Loss: 10.0160, SORS: 2.4828', '\\n', 'Epoch 19/50, Train Loss:\n9.9191, Val Loss: 9.8805, SORS: 2.4830', '\\n', 'Epoch 20/50, Train Loss: 9.7935,\nVal Loss: 9.7461, SORS: 2.4832', '\\n', 'Epoch 21/50, Train Loss: 9.6689, Val\nLoss: 9.6130, SORS: 2.4834', '\\n', 'Epoch 22/50, Train Loss: 9.5456, Val Loss:\n9.4810, SORS: 2.4836', '\\n', 'Epoch 23/50, Train Loss: 9.4241, Val Loss: 9.3500,\nSORS: 2.4839', '\\n', 'Epoch 24/50, Train Loss: 9.3037, Val Loss: 9.2204, SORS:\n2.4841', '\\n', 'Epoch 25/50, Train Loss: 9.1839, Val Loss: 9.0920, SORS:\n2.4843', '\\n', 'Epoch 26/50, Train Loss: 9.0658, Val Loss: 8.9653, SORS:\n2.4845', '\\n', 'Epoch 27/50, Train Loss: 8.9497, Val Loss: 8.8403, SORS:\n2.4846', '\\n', 'Epoch 28/50, Train Loss: 8.8358, Val Loss: 8.7174, SORS:\n2.4848', '\\n', 'Epoch 29/50, Train Loss: 8.7234, Val Loss: 8.5965, SORS:\n2.4849', '\\n', 'Epoch 30/50, Train Loss: 8.6135, Val Loss: 8.4779, SORS:\n2.4851', '\\n', 'Epoch 31/50, Train Loss: 8.5053, Val Loss: 8.3620, SORS:\n2.4852', '\\n', 'Epoch 32/50, Train Loss: 8.3990, Val Loss: 8.2488, SORS:\n2.4854', '\\n', 'Epoch 33/50, Train Loss: 8.2951, Val Loss: 8.1383, SORS:\n2.4855', '\\n', 'Epoch 34/50, Train Loss: 8.1943, Val Loss: 8.0305, SORS:\n2.4856', '\\n', 'Epoch 35/50, Train Loss: 8.0969, Val Loss: 7.9259, SORS:\n2.4856', '\\n', 'Epoch 36/50, Train Loss: 8.0025, Val Loss: 7.8249, SORS:\n2.4857', '\\n', 'Epoch 37/50, Train Loss: 7.9113, Val Loss: 7.7277, SORS:\n2.4857', '\\n', 'Epoch 38/50, Train Loss: 7.8233, Val Loss: 7.6343, SORS:\n2.4858', '\\n', 'Epoch 39/50, Train Loss: 7.7389, Val Loss: 7.5451, SORS:\n2.4858', '\\n', 'Epoch 40/50, Train Loss: 7.6587, Val Loss: 7.4602, SORS:\n2.4858', '\\n', 'Epoch 41/50, Train Loss: 7.5825, Val Loss: 7.3797, SORS:\n2.4859', '\\n', 'Epoch 42/50, Train Loss: 7.5107, Val Loss: 7.3036, SORS:\n2.4859', '\\n', 'Epoch 43/50, Train Loss: 7.4421, Val Loss: 7.2318, SORS:\n2.4859', '\\n', 'Epoch 44/50, Train Loss: 7.3770, Val Loss: 7.1643, SORS:\n2.4858', '\\n', 'Epoch 45/50, Train Loss: 7.3157, Val Loss: 7.1011, SORS:\n2.4856', '\\n', 'Epoch 46/50, Train Loss: 7.2580, Val Loss: 7.0426, SORS:\n2.4855', '\\n', 'Epoch 47/50, Train Loss: 7.2038, Val Loss: 6.9887, SORS:\n2.4854', '\\n', 'Epoch 48/50, Train Loss: 7.1525, Val Loss: 6.9394, SORS:\n2.4853', '\\n', 'Epoch 49/50, Train Loss: 7.1039, Val Loss: 6.8944, SORS:\n2.4853', '\\n', 'Epoch 50/50, Train Loss: 7.0587, Val Loss: 6.8536, SORS:\n2.4852', '\\n', 'Execution time: 23 seconds seconds (time limit is 10 minutes).']", "['Using device: cuda', '\\n', 'Evaluating on dataset_1', '\\n', ' Training with\nbatch size: 16', '\\n', ' Epoch 1/50, Train Loss: 7.5192, Val Loss: 8.3129, SORS:\n2.3626', '\\n', ' Epoch 2/50, Train Loss: 6.3991, Val Loss: 6.3954, SORS:\n2.4497', '\\n', ' Epoch 3/50, Train Loss: 6.7254, Val Loss: 6.3912, SORS:\n2.4811', '\\n', ' Epoch 4/50, Train Loss: 6.7193, Val Loss: 6.3927, SORS:\n2.4813', '\\n', ' Epoch 5/50, Train Loss: 6.6935, Val Loss: 6.3887, SORS:\n2.4807', '\\n', ' Epoch 6/50, Train Loss: 6.6735, Val Loss: 6.3860, SORS:\n2.4802', '\\n', ' Epoch 7/50, Train Loss: 6.6546, Val Loss: 6.3836, SORS:\n2.4798', '\\n', ' Epoch 8/50, Train Loss: 6.6372, Val Loss: 6.3815, SORS:\n2.4794', '\\n', ' Epoch 9/50, Train Loss: 6.6187, Val Loss: 6.3795, SORS:\n2.4790', '\\n', ' Epoch 10/50, Train Loss: 6.5991, Val Loss: 6.3780, SORS:\n2.4786', '\\n', ' Epoch 11/50, Train Loss: 6.5802, Val Loss: 6.3766, SORS:\n2.4783', '\\n', ' Epoch 12/50, Train Loss: 6.5462, Val Loss: 6.3765, SORS:\n2.4781', '\\n', ' Epoch 13/50, Train Loss: 6.5121, Val Loss: 6.3770, SORS:\n2.4781', '\\n', ' Epoch 14/50, Train Loss: 6.4852, Val Loss: 6.3785, SORS:\n2.4782', '\\n', ' Epoch 15/50, Train Loss: 6.4704, Val Loss: 6.3791, SORS:\n2.4781', '\\n', ' Epoch 16/50, Train Loss: 6.4552, Val Loss: 6.3781, SORS:\n2.4778', '\\n', ' Epoch 17/50, Train Loss: 6.4403, Val Loss: 6.3779, SORS:\n2.4777', '\\n', ' Epoch 18/50, Train Loss: 6.4199, Val Loss: 6.3796, SORS:\n2.4778', '\\n', ' Epoch 19/50, Train Loss: 6.4053, Val Loss: 6.3794, SORS:\n2.4776', '\\n', ' Epoch 20/50, Train Loss: 6.3916, Val Loss: 6.3803, SORS:\n2.4777', '\\n', ' Epoch 21/50, Train Loss: 6.3781, Val Loss: 6.3803, SORS:\n2.4775', '\\n', ' Epoch 22/50, Train Loss: 6.3607, Val Loss: 6.3812, SORS:\n2.4775', '\\n', ' Epoch 23/50, Train Loss: 6.3475, Val Loss: 6.3826, SORS:\n2.4776', '\\n', ' Epoch 24/50, Train Loss: 6.3354, Val Loss: 6.3832, SORS:\n2.4776', '\\n', ' Epoch 25/50, Train Loss: 6.3185, Val Loss: 6.3847, SORS:\n2.4777', '\\n', ' Epoch 26/50, Train Loss: 6.3059, Val Loss: 6.3853, SORS:\n2.4776', '\\n', ' Epoch 27/50, Train Loss: 6.2917, Val Loss: 6.3869, SORS:\n2.4777', '\\n', ' Epoch 28/50, Train Loss: 6.2766, Val Loss: 6.3887, SORS:\n2.4779', '\\n', ' Epoch 29/50, Train Loss: 6.2665, Val Loss: 6.3895, SORS:\n2.4778', '\\n', ' Epoch 30/50, Train Loss: 6.2582, Val Loss: 6.3905, SORS:\n2.4779', '\\n', ' Epoch 31/50, Train Loss: 6.2503, Val Loss: 6.3906, SORS:\n2.4778', '\\n', ' Epoch 32/50, Train Loss: 6.2397, Val Loss: 6.3913, SORS:\n2.4778', '\\n', ' Epoch 33/50, Train Loss: 6.2276, Val Loss: 6.3920, SORS:\n2.4778', '\\n', ' Epoch 34/50, Train Loss: 6.2198, Val Loss: 6.3934, SORS:\n2.4779', '\\n', ' Epoch 35/50, Train Loss: 6.2077, Val Loss: 6.3950, SORS:\n2.4781', '\\n', ' Epoch 36/50, Train Loss: 6.1995, Val Loss: 6.3966, SORS:\n2.4782', '\\n', ' Epoch 37/50, Train Loss: 6.2009, Val Loss: 6.3968, SORS:\n2.4782', '\\n', ' Epoch 38/50, Train Loss: 6.1881, Val Loss: 6.3983, SORS:\n2.4783', '\\n', ' Epoch 39/50, Train Loss: 6.1801, Val Loss: 6.4002, SORS:\n2.4785', '\\n', ' Epoch 40/50, Train Loss: 6.1677, Val Loss: 6.4016, SORS:\n2.4787', '\\n', ' Epoch 41/50, Train Loss: 6.1652, Val Loss: 6.4028, SORS:\n2.4788', '\\n', ' Epoch 42/50, Train Loss: 6.1544, Val Loss: 6.4043, SORS:\n2.4790', '\\n', ' Epoch 43/50, Train Loss: 6.1449, Val Loss: 6.4032, SORS:\n2.4786', '\\n', ' Epoch 44/50, Train Loss: 6.1415, Val Loss: 6.4059, SORS:\n2.4790', '\\n', ' Epoch 45/50, Train Loss: 6.1342, Val Loss: 6.4076, SORS:\n2.4793', '\\n', ' Epoch 46/50, Train Loss: 6.1231, Val Loss: 6.4082, SORS:\n2.4792', '\\n', ' Epoch 47/50, Train Loss: 6.1207, Val Loss: 6.4099, SORS:\n2.4795', '\\n', ' Epoch 48/50, Train Loss: 6.1154, Val Loss: 6.4107, SORS:\n2.4795', '\\n', ' Epoch 49/50, Train Loss: 6.1122, Val Loss: 6.4111, SORS:\n2.4796', '\\n', ' Epoch 50/50, Train Loss: 6.1021, Val Loss: 6.4131, SORS:\n2.4798', '\\n', ' Training with batch size: 32', '\\n', ' Epoch 1/50, Train Loss:\n8.7547, Val Loss: 9.5195, SORS: 2.3451', '\\n', ' Epoch 2/50, Train Loss: 7.3674,\nVal Loss: 7.9584, SORS: 2.3838', '\\n', ' Epoch 3/50, Train Loss: 6.3897, Val\nLoss: 6.8066, SORS: 2.4303', '\\n', ' Epoch 4/50, Train Loss: 6.1478, Val Loss:\n6.4135, SORS: 2.4705', '\\n', ' Epoch 5/50, Train Loss: 6.2564, Val Loss: 6.4382,\nSORS: 2.4908', '\\n', ' Epoch 6/50, Train Loss: 6.2958, Val Loss: 6.4585, SORS:\n2.4944', '\\n', ' Epoch 7/50, Train Loss: 6.2857, Val Loss: 6.4524, SORS:\n2.4935', '\\n', ' Epoch 8/50, Train Loss: 6.2763, Val Loss: 6.4473, SORS:\n2.4927', '\\n', ' Epoch 9/50, Train Loss: 6.2711, Val Loss: 6.4446, SORS:\n2.4923', '\\n', ' Epoch 10/50, Train Loss: 6.2665, Val Loss: 6.4423, SORS:\n2.4920', '\\n', ' Epoch 11/50, Train Loss: 6.2619, Val Loss: 6.4400, SORS:\n2.4916', '\\n', ' Epoch 12/50, Train Loss: 6.2570, Val Loss: 6.4376, SORS:\n2.4912', '\\n', ' Epoch 13/50, Train Loss: 6.2524, Val Loss: 6.4353, SORS:\n2.4909', '\\n', ' Epoch 14/50, Train Loss: 6.2477, Val Loss: 6.4331, SORS:\n2.4905', '\\n', ' Epoch 15/50, Train Loss: 6.2432, Val Loss: 6.4311, SORS:\n2.4902', '\\n', ' Epoch 16/50, Train Loss: 6.2385, Val Loss: 6.4290, SORS:\n2.4898', '\\n', ' Epoch 17/50, Train Loss: 6.2343, Val Loss: 6.4270, SORS:\n2.4895', '\\n', ' Epoch 18/50, Train Loss: 6.2296, Val Loss: 6.4250, SORS:\n2.4891', '\\n', ' Epoch 19/50, Train Loss: 6.2263, Val Loss: 6.4234, SORS:\n2.4888', '\\n', ' Epoch 20/50, Train Loss: 6.2212, Val Loss: 6.4213, SORS:\n2.4884', '\\n', ' Epoch 21/50, Train Loss: 6.2158, Val Loss: 6.4194, SORS:\n2.4880', '\\n', ' Epoch 22/50, Train Loss: 6.2117, Val Loss: 6.4181, SORS:\n2.4877', '\\n', ' Epoch 23/50, Train Loss: 6.2065, Val Loss: 6.4164, SORS:\n2.4874', '\\n', ' Epoch 24/50, Train Loss: 6.2019, Val Loss: 6.4148, SORS:\n2.4871', '\\n', ' Epoch 25/50, Train Loss: 6.1973, Val Loss: 6.4134, SORS:\n2.4868', '\\n', ' Epoch 26/50, Train Loss: 6.1930, Val Loss: 6.4119, SORS:\n2.4864', '\\n', ' Epoch 27/50, Train Loss: 6.1886, Val Loss: 6.4104, SORS:\n2.4861', '\\n', ' Epoch 28/50, Train Loss: 6.1850, Val Loss: 6.4091, SORS:\n2.4858', '\\n', ' Epoch 29/50, Train Loss: 6.1811, Val Loss: 6.4077, SORS:\n2.4854', '\\n', ' Epoch 30/50, Train Loss: 6.1768, Val Loss: 6.4064, SORS:\n2.4851', '\\n', ' Epoch 31/50, Train Loss: 6.1731, Val Loss: 6.4052, SORS:\n2.4848', '\\n', ' Epoch 32/50, Train Loss: 6.1693, Val Loss: 6.4042, SORS:\n2.4845', '\\n', ' Epoch 33/50, Train Loss: 6.1649, Val Loss: 6.4033, SORS:\n2.4843', '\\n', ' Epoch 34/50, Train Loss: 6.1614, Val Loss: 6.4023, SORS:\n2.4840', '\\n', ' Epoch 35/50, Train Loss: 6.1580, Val Loss: 6.4015, SORS:\n2.4838', '\\n', ' Epoch 36/50, Train Loss: 6.1541, Val Loss: 6.4006, SORS:\n2.4835', '\\n', ' Epoch 37/50, Train Loss: 6.1511, Val Loss: 6.3998, SORS:\n2.4833', '\\n', ' Epoch 38/50, Train Loss: 6.1475, Val Loss: 6.3993, SORS:\n2.4831', '\\n', ' Epoch 39/50, Train Loss: 6.1440, Val Loss: 6.3986, SORS:\n2.4829', '\\n', ' Epoch 40/50, Train Loss: 6.1411, Val Loss: 6.3981, SORS:\n2.4827', '\\n', ' Epoch 41/50, Train Loss: 6.1379, Val Loss: 6.3973, SORS:\n2.4824', '\\n', ' Epoch 42/50, Train Loss: 6.1344, Val Loss: 6.3970, SORS:\n2.4822', '\\n', ' Epoch 43/50, Train Loss: 6.1311, Val Loss: 6.3961, SORS:\n2.4820', '\\n', ' Epoch 44/50, Train Loss: 6.1283, Val Loss: 6.3956, SORS:\n2.4817', '\\n', ' Epoch 45/50, Train Loss: 6.1242, Val Loss: 6.3950, SORS:\n2.4815', '\\n', ' Epoch 46/50, Train Loss: 6.1218, Val Loss: 6.3944, SORS:\n2.4813', '\\n', ' Epoch 47/50, Train Loss: 6.1181, Val Loss: 6.3944, SORS:\n2.4812', '\\n', ' Epoch 48/50, Train Loss: 6.1165, Val Loss: 6.3939, SORS:\n2.4810', '\\n', ' Epoch 49/50, Train Loss: 6.1120, Val Loss: 6.3936, SORS:\n2.4808', '\\n', ' Epoch 50/50, Train Loss: 6.1099, Val Loss: 6.3932, SORS:\n2.4806', '\\n', ' Training with batch size: 64', '\\n', ' Epoch 1/50, Train Loss:\n10.5389, Val Loss: 11.4941, SORS: 2.3237', '\\n', ' Epoch 2/50, Train Loss:\n9.8915, Val Loss: 10.7962, SORS: 2.3136', '\\n', ' Epoch 3/50, Train Loss:\n9.2643, Val Loss: 10.1125, SORS: 2.3253', '\\n', ' Epoch 4/50, Train Loss:\n8.6190, Val Loss: 9.3874, SORS: 2.3405', '\\n', ' Epoch 5/50, Train Loss: 7.9459,\nVal Loss: 8.5980, SORS: 2.3573', '\\n', ' Epoch 6/50, Train Loss: 7.2518, Val\nLoss: 7.7996, SORS: 2.3782', '\\n', ' Epoch 7/50, Train Loss: 6.6761, Val Loss:\n7.1091, SORS: 2.4008', '\\n', ' Epoch 8/50, Train Loss: 6.3247, Val Loss: 6.6440,\nSORS: 2.4238', '\\n', ' Epoch 9/50, Train Loss: 6.2012, Val Loss: 6.4155, SORS:\n2.4439', '\\n', ' Epoch 10/50, Train Loss: 6.2261, Val Loss: 6.3571, SORS:\n2.4594', '\\n', ' Epoch 11/50, Train Loss: 6.2962, Val Loss: 6.3716, SORS:\n2.4693', '\\n', ' Epoch 12/50, Train Loss: 6.3473, Val Loss: 6.3938, SORS:\n2.4743', '\\n', ' Epoch 13/50, Train Loss: 6.3668, Val Loss: 6.4039, SORS:\n2.4761', '\\n', ' Epoch 14/50, Train Loss: 6.3668, Val Loss: 6.4047, SORS:\n2.4763', '\\n', ' Epoch 15/50, Train Loss: 6.3599, Val Loss: 6.4023, SORS:\n2.4760', '\\n', ' Epoch 16/50, Train Loss: 6.3525, Val Loss: 6.3998, SORS:\n2.4757', '\\n', ' Epoch 17/50, Train Loss: 6.3465, Val Loss: 6.3981, SORS:\n2.4755', '\\n', ' Epoch 18/50, Train Loss: 6.3418, Val Loss: 6.3970, SORS:\n2.4754', '\\n', ' Epoch 19/50, Train Loss: 6.3377, Val Loss: 6.3963, SORS:\n2.4754', '\\n', ' Epoch 20/50, Train Loss: 6.3339, Val Loss: 6.3957, SORS:\n2.4754', '\\n', ' Epoch 21/50, Train Loss: 6.3302, Val Loss: 6.3952, SORS:\n2.4754', '\\n', ' Epoch 22/50, Train Loss: 6.3264, Val Loss: 6.3946, SORS:\n2.4754', '\\n', ' Epoch 23/50, Train Loss: 6.3227, Val Loss: 6.3940, SORS:\n2.4754', '\\n', ' Epoch 24/50, Train Loss: 6.3189, Val Loss: 6.3934, SORS:\n2.4753', '\\n', ' Epoch 25/50, Train Loss: 6.3151, Val Loss: 6.3929, SORS:\n2.4753', '\\n', ' Epoch 26/50, Train Loss: 6.3113, Val Loss: 6.3923, SORS:\n2.4753', '\\n', ' Epoch 27/50, Train Loss: 6.3075, Val Loss: 6.3918, SORS:\n2.4753', '\\n', ' Epoch 28/50, Train Loss: 6.3038, Val Loss: 6.3913, SORS:\n2.4753', '\\n', ' Epoch 29/50, Train Loss: 6.3000, Val Loss: 6.3908, SORS:\n2.4752', '\\n', ' Epoch 30/50, Train Loss: 6.2963, Val Loss: 6.3904, SORS:\n2.4752', '\\n', ' Epoch 31/50, Train Loss: 6.2927, Val Loss: 6.3899, SORS:\n2.4752', '\\n', ' Epoch 32/50, Train Loss: 6.2891, Val Loss: 6.3894, SORS:\n2.4752', '\\n', ' Epoch 33/50, Train Loss: 6.2855, Val Loss: 6.3889, SORS:\n2.4752', '\\n', ' Epoch 34/50, Train Loss: 6.2820, Val Loss: 6.3885, SORS:\n2.4751', '\\n', ' Epoch 35/50, Train Loss: 6.2783, Val Loss: 6.3880, SORS:\n2.4751', '\\n', ' Epoch 36/50, Train Loss: 6.2745, Val Loss: 6.3875, SORS:\n2.4751', '\\n', ' Epoch 37/50, Train Loss: 6.2704, Val Loss: 6.3871, SORS:\n2.4751', '\\n', ' Epoch 38/50, Train Loss: 6.2664, Val Loss: 6.3867, SORS:\n2.4751', '\\n', ' Epoch 39/50, Train Loss: 6.2627, Val Loss: 6.3863, SORS:\n2.4750', '\\n', ' Epoch 40/50, Train Loss: 6.2592, Val Loss: 6.3859, SORS:\n2.4750', '\\n', ' Epoch 41/50, Train Loss: 6.2558, Val Loss: 6.3856, SORS:\n2.4750', '\\n', ' Epoch 42/50, Train Loss: 6.2523, Val Loss: 6.3853, SORS:\n2.4750', '\\n', ' Epoch 43/50, Train Loss: 6.2488, Val Loss: 6.3851, SORS:\n2.4750', '\\n', ' Epoch 44/50, Train Loss: 6.2452, Val Loss: 6.3848, SORS:\n2.4750', '\\n', ' Epoch 45/50, Train Loss: 6.2416, Val Loss: 6.3845, SORS:\n2.4750', '\\n', ' Epoch 46/50, Train Loss: 6.2380, Val Loss: 6.3843, SORS:\n2.4750', '\\n', ' Epoch 47/50, Train Loss: 6.2343, Val Loss: 6.3840, SORS:\n2.4750', '\\n', ' Epoch 48/50, Train Loss: 6.2306, Val Loss: 6.3838, SORS:\n2.4749', '\\n', ' Epoch 49/50, Train Loss: 6.2269, Val Loss: 6.3835, SORS:\n2.4749', '\\n', ' Epoch 50/50, Train Loss: 6.2233, Val Loss: 6.3833, SORS:\n2.4749', '\\n', ' Training with batch size: 128', '\\n', ' Epoch 1/50, Train Loss:\n9.9368, Val Loss: 10.6142, SORS: 2.3151', '\\n', ' Epoch 2/50, Train Loss:\n9.5308, Val Loss: 10.1388, SORS: 2.3213', '\\n', ' Epoch 3/50, Train Loss:\n9.1425, Val Loss: 9.6806, SORS: 2.3288', '\\n', ' Epoch 4/50, Train Loss: 8.7742,\nVal Loss: 9.2342, SORS: 2.3368', '\\n', ' Epoch 5/50, Train Loss: 8.4176, Val\nLoss: 8.7955, SORS: 2.3452', '\\n', ' Epoch 6/50, Train Loss: 8.0634, Val Loss:\n8.3656, SORS: 2.3544', '\\n', ' Epoch 7/50, Train Loss: 7.7194, Val Loss: 7.9471,\nSORS: 2.3645', '\\n', ' Epoch 8/50, Train Loss: 7.4026, Val Loss: 7.5546, SORS:\n2.3767', '\\n', ' Epoch 9/50, Train Loss: 7.1115, Val Loss: 7.1972, SORS:\n2.3898', '\\n', ' Epoch 10/50, Train Loss: 6.8553, Val Loss: 6.8850, SORS:\n2.4029', '\\n', ' Epoch 11/50, Train Loss: 6.6610, Val Loss: 6.6357, SORS:\n2.4163', '\\n', ' Epoch 12/50, Train Loss: 6.5357, Val Loss: 6.4584, SORS:\n2.4295', '\\n', ' Epoch 13/50, Train Loss: 6.4775, Val Loss: 6.3499, SORS:\n2.4412', '\\n', ' Epoch 14/50, Train Loss: 6.4689, Val Loss: 6.3012, SORS:\n2.4514', '\\n', ' Epoch 15/50, Train Loss: 6.4930, Val Loss: 6.2933, SORS:\n2.4597', '\\n', ' Epoch 16/50, Train Loss: 6.5292, Val Loss: 6.3058, SORS:\n2.4659', '\\n', ' Epoch 17/50, Train Loss: 6.5605, Val Loss: 6.3225, SORS:\n2.4700', '\\n', ' Epoch 18/50, Train Loss: 6.5791, Val Loss: 6.3352, SORS:\n2.4724', '\\n', ' Epoch 19/50, Train Loss: 6.5847, Val Loss: 6.3415, SORS:\n2.4735', '\\n', ' Epoch 20/50, Train Loss: 6.5805, Val Loss: 6.3427, SORS:\n2.4738', '\\n', ' Epoch 21/50, Train Loss: 6.5707, Val Loss: 6.3411, SORS:\n2.4736', '\\n', ' Epoch 22/50, Train Loss: 6.5589, Val Loss: 6.3385, SORS:\n2.4732', '\\n', ' Epoch 23/50, Train Loss: 6.5471, Val Loss: 6.3360, SORS:\n2.4728', '\\n', ' Epoch 24/50, Train Loss: 6.5364, Val Loss: 6.3342, SORS:\n2.4726', '\\n', ' Epoch 25/50, Train Loss: 6.5270, Val Loss: 6.3331, SORS:\n2.4724', '\\n', ' Epoch 26/50, Train Loss: 6.5188, Val Loss: 6.3327, SORS:\n2.4724', '\\n', ' Epoch 27/50, Train Loss: 6.5114, Val Loss: 6.3327, SORS:\n2.4725', '\\n', ' Epoch 28/50, Train Loss: 6.5047, Val Loss: 6.3330, SORS:\n2.4726', '\\n', ' Epoch 29/50, Train Loss: 6.4981, Val Loss: 6.3334, SORS:\n2.4727', '\\n', ' Epoch 30/50, Train Loss: 6.4917, Val Loss: 6.3339, SORS:\n2.4728', '\\n', ' Epoch 31/50, Train Loss: 6.4853, Val Loss: 6.3344, SORS:\n2.4729', '\\n', ' Epoch 32/50, Train Loss: 6.4787, Val Loss: 6.3349, SORS:\n2.4730', '\\n', ' Epoch 33/50, Train Loss: 6.4721, Val Loss: 6.3354, SORS:\n2.4732', '\\n', ' Epoch 34/50, Train Loss: 6.4655, Val Loss: 6.3358, SORS:\n2.4733', '\\n', ' Epoch 35/50, Train Loss: 6.4588, Val Loss: 6.3361, SORS:\n2.4734', '\\n', ' Epoch 36/50, Train Loss: 6.4521, Val Loss: 6.3366, SORS:\n2.4735', '\\n', ' Epoch 37/50, Train Loss: 6.4453, Val Loss: 6.3371, SORS:\n2.4736', '\\n', ' Epoch 38/50, Train Loss: 6.4386, Val Loss: 6.3375, SORS:\n2.4737', '\\n', ' Epoch 39/50, Train Loss: 6.4319, Val Loss: 6.3379, SORS:\n2.4738', '\\n', ' Epoch 40/50, Train Loss: 6.4253, Val Loss: 6.3384, SORS:\n2.4739', '\\n', ' Epoch 41/50, Train Loss: 6.4186, Val Loss: 6.3388, SORS:\n2.4740', '\\n', ' Epoch 42/50, Train Loss: 6.4120, Val Loss: 6.3393, SORS:\n2.4741', '\\n', ' Epoch 43/50, Train Loss: 6.4054, Val Loss: 6.3398, SORS:\n2.4741', '\\n', ' Epoch 44/50, Train Loss: 6.3988, Val Loss: 6.3403, SORS:\n2.4742', '\\n', ' Epoch 45/50, Train Loss: 6.3922, Val Loss: 6.3408, SORS:\n2.4743', '\\n', ' Epoch 46/50, Train Loss: 6.3857, Val Loss: 6.3413, SORS:\n2.4744', '\\n', ' Epoch 47/50, Train Loss: 6.3792, Val Loss: 6.3417, SORS:\n2.4745', '\\n', ' Epoch 48/50, Train Loss: 6.3727, Val Loss: 6.3423, SORS:\n2.4746', '\\n', ' Epoch 49/50, Train Loss: 6.3662, Val Loss: 6.3428, SORS:\n2.4747', '\\n', ' Epoch 50/50, Train Loss: 6.3597, Val Loss: 6.3434, SORS:\n2.4748', '\\n', ' Training with batch size: 256', '\\n', ' Epoch 1/50, Train Loss:\n10.6213, Val Loss: 11.5981, SORS: 2.3282', '\\n', ' Epoch 2/50, Train Loss:\n10.4216, Val Loss: 11.3900, SORS: 2.3160', '\\n', ' Epoch 3/50, Train Loss:\n10.2224, Val Loss: 11.1815, SORS: 2.3122', '\\n', ' Epoch 4/50, Train Loss:\n10.0234, Val Loss: 10.9697, SORS: 2.3129', '\\n', ' Epoch 5/50, Train Loss:\n9.8255, Val Loss: 10.7524, SORS: 2.3151', '\\n', ' Epoch 6/50, Train Loss:\n9.6265, Val Loss: 10.5294, SORS: 2.3184', '\\n', ' Epoch 7/50, Train Loss:\n9.4266, Val Loss: 10.2991, SORS: 2.3222', '\\n', ' Epoch 8/50, Train Loss:\n9.2223, Val Loss: 10.0609, SORS: 2.3262', '\\n', ' Epoch 9/50, Train Loss:\n9.0121, Val Loss: 9.8128, SORS: 2.3305', '\\n', ' Epoch 10/50, Train Loss:\n8.7956, Val Loss: 9.5559, SORS: 2.3351', '\\n', ' Epoch 11/50, Train Loss:\n8.5746, Val Loss: 9.2925, SORS: 2.3401', '\\n', ' Epoch 12/50, Train Loss:\n8.3500, Val Loss: 9.0232, SORS: 2.3454', '\\n', ' Epoch 13/50, Train Loss:\n8.1234, Val Loss: 8.7509, SORS: 2.3513', '\\n', ' Epoch 14/50, Train Loss:\n7.8918, Val Loss: 8.4769, SORS: 2.3576', '\\n', ' Epoch 15/50, Train Loss:\n7.6630, Val Loss: 8.2048, SORS: 2.3642', '\\n', ' Epoch 16/50, Train Loss:\n7.4408, Val Loss: 7.9371, SORS: 2.3709', '\\n', ' Epoch 17/50, Train Loss:\n7.2307, Val Loss: 7.6797, SORS: 2.3781', '\\n', ' Epoch 18/50, Train Loss:\n7.0358, Val Loss: 7.4385, SORS: 2.3859', '\\n', ' Epoch 19/50, Train Loss:\n6.8571, Val Loss: 7.2168, SORS: 2.3940', '\\n', ' Epoch 20/50, Train Loss:\n6.6965, Val Loss: 7.0173, SORS: 2.4024', '\\n', ' Epoch 21/50, Train Loss:\n6.5591, Val Loss: 6.8441, SORS: 2.4108', '\\n', ' Epoch 22/50, Train Loss:\n6.4481, Val Loss: 6.6982, SORS: 2.4193', '\\n', ' Epoch 23/50, Train Loss:\n6.3656, Val Loss: 6.5809, SORS: 2.4274', '\\n', ' Epoch 24/50, Train Loss:\n6.3092, Val Loss: 6.4927, SORS: 2.4353', '\\n', ' Epoch 25/50, Train Loss:\n6.2781, Val Loss: 6.4317, SORS: 2.4428', '\\n', ' Epoch 26/50, Train Loss:\n6.2658, Val Loss: 6.3935, SORS: 2.4496', '\\n', ' Epoch 27/50, Train Loss:\n6.2670, Val Loss: 6.3737, SORS: 2.4556', '\\n', ' Epoch 28/50, Train Loss:\n6.2788, Val Loss: 6.3669, SORS: 2.4608', '\\n', ' Epoch 29/50, Train Loss:\n6.2960, Val Loss: 6.3690, SORS: 2.4651', '\\n', ' Epoch 30/50, Train Loss:\n6.3141, Val Loss: 6.3759, SORS: 2.4686', '\\n', ' Epoch 31/50, Train Loss:\n6.3300, Val Loss: 6.3841, SORS: 2.4713', '\\n', ' Epoch 32/50, Train Loss:\n6.3419, Val Loss: 6.3916, SORS: 2.4732', '\\n', ' Epoch 33/50, Train Loss:\n6.3488, Val Loss: 6.3971, SORS: 2.4745', '\\n', ' Epoch 34/50, Train Loss:\n6.3508, Val Loss: 6.4005, SORS: 2.4753', '\\n', ' Epoch 35/50, Train Loss:\n6.3485, Val Loss: 6.4020, SORS: 2.4756', '\\n', ' Epoch 36/50, Train Loss:\n6.3427, Val Loss: 6.4020, SORS: 2.4757', '\\n', ' Epoch 37/50, Train Loss:\n6.3344, Val Loss: 6.4009, SORS: 2.4755', '\\n', ' Epoch 38/50, Train Loss:\n6.3247, Val Loss: 6.3993, SORS: 2.4753', '\\n', ' Epoch 39/50, Train Loss:\n6.3146, Val Loss: 6.3974, SORS: 2.4750', '\\n', ' Epoch 40/50, Train Loss:\n6.3046, Val Loss: 6.3958, SORS: 2.4747', '\\n', ' Epoch 41/50, Train Loss:\n6.2953, Val Loss: 6.3943, SORS: 2.4744', '\\n', ' Epoch 42/50, Train Loss:\n6.2866, Val Loss: 6.3931, SORS: 2.4741', '\\n', ' Epoch 43/50, Train Loss:\n6.2779, Val Loss: 6.3920, SORS: 2.4739', '\\n', ' Epoch 44/50, Train Loss:\n6.2692, Val Loss: 6.3910, SORS: 2.4738', '\\n', ' Epoch 45/50, Train Loss:\n6.2608, Val Loss: 6.3902, SORS: 2.4736', '\\n', ' Epoch 46/50, Train Loss:\n6.2529, Val Loss: 6.3897, SORS: 2.4736', '\\n', ' Epoch 47/50, Train Loss:\n6.2457, Val Loss: 6.3895, SORS: 2.4736', '\\n', ' Epoch 48/50, Train Loss:\n6.2388, Val Loss: 6.3895, SORS: 2.4736', '\\n', ' Epoch 49/50, Train Loss:\n6.2323, Val Loss: 6.3895, SORS: 2.4736', '\\n', ' Epoch 50/50, Train Loss:\n6.2260, Val Loss: 6.3897, SORS: 2.4737', '\\n', 'Evaluating on dataset_2', '\\n',\n' Training with batch size: 16', '\\n', ' Epoch 1/50, Train Loss: 16.3728, Val\nLoss: 11.7040, SORS: 2.6889', '\\n', ' Epoch 2/50, Train Loss: 10.2061, Val Loss:\n7.9719, SORS: 2.6241', '\\n', ' Epoch 3/50, Train Loss: 7.2796, Val Loss: 6.9033,\nSORS: 2.5776', '\\n', ' Epoch 4/50, Train Loss: 7.0055, Val Loss: 6.8667, SORS:\n2.5719', '\\n', ' Epoch 5/50, Train Loss: 6.9903, Val Loss: 6.8648, SORS:\n2.5716', '\\n', ' Epoch 6/50, Train Loss: 6.9646, Val Loss: 6.8621, SORS:\n2.5712', '\\n', ' Epoch 7/50, Train Loss: 6.9404, Val Loss: 6.8594, SORS:\n2.5706', '\\n', ' Epoch 8/50, Train Loss: 6.9135, Val Loss: 6.8567, SORS:\n2.5701', '\\n', ' Epoch 9/50, Train Loss: 6.8909, Val Loss: 6.8543, SORS:\n2.5694', '\\n', ' Epoch 10/50, Train Loss: 6.8706, Val Loss: 6.8523, SORS:\n2.5690', '\\n', ' Epoch 11/50, Train Loss: 6.8473, Val Loss: 6.8504, SORS:\n2.5684', '\\n', ' Epoch 12/50, Train Loss: 6.8248, Val Loss: 6.8479, SORS:\n2.5676', '\\n', ' Epoch 13/50, Train Loss: 6.8024, Val Loss: 6.8464, SORS:\n2.5670', '\\n', ' Epoch 14/50, Train Loss: 6.7761, Val Loss: 6.8451, SORS:\n2.5665', '\\n', ' Epoch 15/50, Train Loss: 6.7555, Val Loss: 6.8440, SORS:\n2.5659', '\\n', ' Epoch 16/50, Train Loss: 6.7379, Val Loss: 6.8420, SORS:\n2.5651', '\\n', ' Epoch 17/50, Train Loss: 6.7166, Val Loss: 6.8394, SORS:\n2.5642', '\\n', ' Epoch 18/50, Train Loss: 6.7026, Val Loss: 6.8383, SORS:\n2.5637', '\\n', ' Epoch 19/50, Train Loss: 6.6836, Val Loss: 6.8383, SORS:\n2.5633', '\\n', ' Epoch 20/50, Train Loss: 6.6659, Val Loss: 6.8379, SORS:\n2.5628', '\\n', ' Epoch 21/50, Train Loss: 6.6453, Val Loss: 6.8375, SORS:\n2.5623', '\\n', ' Epoch 22/50, Train Loss: 6.6248, Val Loss: 6.8371, SORS:\n2.5618', '\\n', ' Epoch 23/50, Train Loss: 6.6055, Val Loss: 6.8379, SORS:\n2.5616', '\\n', ' Epoch 24/50, Train Loss: 6.5832, Val Loss: 6.8382, SORS:\n2.5613', '\\n', ' Epoch 25/50, Train Loss: 6.5661, Val Loss: 6.8396, SORS:\n2.5612', '\\n', ' Epoch 26/50, Train Loss: 6.5519, Val Loss: 6.8401, SORS:\n2.5608', '\\n', ' Epoch 27/50, Train Loss: 6.5365, Val Loss: 6.8405, SORS:\n2.5604', '\\n', ' Epoch 28/50, Train Loss: 6.5234, Val Loss: 6.8418, SORS:\n2.5603', '\\n', ' Epoch 29/50, Train Loss: 6.5099, Val Loss: 6.8425, SORS:\n2.5600', '\\n', ' Epoch 30/50, Train Loss: 6.4971, Val Loss: 6.8432, SORS:\n2.5598', '\\n', ' Epoch 31/50, Train Loss: 6.4881, Val Loss: 6.8442, SORS:\n2.5596', '\\n', ' Epoch 32/50, Train Loss: 6.4805, Val Loss: 6.8451, SORS:\n2.5594', '\\n', ' Epoch 33/50, Train Loss: 6.4671, Val Loss: 6.8460, SORS:\n2.5592', '\\n', ' Epoch 34/50, Train Loss: 6.4562, Val Loss: 6.8474, SORS:\n2.5591', '\\n', ' Epoch 35/50, Train Loss: 6.4456, Val Loss: 6.8489, SORS:\n2.5590', '\\n', ' Epoch 36/50, Train Loss: 6.4339, Val Loss: 6.8495, SORS:\n2.5588', '\\n', ' Epoch 37/50, Train Loss: 6.4258, Val Loss: 6.8512, SORS:\n2.5587', '\\n', ' Epoch 38/50, Train Loss: 6.4158, Val Loss: 6.8510, SORS:\n2.5584', '\\n', ' Epoch 39/50, Train Loss: 6.4045, Val Loss: 6.8530, SORS:\n2.5585', '\\n', ' Epoch 40/50, Train Loss: 6.3964, Val Loss: 6.8546, SORS:\n2.5585', '\\n', ' Epoch 41/50, Train Loss: 6.3820, Val Loss: 6.8564, SORS:\n2.5587', '\\n', ' Epoch 42/50, Train Loss: 6.3718, Val Loss: 6.8574, SORS:\n2.5586', '\\n', ' Epoch 43/50, Train Loss: 6.3621, Val Loss: 6.8591, SORS:\n2.5587', '\\n', ' Epoch 44/50, Train Loss: 6.3523, Val Loss: 6.8606, SORS:\n2.5588', '\\n', ' Epoch 45/50, Train Loss: 6.3481, Val Loss: 6.8608, SORS:\n2.5587', '\\n', ' Epoch 46/50, Train Loss: 6.3335, Val Loss: 6.8630, SORS:\n2.5589', '\\n', ' Epoch 47/50, Train Loss: 6.3224, Val Loss: 6.8629, SORS:\n2.5588', '\\n', ' Epoch 48/50, Train Loss: 6.3193, Val Loss: 6.8659, SORS:\n2.5590', '\\n', ' Epoch 49/50, Train Loss: 6.3073, Val Loss: 6.8671, SORS:\n2.5591', '\\n', ' Epoch 50/50, Train Loss: 6.3061, Val Loss: 6.8690, SORS:\n2.5592', '\\n', ' Training with batch size: 32', '\\n', ' Epoch 1/50, Train Loss:\n14.8092, Val Loss: 12.5792, SORS: 2.7039', '\\n', ' Epoch 2/50, Train Loss:\n12.3599, Val Loss: 10.6367, SORS: 2.6710', '\\n', ' Epoch 3/50, Train Loss:\n9.5594, Val Loss: 8.5777, SORS: 2.6384', '\\n', ' Epoch 4/50, Train Loss: 7.3267,\nVal Loss: 7.2548, SORS: 2.6020', '\\n', ' Epoch 5/50, Train Loss: 6.3435, Val\nLoss: 6.9141, SORS: 2.5779', '\\n', ' Epoch 6/50, Train Loss: 6.1732, Val Loss:\n6.8892, SORS: 2.5725', '\\n', ' Epoch 7/50, Train Loss: 6.1875, Val Loss: 6.8889,\nSORS: 2.5729', '\\n', ' Epoch 8/50, Train Loss: 6.1891, Val Loss: 6.8874, SORS:\n2.5729', '\\n', ' Epoch 9/50, Train Loss: 6.1757, Val Loss: 6.8843, SORS:\n2.5723', '\\n', ' Epoch 10/50, Train Loss: 6.1616, Val Loss: 6.8813, SORS:\n2.5717', '\\n', ' Epoch 11/50, Train Loss: 6.1483, Val Loss: 6.8784, SORS:\n2.5711', '\\n', ' Epoch 12/50, Train Loss: 6.1349, Val Loss: 6.8756, SORS:\n2.5706', '\\n', ' Epoch 13/50, Train Loss: 6.1227, Val Loss: 6.8730, SORS:\n2.5700', '\\n', ' Epoch 14/50, Train Loss: 6.1117, Val Loss: 6.8706, SORS:\n2.5695', '\\n', ' Epoch 15/50, Train Loss: 6.1009, Val Loss: 6.8684, SORS:\n2.5689', '\\n', ' Epoch 16/50, Train Loss: 6.0900, Val Loss: 6.8661, SORS:\n2.5683', '\\n', ' Epoch 17/50, Train Loss: 6.0795, Val Loss: 6.8641, SORS:\n2.5678', '\\n', ' Epoch 18/50, Train Loss: 6.0695, Val Loss: 6.8624, SORS:\n2.5673', '\\n', ' Epoch 19/50, Train Loss: 6.0603, Val Loss: 6.8609, SORS:\n2.5668', '\\n', ' Epoch 20/50, Train Loss: 6.0499, Val Loss: 6.8591, SORS:\n2.5662', '\\n', ' Epoch 21/50, Train Loss: 6.0398, Val Loss: 6.8574, SORS:\n2.5656', '\\n', ' Epoch 22/50, Train Loss: 6.0302, Val Loss: 6.8559, SORS:\n2.5651', '\\n', ' Epoch 23/50, Train Loss: 6.0217, Val Loss: 6.8546, SORS:\n2.5646', '\\n', ' Epoch 24/50, Train Loss: 6.0128, Val Loss: 6.8532, SORS:\n2.5640', '\\n', ' Epoch 25/50, Train Loss: 6.0044, Val Loss: 6.8519, SORS:\n2.5635', '\\n', ' Epoch 26/50, Train Loss: 5.9962, Val Loss: 6.8508, SORS:\n2.5630', '\\n', ' Epoch 27/50, Train Loss: 5.9887, Val Loss: 6.8498, SORS:\n2.5625', '\\n', ' Epoch 28/50, Train Loss: 5.9815, Val Loss: 6.8489, SORS:\n2.5620', '\\n', ' Epoch 29/50, Train Loss: 5.9742, Val Loss: 6.8479, SORS:\n2.5615', '\\n', ' Epoch 30/50, Train Loss: 5.9671, Val Loss: 6.8471, SORS:\n2.5610', '\\n', ' Epoch 31/50, Train Loss: 5.9600, Val Loss: 6.8463, SORS:\n2.5606', '\\n', ' Epoch 32/50, Train Loss: 5.9537, Val Loss: 6.8457, SORS:\n2.5601', '\\n', ' Epoch 33/50, Train Loss: 5.9477, Val Loss: 6.8451, SORS:\n2.5597', '\\n', ' Epoch 34/50, Train Loss: 5.9411, Val Loss: 6.8445, SORS:\n2.5592', '\\n', ' Epoch 35/50, Train Loss: 5.9358, Val Loss: 6.8440, SORS:\n2.5588', '\\n', ' Epoch 36/50, Train Loss: 5.9302, Val Loss: 6.8434, SORS:\n2.5584', '\\n', ' Epoch 37/50, Train Loss: 5.9249, Val Loss: 6.8429, SORS:\n2.5580', '\\n', ' Epoch 38/50, Train Loss: 5.9204, Val Loss: 6.8425, SORS:\n2.5576', '\\n', ' Epoch 39/50, Train Loss: 5.9148, Val Loss: 6.8420, SORS:\n2.5572', '\\n', ' Epoch 40/50, Train Loss: 5.9105, Val Loss: 6.8415, SORS:\n2.5568', '\\n', ' Epoch 41/50, Train Loss: 5.9064, Val Loss: 6.8410, SORS:\n2.5564', '\\n', ' Epoch 42/50, Train Loss: 5.9019, Val Loss: 6.8404, SORS:\n2.5560', '\\n', ' Epoch 43/50, Train Loss: 5.8966, Val Loss: 6.8397, SORS:\n2.5556', '\\n', ' Epoch 44/50, Train Loss: 5.8928, Val Loss: 6.8394, SORS:\n2.5552', '\\n', ' Epoch 45/50, Train Loss: 5.8887, Val Loss: 6.8390, SORS:\n2.5549', '\\n', ' Epoch 46/50, Train Loss: 5.8845, Val Loss: 6.8388, SORS:\n2.5545', '\\n', ' Epoch 47/50, Train Loss: 5.8803, Val Loss: 6.8382, SORS:\n2.5541', '\\n', ' Epoch 48/50, Train Loss: 5.8770, Val Loss: 6.8382, SORS:\n2.5539', '\\n', ' Epoch 49/50, Train Loss: 5.8731, Val Loss: 6.8381, SORS:\n2.5535', '\\n', ' Epoch 50/50, Train Loss: 5.8694, Val Loss: 6.8377, SORS:\n2.5532', '\\n', ' Training with batch size: 64', '\\n', ' Epoch 1/50, Train Loss:\n14.2974, Val Loss: 12.2368, SORS: 2.7024', '\\n', ' Epoch 2/50, Train Loss:\n12.9414, Val Loss: 11.1757, SORS: 2.6839', '\\n', ' Epoch 3/50, Train Loss:\n11.6280, Val Loss: 10.1708, SORS: 2.6704', '\\n', ' Epoch 4/50, Train Loss:\n10.3618, Val Loss: 9.2314, SORS: 2.6553', '\\n', ' Epoch 5/50, Train Loss:\n9.1565, Val Loss: 8.4033, SORS: 2.6391', '\\n', ' Epoch 6/50, Train Loss: 8.1078,\nVal Loss: 7.7482, SORS: 2.6228', '\\n', ' Epoch 7/50, Train Loss: 7.2822, Val\nLoss: 7.3020, SORS: 2.6069', '\\n', ' Epoch 8/50, Train Loss: 6.7060, Val Loss:\n7.0544, SORS: 2.5936', '\\n', ' Epoch 9/50, Train Loss: 6.3546, Val Loss: 6.9467,\nSORS: 2.5838', '\\n', ' Epoch 10/50, Train Loss: 6.1690, Val Loss: 6.9104, SORS:\n2.5778', '\\n', ' Epoch 11/50, Train Loss: 6.0858, Val Loss: 6.8996, SORS:\n2.5748', '\\n', ' Epoch 12/50, Train Loss: 6.0561, Val Loss: 6.8954, SORS:\n2.5735', '\\n', ' Epoch 13/50, Train Loss: 6.0494, Val Loss: 6.8930, SORS:\n2.5731', '\\n', ' Epoch 14/50, Train Loss: 6.0493, Val Loss: 6.8912, SORS:\n2.5728', '\\n', ' Epoch 15/50, Train Loss: 6.0486, Val Loss: 6.8893, SORS:\n2.5726', '\\n', ' Epoch 16/50, Train Loss: 6.0458, Val Loss: 6.8872, SORS:\n2.5722', '\\n', ' Epoch 17/50, Train Loss: 6.0413, Val Loss: 6.8849, SORS:\n2.5718', '\\n', ' Epoch 18/50, Train Loss: 6.0357, Val Loss: 6.8827, SORS:\n2.5714', '\\n', ' Epoch 19/50, Train Loss: 6.0296, Val Loss: 6.8802, SORS:\n2.5709', '\\n', ' Epoch 20/50, Train Loss: 6.0231, Val Loss: 6.8777, SORS:\n2.5704', '\\n', ' Epoch 21/50, Train Loss: 6.0168, Val Loss: 6.8750, SORS:\n2.5699', '\\n', ' Epoch 22/50, Train Loss: 6.0109, Val Loss: 6.8723, SORS:\n2.5693', '\\n', ' Epoch 23/50, Train Loss: 6.0052, Val Loss: 6.8699, SORS:\n2.5689', '\\n', ' Epoch 24/50, Train Loss: 6.0004, Val Loss: 6.8674, SORS:\n2.5684', '\\n', ' Epoch 25/50, Train Loss: 5.9970, Val Loss: 6.8649, SORS:\n2.5679', '\\n', ' Epoch 26/50, Train Loss: 5.9893, Val Loss: 6.8632, SORS:\n2.5674', '\\n', ' Epoch 27/50, Train Loss: 5.9835, Val Loss: 6.8612, SORS:\n2.5670', '\\n', ' Epoch 28/50, Train Loss: 5.9780, Val Loss: 6.8593, SORS:\n2.5665', '\\n', ' Epoch 29/50, Train Loss: 5.9707, Val Loss: 6.8574, SORS:\n2.5661', '\\n', ' Epoch 30/50, Train Loss: 5.9629, Val Loss: 6.8552, SORS:\n2.5655', '\\n', ' Epoch 31/50, Train Loss: 5.9559, Val Loss: 6.8523, SORS:\n2.5648', '\\n', ' Epoch 32/50, Train Loss: 5.9534, Val Loss: 6.8487, SORS:\n2.5641', '\\n', ' Epoch 33/50, Train Loss: 5.9427, Val Loss: 6.8476, SORS:\n2.5637', '\\n', ' Epoch 34/50, Train Loss: 5.9365, Val Loss: 6.8463, SORS:\n2.5633', '\\n', ' Epoch 35/50, Train Loss: 5.9299, Val Loss: 6.8443, SORS:\n2.5628', '\\n', ' Epoch 36/50, Train Loss: 5.9244, Val Loss: 6.8423, SORS:\n2.5623', '\\n', ' Epoch 37/50, Train Loss: 5.9176, Val Loss: 6.8404, SORS:\n2.5617', '\\n', ' Epoch 38/50, Train Loss: 5.9105, Val Loss: 6.8382, SORS:\n2.5611', '\\n', ' Epoch 39/50, Train Loss: 5.9043, Val Loss: 6.8352, SORS:\n2.5604', '\\n', ' Epoch 40/50, Train Loss: 5.8966, Val Loss: 6.8329, SORS:\n2.5597', '\\n', ' Epoch 41/50, Train Loss: 5.8904, Val Loss: 6.8304, SORS:\n2.5590', '\\n', ' Epoch 42/50, Train Loss: 5.8894, Val Loss: 6.8276, SORS:\n2.5582', '\\n', ' Epoch 43/50, Train Loss: 5.8844, Val Loss: 6.8260, SORS:\n2.5576', '\\n', ' Epoch 44/50, Train Loss: 5.8738, Val Loss: 6.8241, SORS:\n2.5570', '\\n', ' Epoch 45/50, Train Loss: 5.8681, Val Loss: 6.8223, SORS:\n2.5565', '\\n', ' Epoch 46/50, Train Loss: 5.8607, Val Loss: 6.8208, SORS:\n2.5559', '\\n', ' Epoch 47/50, Train Loss: 5.8535, Val Loss: 6.8189, SORS:\n2.5553', '\\n', ' Epoch 48/50, Train Loss: 5.8480, Val Loss: 6.8167, SORS:\n2.5546', '\\n', ' Epoch 49/50, Train Loss: 5.8415, Val Loss: 6.8147, SORS:\n2.5540', '\\n', ' Epoch 50/50, Train Loss: 5.8347, Val Loss: 6.8129, SORS:\n2.5533', '\\n', ' Training with batch size: 128', '\\n', ' Epoch 1/50, Train Loss:\n16.6717, Val Loss: 14.0069, SORS: 2.7705', '\\n', ' Epoch 2/50, Train Loss:\n15.9005, Val Loss: 13.3766, SORS: 2.7342', '\\n', ' Epoch 3/50, Train Loss:\n15.1181, Val Loss: 12.7442, SORS: 2.7091', '\\n', ' Epoch 4/50, Train Loss:\n14.3160, Val Loss: 12.1037, SORS: 2.6903', '\\n', ' Epoch 5/50, Train Loss:\n13.4899, Val Loss: 11.4561, SORS: 2.6790', '\\n', ' Epoch 6/50, Train Loss:\n12.6456, Val Loss: 10.8023, SORS: 2.6701', '\\n', ' Epoch 7/50, Train Loss:\n11.7863, Val Loss: 10.1530, SORS: 2.6618', '\\n', ' Epoch 8/50, Train Loss:\n10.9218, Val Loss: 9.5200, SORS: 2.6522', '\\n', ' Epoch 9/50, Train Loss:\n10.0790, Val Loss: 8.9189, SORS: 2.6412', '\\n', ' Epoch 10/50, Train Loss:\n9.2769, Val Loss: 8.3756, SORS: 2.6300', '\\n', ' Epoch 11/50, Train Loss:\n8.5485, Val Loss: 7.9074, SORS: 2.6184', '\\n', ' Epoch 12/50, Train Loss:\n7.8998, Val Loss: 7.5289, SORS: 2.6069', '\\n', ' Epoch 13/50, Train Loss:\n7.3505, Val Loss: 7.2471, SORS: 2.5965', '\\n', ' Epoch 14/50, Train Loss:\n6.9099, Val Loss: 7.0542, SORS: 2.5865', '\\n', ' Epoch 15/50, Train Loss:\n6.5690, Val Loss: 6.9385, SORS: 2.5778', '\\n', ' Epoch 16/50, Train Loss:\n6.3223, Val Loss: 6.8809, SORS: 2.5709', '\\n', ' Epoch 17/50, Train Loss:\n6.1538, Val Loss: 6.8575, SORS: 2.5655', '\\n', ' Epoch 18/50, Train Loss:\n6.0480, Val Loss: 6.8513, SORS: 2.5620', '\\n', ' Epoch 19/50, Train Loss:\n5.9882, Val Loss: 6.8510, SORS: 2.5599', '\\n', ' Epoch 20/50, Train Loss:\n5.9589, Val Loss: 6.8513, SORS: 2.5589', '\\n', ' Epoch 21/50, Train Loss:\n5.9481, Val Loss: 6.8510, SORS: 2.5587', '\\n', ' Epoch 22/50, Train Loss:\n5.9472, Val Loss: 6.8502, SORS: 2.5587', '\\n', ' Epoch 23/50, Train Loss:\n5.9504, Val Loss: 6.8493, SORS: 2.5590', '\\n', ' Epoch 24/50, Train Loss:\n5.9537, Val Loss: 6.8485, SORS: 2.5592', '\\n', ' Epoch 25/50, Train Loss:\n5.9556, Val Loss: 6.8479, SORS: 2.5594', '\\n', ' Epoch 26/50, Train Loss:\n5.9553, Val Loss: 6.8473, SORS: 2.5594', '\\n', ' Epoch 27/50, Train Loss:\n5.9528, Val Loss: 6.8467, SORS: 2.5594', '\\n', ' Epoch 28/50, Train Loss:\n5.9485, Val Loss: 6.8463, SORS: 2.5593', '\\n', ' Epoch 29/50, Train Loss:\n5.9432, Val Loss: 6.8458, SORS: 2.5592', '\\n', ' Epoch 30/50, Train Loss:\n5.9373, Val Loss: 6.8452, SORS: 2.5590', '\\n', ' Epoch 31/50, Train Loss:\n5.9308, Val Loss: 6.8447, SORS: 2.5588', '\\n', ' Epoch 32/50, Train Loss:\n5.9244, Val Loss: 6.8442, SORS: 2.5586', '\\n', ' Epoch 33/50, Train Loss:\n5.9187, Val Loss: 6.8436, SORS: 2.5585', '\\n', ' Epoch 34/50, Train Loss:\n5.9143, Val Loss: 6.8428, SORS: 2.5582', '\\n', ' Epoch 35/50, Train Loss:\n5.9098, Val Loss: 6.8417, SORS: 2.5580', '\\n', ' Epoch 36/50, Train Loss:\n5.9059, Val Loss: 6.8409, SORS: 2.5578', '\\n', ' Epoch 37/50, Train Loss:\n5.8996, Val Loss: 6.8404, SORS: 2.5576', '\\n', ' Epoch 38/50, Train Loss:\n5.8923, Val Loss: 6.8402, SORS: 2.5574', '\\n', ' Epoch 39/50, Train Loss:\n5.8853, Val Loss: 6.8401, SORS: 2.5574', '\\n', ' Epoch 40/50, Train Loss:\n5.8801, Val Loss: 6.8396, SORS: 2.5572', '\\n', ' Epoch 41/50, Train Loss:\n5.8754, Val Loss: 6.8390, SORS: 2.5571', '\\n', ' Epoch 42/50, Train Loss:\n5.8704, Val Loss: 6.8385, SORS: 2.5569', '\\n', ' Epoch 43/50, Train Loss:\n5.8651, Val Loss: 6.8381, SORS: 2.5568', '\\n', ' Epoch 44/50, Train Loss:\n5.8595, Val Loss: 6.8377, SORS: 2.5566', '\\n', ' Epoch 45/50, Train Loss:\n5.8537, Val Loss: 6.8373, SORS: 2.5565', '\\n', ' Epoch 46/50, Train Loss:\n5.8477, Val Loss: 6.8370, SORS: 2.5564', '\\n', ' Epoch 47/50, Train Loss:\n5.8419, Val Loss: 6.8367, SORS: 2.5563', '\\n', ' Epoch 48/50, Train Loss:\n5.8364, Val Loss: 6.8363, SORS: 2.5561', '\\n', ' Epoch 49/50, Train Loss:\n5.8316, Val Loss: 6.8357, SORS: 2.5559', '\\n', ' Epoch 50/50, Train Loss:\n5.8264, Val Loss: 6.8351, SORS: 2.5558', '\\n', ' Training with batch size: 256',\n'\\n', ' Epoch 1/50, Train Loss: 18.2476, Val Loss: 15.4239, SORS: 2.9074', '\\n',\n' Epoch 2/50, Train Loss: 17.9438, Val Loss: 15.1775, SORS: 2.8745', '\\n', '\nEpoch 3/50, Train Loss: 17.6651, Val Loss: 14.9533, SORS: 2.8473', '\\n', ' Epoch\n4/50, Train Loss: 17.4094, Val Loss: 14.7503, SORS: 2.8252', '\\n', ' Epoch 5/50,\nTrain Loss: 17.1705, Val Loss: 14.5643, SORS: 2.8072', '\\n', ' Epoch 6/50, Train\nLoss: 16.9495, Val Loss: 14.3909, SORS: 2.7930', '\\n', ' Epoch 7/50, Train Loss:\n16.7429, Val Loss: 14.2287, SORS: 2.7807', '\\n', ' Epoch 8/50, Train Loss:\n16.5467, Val Loss: 14.0747, SORS: 2.7699', '\\n', ' Epoch 9/50, Train Loss:\n16.3586, Val Loss: 13.9260, SORS: 2.7606', '\\n', ' Epoch 10/50, Train Loss:\n16.1762, Val Loss: 13.7790, SORS: 2.7520', '\\n', ' Epoch 11/50, Train Loss:\n15.9926, Val Loss: 13.6316, SORS: 2.7446', '\\n', ' Epoch 12/50, Train Loss:\n15.8049, Val Loss: 13.4805, SORS: 2.7380', '\\n', ' Epoch 13/50, Train Loss:\n15.6116, Val Loss: 13.3225, SORS: 2.7317', '\\n', ' Epoch 14/50, Train Loss:\n15.4065, Val Loss: 13.1553, SORS: 2.7256', '\\n', ' Epoch 15/50, Train Loss:\n15.1885, Val Loss: 12.9766, SORS: 2.7197', '\\n', ' Epoch 16/50, Train Loss:\n14.9582, Val Loss: 12.7868, SORS: 2.7136', '\\n', ' Epoch 17/50, Train Loss:\n14.7165, Val Loss: 12.5852, SORS: 2.7073', '\\n', ' Epoch 18/50, Train Loss:\n14.4592, Val Loss: 12.3712, SORS: 2.7013', '\\n', ' Epoch 19/50, Train Loss:\n14.1857, Val Loss: 12.1468, SORS: 2.6964', '\\n', ' Epoch 20/50, Train Loss:\n13.8962, Val Loss: 11.9128, SORS: 2.6916', '\\n', ' Epoch 21/50, Train Loss:\n13.5916, Val Loss: 11.6695, SORS: 2.6871', '\\n', ' Epoch 22/50, Train Loss:\n13.2771, Val Loss: 11.4189, SORS: 2.6827', '\\n', ' Epoch 23/50, Train Loss:\n12.9541, Val Loss: 11.1636, SORS: 2.6786', '\\n', ' Epoch 24/50, Train Loss:\n12.6245, Val Loss: 10.9056, SORS: 2.6751', '\\n', ' Epoch 25/50, Train Loss:\n12.2902, Val Loss: 10.6464, SORS: 2.6715', '\\n', ' Epoch 26/50, Train Loss:\n11.9530, Val Loss: 10.3875, SORS: 2.6678', '\\n', ' Epoch 27/50, Train Loss:\n11.6152, Val Loss: 10.1305, SORS: 2.6639', '\\n', ' Epoch 28/50, Train Loss:\n11.2781, Val Loss: 9.8771, SORS: 2.6600', '\\n', ' Epoch 29/50, Train Loss:\n10.9431, Val Loss: 9.6286, SORS: 2.6560', '\\n', ' Epoch 30/50, Train Loss:\n10.6117, Val Loss: 9.3865, SORS: 2.6519', '\\n', ' Epoch 31/50, Train Loss:\n10.2855, Val Loss: 9.1520, SORS: 2.6478', '\\n', ' Epoch 32/50, Train Loss:\n9.9661, Val Loss: 8.9262, SORS: 2.6436', '\\n', ' Epoch 33/50, Train Loss:\n9.6547, Val Loss: 8.7102, SORS: 2.6394', '\\n', ' Epoch 34/50, Train Loss:\n9.3526, Val Loss: 8.5052, SORS: 2.6351', '\\n', ' Epoch 35/50, Train Loss:\n9.0609, Val Loss: 8.3118, SORS: 2.6308', '\\n', ' Epoch 36/50, Train Loss:\n8.7807, Val Loss: 8.1307, SORS: 2.6266', '\\n', ' Epoch 37/50, Train Loss:\n8.5129, Val Loss: 7.9627, SORS: 2.6224', '\\n', ' Epoch 38/50, Train Loss:\n8.2585, Val Loss: 7.8080, SORS: 2.6182', '\\n', ' Epoch 39/50, Train Loss:\n8.0181, Val Loss: 7.6668, SORS: 2.6141', '\\n', ' Epoch 40/50, Train Loss:\n7.7923, Val Loss: 7.5391, SORS: 2.6100', '\\n', ' Epoch 41/50, Train Loss:\n7.5812, Val Loss: 7.4250, SORS: 2.6060', '\\n', ' Epoch 42/50, Train Loss:\n7.3854, Val Loss: 7.3240, SORS: 2.6022', '\\n', ' Epoch 43/50, Train Loss:\n7.2046, Val Loss: 7.2356, SORS: 2.5984', '\\n', ' Epoch 44/50, Train Loss:\n7.0383, Val Loss: 7.1594, SORS: 2.5949', '\\n', ' Epoch 45/50, Train Loss:\n6.8868, Val Loss: 7.0944, SORS: 2.5914', '\\n', ' Epoch 46/50, Train Loss:\n6.7493, Val Loss: 7.0398, SORS: 2.5880', '\\n', ' Epoch 47/50, Train Loss:\n6.6246, Val Loss: 6.9949, SORS: 2.5849', '\\n', ' Epoch 48/50, Train Loss:\n6.5127, Val Loss: 6.9585, SORS: 2.5820', '\\n', ' Epoch 49/50, Train Loss:\n6.4127, Val Loss: 6.9297, SORS: 2.5792', '\\n', ' Epoch 50/50, Train Loss:\n6.3237, Val Loss: 6.9076, SORS: 2.5767', '\\n', 'Evaluating on dataset_3', '\\n',\n' Training with batch size: 16', '\\n', ' Epoch 1/50, Train Loss: 5.2577, Val\nLoss: 5.3399, SORS: 1.4534', '\\n', ' Epoch 2/50, Train Loss: 4.4118, Val Loss:\n4.6122, SORS: 1.4219', '\\n', ' Epoch 3/50, Train Loss: 3.5311, Val Loss: 3.8817,\nSORS: 1.4007', '\\n', ' Epoch 4/50, Train Loss: 2.8071, Val Loss: 3.3586, SORS:\n1.3861', '\\n', ' Epoch 5/50, Train Loss: 2.3496, Val Loss: 3.0971, SORS:\n1.3806', '\\n', ' Epoch 6/50, Train Loss: 2.1088, Val Loss: 3.0041, SORS:\n1.3815', '\\n', ' Epoch 7/50, Train Loss: 1.9897, Val Loss: 2.9809, SORS:\n1.3840', '\\n', ' Epoch 8/50, Train Loss: 1.9236, Val Loss: 2.9816, SORS:\n1.3867', '\\n', ' Epoch 9/50, Train Loss: 1.8839, Val Loss: 2.9896, SORS:\n1.3891', '\\n', ' Epoch 10/50, Train Loss: 1.8536, Val Loss: 2.9994, SORS:\n1.3912', '\\n', ' Epoch 11/50, Train Loss: 1.8270, Val Loss: 3.0088, SORS:\n1.3931', '\\n', ' Epoch 12/50, Train Loss: 1.8047, Val Loss: 3.0175, SORS:\n1.3946', '\\n', ' Epoch 13/50, Train Loss: 1.7840, Val Loss: 3.0250, SORS:\n1.3959', '\\n', ' Epoch 14/50, Train Loss: 1.7647, Val Loss: 3.0321, SORS:\n1.3969', '\\n', ' Epoch 15/50, Train Loss: 1.7480, Val Loss: 3.0391, SORS:\n1.3980', '\\n', ' Epoch 16/50, Train Loss: 1.7334, Val Loss: 3.0453, SORS:\n1.3990', '\\n', ' Epoch 17/50, Train Loss: 1.7187, Val Loss: 3.0507, SORS:\n1.3999', '\\n', ' Epoch 18/50, Train Loss: 1.7054, Val Loss: 3.0568, SORS:\n1.4008', '\\n', ' Epoch 19/50, Train Loss: 1.6933, Val Loss: 3.0643, SORS:\n1.4020', '\\n', ' Epoch 20/50, Train Loss: 1.6804, Val Loss: 3.0705, SORS:\n1.4032', '\\n', ' Epoch 21/50, Train Loss: 1.6698, Val Loss: 3.0765, SORS:\n1.4044', '\\n', ' Epoch 22/50, Train Loss: 1.6589, Val Loss: 3.0827, SORS:\n1.4056', '\\n', ' Epoch 23/50, Train Loss: 1.6491, Val Loss: 3.0885, SORS:\n1.4069', '\\n', ' Epoch 24/50, Train Loss: 1.6393, Val Loss: 3.0938, SORS:\n1.4078', '\\n', ' Epoch 25/50, Train Loss: 1.6294, Val Loss: 3.0993, SORS:\n1.4089', '\\n', ' Epoch 26/50, Train Loss: 1.6209, Val Loss: 3.1041, SORS:\n1.4098', '\\n', ' Epoch 27/50, Train Loss: 1.6113, Val Loss: 3.1082, SORS:\n1.4107', '\\n', ' Epoch 28/50, Train Loss: 1.6036, Val Loss: 3.1122, SORS:\n1.4115', '\\n', ' Epoch 29/50, Train Loss: 1.5968, Val Loss: 3.1174, SORS:\n1.4127', '\\n', ' Epoch 30/50, Train Loss: 1.5873, Val Loss: 3.1210, SORS:\n1.4135', '\\n', ' Epoch 31/50, Train Loss: 1.5779, Val Loss: 3.1242, SORS:\n1.4143', '\\n', ' Epoch 32/50, Train Loss: 1.5694, Val Loss: 3.1291, SORS:\n1.4157', '\\n', ' Epoch 33/50, Train Loss: 1.5623, Val Loss: 3.1329, SORS:\n1.4168', '\\n', ' Epoch 34/50, Train Loss: 1.5538, Val Loss: 3.1374, SORS:\n1.4180', '\\n', ' Epoch 35/50, Train Loss: 1.5468, Val Loss: 3.1411, SORS:\n1.4190', '\\n', ' Epoch 36/50, Train Loss: 1.5387, Val Loss: 3.1453, SORS:\n1.4201', '\\n', ' Epoch 37/50, Train Loss: 1.5305, Val Loss: 3.1489, SORS:\n1.4211', '\\n', ' Epoch 38/50, Train Loss: 1.5214, Val Loss: 3.1537, SORS:\n1.4224', '\\n', ' Epoch 39/50, Train Loss: 1.5112, Val Loss: 3.1571, SORS:\n1.4232', '\\n', ' Epoch 40/50, Train Loss: 1.5030, Val Loss: 3.1622, SORS:\n1.4245', '\\n', ' Epoch 41/50, Train Loss: 1.4953, Val Loss: 3.1665, SORS:\n1.4256', '\\n', ' Epoch 42/50, Train Loss: 1.4890, Val Loss: 3.1715, SORS:\n1.4269', '\\n', ' Epoch 43/50, Train Loss: 1.4839, Val Loss: 3.1767, SORS:\n1.4283', '\\n', ' Epoch 44/50, Train Loss: 1.4791, Val Loss: 3.1816, SORS:\n1.4295', '\\n', ' Epoch 45/50, Train Loss: 1.4755, Val Loss: 3.1873, SORS:\n1.4308', '\\n', ' Epoch 46/50, Train Loss: 1.4710, Val Loss: 3.1930, SORS:\n1.4322', '\\n', ' Epoch 47/50, Train Loss: 1.4662, Val Loss: 3.1983, SORS:\n1.4337', '\\n', ' Epoch 48/50, Train Loss: 1.4617, Val Loss: 3.2036, SORS:\n1.4350', '\\n', ' Epoch 49/50, Train Loss: 1.4569, Val Loss: 3.2082, SORS:\n1.4362', '\\n', ' Epoch 50/50, Train Loss: 1.4561, Val Loss: 3.2145, SORS:\n1.4377', '\\n', ' Training with batch size: 32', '\\n', ' Epoch 1/50, Train Loss:\n3.8465, Val Loss: 5.7676, SORS: 1.4996', '\\n', ' Epoch 2/50, Train Loss: 3.5668,\nVal Loss: 5.3968, SORS: 1.4813', '\\n', ' Epoch 3/50, Train Loss: 3.2717, Val\nLoss: 4.9832, SORS: 1.4675', '\\n', ' Epoch 4/50, Train Loss: 2.9690, Val Loss:\n4.5423, SORS: 1.4558', '\\n', ' Epoch 5/50, Train Loss: 2.6884, Val Loss: 4.1122,\nSORS: 1.4473', '\\n', ' Epoch 6/50, Train Loss: 2.4547, Val Loss: 3.7415, SORS:\n1.4395', '\\n', ' Epoch 7/50, Train Loss: 2.2871, Val Loss: 3.4602, SORS:\n1.4312', '\\n', ' Epoch 8/50, Train Loss: 2.1844, Val Loss: 3.2758, SORS:\n1.4234', '\\n', ' Epoch 9/50, Train Loss: 2.1257, Val Loss: 3.1704, SORS:\n1.4181', '\\n', ' Epoch 10/50, Train Loss: 2.0878, Val Loss: 3.1128, SORS:\n1.4148', '\\n', ' Epoch 11/50, Train Loss: 2.0612, Val Loss: 3.0834, SORS:\n1.4131', '\\n', ' Epoch 12/50, Train Loss: 2.0399, Val Loss: 3.0693, SORS:\n1.4121', '\\n', ' Epoch 13/50, Train Loss: 2.0221, Val Loss: 3.0633, SORS:\n1.4116', '\\n', ' Epoch 14/50, Train Loss: 2.0057, Val Loss: 3.0607, SORS:\n1.4111', '\\n', ' Epoch 15/50, Train Loss: 1.9907, Val Loss: 3.0598, SORS:\n1.4107', '\\n', ' Epoch 16/50, Train Loss: 1.9774, Val Loss: 3.0603, SORS:\n1.4104', '\\n', ' Epoch 17/50, Train Loss: 1.9648, Val Loss: 3.0613, SORS:\n1.4104', '\\n', ' Epoch 18/50, Train Loss: 1.9539, Val Loss: 3.0627, SORS:\n1.4103', '\\n', ' Epoch 19/50, Train Loss: 1.9441, Val Loss: 3.0635, SORS:\n1.4102', '\\n', ' Epoch 20/50, Train Loss: 1.9361, Val Loss: 3.0648, SORS:\n1.4101', '\\n', ' Epoch 21/50, Train Loss: 1.9284, Val Loss: 3.0660, SORS:\n1.4100', '\\n', ' Epoch 22/50, Train Loss: 1.9208, Val Loss: 3.0674, SORS:\n1.4100', '\\n', ' Epoch 23/50, Train Loss: 1.9136, Val Loss: 3.0688, SORS:\n1.4100', '\\n', ' Epoch 24/50, Train Loss: 1.9065, Val Loss: 3.0703, SORS:\n1.4101', '\\n', ' Epoch 25/50, Train Loss: 1.8995, Val Loss: 3.0714, SORS:\n1.4101', '\\n', ' Epoch 26/50, Train Loss: 1.8935, Val Loss: 3.0727, SORS:\n1.4102', '\\n', ' Epoch 27/50, Train Loss: 1.8885, Val Loss: 3.0741, SORS:\n1.4104', '\\n', ' Epoch 28/50, Train Loss: 1.8840, Val Loss: 3.0752, SORS:\n1.4107', '\\n', ' Epoch 29/50, Train Loss: 1.8792, Val Loss: 3.0764, SORS:\n1.4108', '\\n', ' Epoch 30/50, Train Loss: 1.8748, Val Loss: 3.0779, SORS:\n1.4110', '\\n', ' Epoch 31/50, Train Loss: 1.8713, Val Loss: 3.0795, SORS:\n1.4113', '\\n', ' Epoch 32/50, Train Loss: 1.8678, Val Loss: 3.0817, SORS:\n1.4116', '\\n', ' Epoch 33/50, Train Loss: 1.8647, Val Loss: 3.0840, SORS:\n1.4121', '\\n', ' Epoch 34/50, Train Loss: 1.8620, Val Loss: 3.0857, SORS:\n1.4124', '\\n', ' Epoch 35/50, Train Loss: 1.8596, Val Loss: 3.0878, SORS:\n1.4127', '\\n', ' Epoch 36/50, Train Loss: 1.8560, Val Loss: 3.0902, SORS:\n1.4132', '\\n', ' Epoch 37/50, Train Loss: 1.8536, Val Loss: 3.0925, SORS:\n1.4137', '\\n', ' Epoch 38/50, Train Loss: 1.8504, Val Loss: 3.0939, SORS:\n1.4140', '\\n', ' Epoch 39/50, Train Loss: 1.8476, Val Loss: 3.0951, SORS:\n1.4143', '\\n', ' Epoch 40/50, Train Loss: 1.8453, Val Loss: 3.0967, SORS:\n1.4147', '\\n', ' Epoch 41/50, Train Loss: 1.8440, Val Loss: 3.0979, SORS:\n1.4149', '\\n', ' Epoch 42/50, Train Loss: 1.8426, Val Loss: 3.0992, SORS:\n1.4152', '\\n', ' Epoch 43/50, Train Loss: 1.8405, Val Loss: 3.1010, SORS:\n1.4155', '\\n', ' Epoch 44/50, Train Loss: 1.8397, Val Loss: 3.1019, SORS:\n1.4156', '\\n', ' Epoch 45/50, Train Loss: 1.8381, Val Loss: 3.1027, SORS:\n1.4157', '\\n', ' Epoch 46/50, Train Loss: 1.8365, Val Loss: 3.1041, SORS:\n1.4158', '\\n', ' Epoch 47/50, Train Loss: 1.8339, Val Loss: 3.1044, SORS:\n1.4158', '\\n', ' Epoch 48/50, Train Loss: 1.8319, Val Loss: 3.1048, SORS:\n1.4157', '\\n', ' Epoch 49/50, Train Loss: 1.8297, Val Loss: 3.1052, SORS:\n1.4158', '\\n', ' Epoch 50/50, Train Loss: 1.8279, Val Loss: 3.1067, SORS:\n1.4160', '\\n', ' Training with batch size: 64', '\\n', ' Epoch 1/50, Train Loss:\n4.5322, Val Loss: 6.1775, SORS: 1.5396', '\\n', ' Epoch 2/50, Train Loss: 4.2102,\nVal Loss: 5.9387, SORS: 1.5081', '\\n', ' Epoch 3/50, Train Loss: 3.9266, Val\nLoss: 5.7186, SORS: 1.4979', '\\n', ' Epoch 4/50, Train Loss: 3.6701, Val Loss:\n5.5045, SORS: 1.4951', '\\n', ' Epoch 5/50, Train Loss: 3.4278, Val Loss: 5.2859,\nSORS: 1.4941', '\\n', ' Epoch 6/50, Train Loss: 3.1926, Val Loss: 5.0589, SORS:\n1.4920', '\\n', ' Epoch 7/50, Train Loss: 2.9615, Val Loss: 4.8244, SORS:\n1.4891', '\\n', ' Epoch 8/50, Train Loss: 2.7437, Val Loss: 4.5899, SORS:\n1.4872', '\\n', ' Epoch 9/50, Train Loss: 2.5447, Val Loss: 4.3597, SORS:\n1.4843', '\\n', ' Epoch 10/50, Train Loss: 2.3694, Val Loss: 4.1410, SORS:\n1.4804', '\\n', ' Epoch 11/50, Train Loss: 2.2221, Val Loss: 3.9416, SORS:\n1.4755', '\\n', ' Epoch 12/50, Train Loss: 2.1034, Val Loss: 3.7680, SORS:\n1.4703', '\\n', ' Epoch 13/50, Train Loss: 2.0148, Val Loss: 3.6226, SORS:\n1.4658', '\\n', ' Epoch 14/50, Train Loss: 1.9525, Val Loss: 3.5052, SORS:\n1.4608', '\\n', ' Epoch 15/50, Train Loss: 1.9084, Val Loss: 3.4127, SORS:\n1.4561', '\\n', ' Epoch 16/50, Train Loss: 1.8766, Val Loss: 3.3424, SORS:\n1.4513', '\\n', ' Epoch 17/50, Train Loss: 1.8536, Val Loss: 3.2900, SORS:\n1.4467', '\\n', ' Epoch 18/50, Train Loss: 1.8371, Val Loss: 3.2514, SORS:\n1.4426', '\\n', ' Epoch 19/50, Train Loss: 1.8245, Val Loss: 3.2228, SORS:\n1.4388', '\\n', ' Epoch 20/50, Train Loss: 1.8140, Val Loss: 3.2017, SORS:\n1.4357', '\\n', ' Epoch 21/50, Train Loss: 1.8047, Val Loss: 3.1857, SORS:\n1.4331', '\\n', ' Epoch 22/50, Train Loss: 1.7961, Val Loss: 3.1737, SORS:\n1.4309', '\\n', ' Epoch 23/50, Train Loss: 1.7876, Val Loss: 3.1650, SORS:\n1.4289', '\\n', ' Epoch 24/50, Train Loss: 1.7792, Val Loss: 3.1585, SORS:\n1.4272', '\\n', ' Epoch 25/50, Train Loss: 1.7704, Val Loss: 3.1536, SORS:\n1.4257', '\\n', ' Epoch 26/50, Train Loss: 1.7618, Val Loss: 3.1496, SORS:\n1.4244', '\\n', ' Epoch 27/50, Train Loss: 1.7536, Val Loss: 3.1469, SORS:\n1.4233', '\\n', ' Epoch 28/50, Train Loss: 1.7456, Val Loss: 3.1451, SORS:\n1.4224', '\\n', ' Epoch 29/50, Train Loss: 1.7376, Val Loss: 3.1443, SORS:\n1.4219', '\\n', ' Epoch 30/50, Train Loss: 1.7298, Val Loss: 3.1442, SORS:\n1.4216', '\\n', ' Epoch 31/50, Train Loss: 1.7222, Val Loss: 3.1444, SORS:\n1.4213', '\\n', ' Epoch 32/50, Train Loss: 1.7146, Val Loss: 3.1450, SORS:\n1.4210', '\\n', ' Epoch 33/50, Train Loss: 1.7072, Val Loss: 3.1460, SORS:\n1.4208', '\\n', ' Epoch 34/50, Train Loss: 1.7000, Val Loss: 3.1472, SORS:\n1.4207', '\\n', ' Epoch 35/50, Train Loss: 1.6926, Val Loss: 3.1487, SORS:\n1.4207', '\\n', ' Epoch 36/50, Train Loss: 1.6854, Val Loss: 3.1503, SORS:\n1.4207', '\\n', ' Epoch 37/50, Train Loss: 1.6784, Val Loss: 3.1522, SORS:\n1.4207', '\\n', ' Epoch 38/50, Train Loss: 1.6721, Val Loss: 3.1541, SORS:\n1.4208', '\\n', ' Epoch 39/50, Train Loss: 1.6656, Val Loss: 3.1564, SORS:\n1.4208', '\\n', ' Epoch 40/50, Train Loss: 1.6595, Val Loss: 3.1584, SORS:\n1.4209', '\\n', ' Epoch 41/50, Train Loss: 1.6533, Val Loss: 3.1604, SORS:\n1.4210', '\\n', ' Epoch 42/50, Train Loss: 1.6472, Val Loss: 3.1626, SORS:\n1.4210', '\\n', ' Epoch 43/50, Train Loss: 1.6415, Val Loss: 3.1650, SORS:\n1.4211', '\\n', ' Epoch 44/50, Train Loss: 1.6359, Val Loss: 3.1671, SORS:\n1.4212', '\\n', ' Epoch 45/50, Train Loss: 1.6302, Val Loss: 3.1692, SORS:\n1.4214', '\\n', ' Epoch 46/50, Train Loss: 1.6247, Val Loss: 3.1717, SORS:\n1.4216', '\\n', ' Epoch 47/50, Train Loss: 1.6199, Val Loss: 3.1738, SORS:\n1.4218', '\\n', ' Epoch 48/50, Train Loss: 1.6155, Val Loss: 3.1758, SORS:\n1.4220', '\\n', ' Epoch 49/50, Train Loss: 1.6112, Val Loss: 3.1775, SORS:\n1.4221', '\\n', ' Epoch 50/50, Train Loss: 1.6075, Val Loss: 3.1793, SORS:\n1.4222', '\\n', ' Training with batch size: 128', '\\n', ' Epoch 1/50, Train Loss:\n3.9095, Val Loss: 5.9428, SORS: 1.5020', '\\n', ' Epoch 2/50, Train Loss: 3.7645,\nVal Loss: 5.8223, SORS: 1.4936', '\\n', ' Epoch 3/50, Train Loss: 3.6226, Val\nLoss: 5.7009, SORS: 1.4854', '\\n', ' Epoch 4/50, Train Loss: 3.4853, Val Loss:\n5.5779, SORS: 1.4774', '\\n', ' Epoch 5/50, Train Loss: 3.3505, Val Loss: 5.4510,\nSORS: 1.4708', '\\n', ' Epoch 6/50, Train Loss: 3.2181, Val Loss: 5.3211, SORS:\n1.4681', '\\n', ' Epoch 7/50, Train Loss: 3.0886, Val Loss: 5.1869, SORS:\n1.4662', '\\n', ' Epoch 8/50, Train Loss: 2.9612, Val Loss: 5.0487, SORS:\n1.4639', '\\n', ' Epoch 9/50, Train Loss: 2.8374, Val Loss: 4.9079, SORS:\n1.4612', '\\n', ' Epoch 10/50, Train Loss: 2.7176, Val Loss: 4.7671, SORS:\n1.4589', '\\n', ' Epoch 11/50, Train Loss: 2.6022, Val Loss: 4.6272, SORS:\n1.4565', '\\n', ' Epoch 12/50, Train Loss: 2.4915, Val Loss: 4.4888, SORS:\n1.4544', '\\n', ' Epoch 13/50, Train Loss: 2.3861, Val Loss: 4.3514, SORS:\n1.4528', '\\n', ' Epoch 14/50, Train Loss: 2.2872, Val Loss: 4.2192, SORS:\n1.4511', '\\n', ' Epoch 15/50, Train Loss: 2.1979, Val Loss: 4.0921, SORS:\n1.4495', '\\n', ' Epoch 16/50, Train Loss: 2.1168, Val Loss: 3.9723, SORS:\n1.4476', '\\n', ' Epoch 17/50, Train Loss: 2.0438, Val Loss: 3.8585, SORS:\n1.4453', '\\n', ' Epoch 18/50, Train Loss: 1.9812, Val Loss: 3.7514, SORS:\n1.4423', '\\n', ' Epoch 19/50, Train Loss: 1.9288, Val Loss: 3.6530, SORS:\n1.4392', '\\n', ' Epoch 20/50, Train Loss: 1.8842, Val Loss: 3.5638, SORS:\n1.4358', '\\n', ' Epoch 21/50, Train Loss: 1.8472, Val Loss: 3.4837, SORS:\n1.4322', '\\n', ' Epoch 22/50, Train Loss: 1.8165, Val Loss: 3.4130, SORS:\n1.4287', '\\n', ' Epoch 23/50, Train Loss: 1.7918, Val Loss: 3.3514, SORS:\n1.4251', '\\n', ' Epoch 24/50, Train Loss: 1.7719, Val Loss: 3.2987, SORS:\n1.4217', '\\n', ' Epoch 25/50, Train Loss: 1.7555, Val Loss: 3.2542, SORS:\n1.4185', '\\n', ' Epoch 26/50, Train Loss: 1.7416, Val Loss: 3.2170, SORS:\n1.4158', '\\n', ' Epoch 27/50, Train Loss: 1.7299, Val Loss: 3.1863, SORS:\n1.4133', '\\n', ' Epoch 28/50, Train Loss: 1.7197, Val Loss: 3.1612, SORS:\n1.4110', '\\n', ' Epoch 29/50, Train Loss: 1.7108, Val Loss: 3.1406, SORS:\n1.4090', '\\n', ' Epoch 30/50, Train Loss: 1.7022, Val Loss: 3.1239, SORS:\n1.4072', '\\n', ' Epoch 31/50, Train Loss: 1.6936, Val Loss: 3.1102, SORS:\n1.4056', '\\n', ' Epoch 32/50, Train Loss: 1.6851, Val Loss: 3.0988, SORS:\n1.4041', '\\n', ' Epoch 33/50, Train Loss: 1.6763, Val Loss: 3.0896, SORS:\n1.4029', '\\n', ' Epoch 34/50, Train Loss: 1.6677, Val Loss: 3.0824, SORS:\n1.4019', '\\n', ' Epoch 35/50, Train Loss: 1.6590, Val Loss: 3.0768, SORS:\n1.4011', '\\n', ' Epoch 36/50, Train Loss: 1.6501, Val Loss: 3.0726, SORS:\n1.4005', '\\n', ' Epoch 37/50, Train Loss: 1.6409, Val Loss: 3.0696, SORS:\n1.4000', '\\n', ' Epoch 38/50, Train Loss: 1.6319, Val Loss: 3.0674, SORS:\n1.3997', '\\n', ' Epoch 39/50, Train Loss: 1.6228, Val Loss: 3.0657, SORS:\n1.3993', '\\n', ' Epoch 40/50, Train Loss: 1.6135, Val Loss: 3.0646, SORS:\n1.3991', '\\n', ' Epoch 41/50, Train Loss: 1.6042, Val Loss: 3.0639, SORS:\n1.3989', '\\n', ' Epoch 42/50, Train Loss: 1.5952, Val Loss: 3.0634, SORS:\n1.3988', '\\n', ' Epoch 43/50, Train Loss: 1.5862, Val Loss: 3.0633, SORS:\n1.3987', '\\n', ' Epoch 44/50, Train Loss: 1.5774, Val Loss: 3.0635, SORS:\n1.3987', '\\n', ' Epoch 45/50, Train Loss: 1.5686, Val Loss: 3.0639, SORS:\n1.3988', '\\n', ' Epoch 46/50, Train Loss: 1.5600, Val Loss: 3.0647, SORS:\n1.3989', '\\n', ' Epoch 47/50, Train Loss: 1.5512, Val Loss: 3.0658, SORS:\n1.3991', '\\n', ' Epoch 48/50, Train Loss: 1.5426, Val Loss: 3.0671, SORS:\n1.3994', '\\n', ' Epoch 49/50, Train Loss: 1.5341, Val Loss: 3.0685, SORS:\n1.3997', '\\n', ' Epoch 50/50, Train Loss: 1.5257, Val Loss: 3.0699, SORS:\n1.4000', '\\n', ' Training with batch size: 256', '\\n', ' Epoch 1/50, Train Loss:\n4.8285, Val Loss: 6.2038, SORS: 1.6256', '\\n', ' Epoch 2/50, Train Loss: 4.7044,\nVal Loss: 6.1119, SORS: 1.6030', '\\n', ' Epoch 3/50, Train Loss: 4.5830, Val\nLoss: 6.0221, SORS: 1.5822', '\\n', ' Epoch 4/50, Train Loss: 4.4647, Val Loss:\n5.9328, SORS: 1.5630', '\\n', ' Epoch 5/50, Train Loss: 4.3498, Val Loss: 5.8437,\nSORS: 1.5446', '\\n', ' Epoch 6/50, Train Loss: 4.2382, Val Loss: 5.7543, SORS:\n1.5279', '\\n', ' Epoch 7/50, Train Loss: 4.1296, Val Loss: 5.6643, SORS:\n1.5135', '\\n', ' Epoch 8/50, Train Loss: 4.0240, Val Loss: 5.5729, SORS:\n1.5001', '\\n', ' Epoch 9/50, Train Loss: 3.9204, Val Loss: 5.4804, SORS:\n1.4895', '\\n', ' Epoch 10/50, Train Loss: 3.8191, Val Loss: 5.3873, SORS:\n1.4812', '\\n', ' Epoch 11/50, Train Loss: 3.7204, Val Loss: 5.2925, SORS:\n1.4739', '\\n', ' Epoch 12/50, Train Loss: 3.6224, Val Loss: 5.1956, SORS:\n1.4680', '\\n', ' Epoch 13/50, Train Loss: 3.5254, Val Loss: 5.0966, SORS:\n1.4634', '\\n', ' Epoch 14/50, Train Loss: 3.4293, Val Loss: 4.9952, SORS:\n1.4589', '\\n', ' Epoch 15/50, Train Loss: 3.3340, Val Loss: 4.8921, SORS:\n1.4550', '\\n', ' Epoch 16/50, Train Loss: 3.2405, Val Loss: 4.7872, SORS:\n1.4513', '\\n', ' Epoch 17/50, Train Loss: 3.1489, Val Loss: 4.6817, SORS:\n1.4477', '\\n', ' Epoch 18/50, Train Loss: 3.0585, Val Loss: 4.5758, SORS:\n1.4441', '\\n', ' Epoch 19/50, Train Loss: 2.9702, Val Loss: 4.4697, SORS:\n1.4411', '\\n', ' Epoch 20/50, Train Loss: 2.8826, Val Loss: 4.3641, SORS:\n1.4386', '\\n', ' Epoch 21/50, Train Loss: 2.7960, Val Loss: 4.2593, SORS:\n1.4361', '\\n', ' Epoch 22/50, Train Loss: 2.7104, Val Loss: 4.1566, SORS:\n1.4335', '\\n', ' Epoch 23/50, Train Loss: 2.6273, Val Loss: 4.0570, SORS:\n1.4313', '\\n', ' Epoch 24/50, Train Loss: 2.5461, Val Loss: 3.9610, SORS:\n1.4293', '\\n', ' Epoch 25/50, Train Loss: 2.4668, Val Loss: 3.8689, SORS:\n1.4273', '\\n', ' Epoch 26/50, Train Loss: 2.3907, Val Loss: 3.7808, SORS:\n1.4253', '\\n', ' Epoch 27/50, Train Loss: 2.3174, Val Loss: 3.6974, SORS:\n1.4236', '\\n', ' Epoch 28/50, Train Loss: 2.2470, Val Loss: 3.6194, SORS:\n1.4221', '\\n', ' Epoch 29/50, Train Loss: 2.1807, Val Loss: 3.5463, SORS:\n1.4206', '\\n', ' Epoch 30/50, Train Loss: 2.1184, Val Loss: 3.4785, SORS:\n1.4192', '\\n', ' Epoch 31/50, Train Loss: 2.0598, Val Loss: 3.4164, SORS:\n1.4180', '\\n', ' Epoch 32/50, Train Loss: 2.0046, Val Loss: 3.3600, SORS:\n1.4168', '\\n', ' Epoch 33/50, Train Loss: 1.9531, Val Loss: 3.3095, SORS:\n1.4158', '\\n', ' Epoch 34/50, Train Loss: 1.9050, Val Loss: 3.2649, SORS:\n1.4151', '\\n', ' Epoch 35/50, Train Loss: 1.8609, Val Loss: 3.2258, SORS:\n1.4146', '\\n', ' Epoch 36/50, Train Loss: 1.8211, Val Loss: 3.1918, SORS:\n1.4142', '\\n', ' Epoch 37/50, Train Loss: 1.7844, Val Loss: 3.1626, SORS:\n1.4139', '\\n', ' Epoch 38/50, Train Loss: 1.7500, Val Loss: 3.1379, SORS:\n1.4137', '\\n', ' Epoch 39/50, Train Loss: 1.7180, Val Loss: 3.1168, SORS:\n1.4136', '\\n', ' Epoch 40/50, Train Loss: 1.6883, Val Loss: 3.0993, SORS:\n1.4137', '\\n', ' Epoch 41/50, Train Loss: 1.6607, Val Loss: 3.0850, SORS:\n1.4138', '\\n', ' Epoch 42/50, Train Loss: 1.6348, Val Loss: 3.0734, SORS:\n1.4139', '\\n', ' Epoch 43/50, Train Loss: 1.6108, Val Loss: 3.0641, SORS:\n1.4140', '\\n', ' Epoch 44/50, Train Loss: 1.5880, Val Loss: 3.0569, SORS:\n1.4142', '\\n', ' Epoch 45/50, Train Loss: 1.5665, Val Loss: 3.0514, SORS:\n1.4144', '\\n', ' Epoch 46/50, Train Loss: 1.5460, Val Loss: 3.0474, SORS:\n1.4146', '\\n', ' Epoch 47/50, Train Loss: 1.5268, Val Loss: 3.0446, SORS:\n1.4149', '\\n', ' Epoch 48/50, Train Loss: 1.5086, Val Loss: 3.0428, SORS:\n1.4152', '\\n', ' Epoch 49/50, Train Loss: 1.4911, Val Loss: 3.0418, SORS:\n1.4155', '\\n', ' Epoch 50/50, Train Loss: 1.4745, Val Loss: 3.0414, SORS:\n1.4158', '\\n', 'Execution time: 18 seconds seconds (time limit is 10 minutes).']", "['Using device: cuda', '\\n', 'Training full_dataset with batch size: 16', '\\n',\n'Epoch 1/50, Train Loss: 10.3411, Val Loss: 9.1841, SORS: 2.4844', '\\n', 'Epoch\n2/50, Train Loss: 7.0184, Val Loss: 6.5130, SORS: 2.4685', '\\n', 'Epoch 3/50,\nTrain Loss: 6.6065, Val Loss: 6.2969, SORS: 2.4622', '\\n', 'Epoch 4/50, Train\nLoss: 6.5735, Val Loss: 6.2844, SORS: 2.4602', '\\n', 'Epoch 5/50, Train Loss:\n6.5422, Val Loss: 6.2729, SORS: 2.4582', '\\n', 'Epoch 6/50, Train Loss: 6.5064,\nVal Loss: 6.2631, SORS: 2.4563', '\\n', 'Epoch 7/50, Train Loss: 6.4692, Val\nLoss: 6.2544, SORS: 2.4545', '\\n', 'Epoch 8/50, Train Loss: 6.4219, Val Loss:\n6.2441, SORS: 2.4521', '\\n', 'Epoch 9/50, Train Loss: 6.3737, Val Loss: 6.2349,\nSORS: 2.4498', '\\n', 'Epoch 10/50, Train Loss: 6.3367, Val Loss: 6.2278, SORS:\n2.4479', '\\n', 'Epoch 11/50, Train Loss: 6.3000, Val Loss: 6.2224, SORS:\n2.4462', '\\n', 'Epoch 12/50, Train Loss: 6.2701, Val Loss: 6.2165, SORS:\n2.4445', '\\n', 'Epoch 13/50, Train Loss: 6.2436, Val Loss: 6.2108, SORS:\n2.4428', '\\n', 'Epoch 14/50, Train Loss: 6.2230, Val Loss: 6.2057, SORS:\n2.4412', '\\n', 'Epoch 15/50, Train Loss: 6.2037, Val Loss: 6.2010, SORS:\n2.4398', '\\n', 'Epoch 16/50, Train Loss: 6.1830, Val Loss: 6.1968, SORS:\n2.4383', '\\n', 'Epoch 17/50, Train Loss: 6.1674, Val Loss: 6.1925, SORS:\n2.4370', '\\n', 'Epoch 18/50, Train Loss: 6.1483, Val Loss: 6.1895, SORS:\n2.4358', '\\n', 'Epoch 19/50, Train Loss: 6.1335, Val Loss: 6.1864, SORS:\n2.4346', '\\n', 'Epoch 20/50, Train Loss: 6.1178, Val Loss: 6.1836, SORS:\n2.4335', '\\n', 'Epoch 21/50, Train Loss: 6.1074, Val Loss: 6.1807, SORS:\n2.4324', '\\n', 'Epoch 22/50, Train Loss: 6.0972, Val Loss: 6.1783, SORS:\n2.4315', '\\n', 'Epoch 23/50, Train Loss: 6.0865, Val Loss: 6.1762, SORS:\n2.4306', '\\n', 'Epoch 24/50, Train Loss: 6.0773, Val Loss: 6.1737, SORS:\n2.4297', '\\n', 'Epoch 25/50, Train Loss: 6.0682, Val Loss: 6.1715, SORS:\n2.4288', '\\n', 'Epoch 26/50, Train Loss: 6.0591, Val Loss: 6.1693, SORS:\n2.4280', '\\n', 'Epoch 27/50, Train Loss: 6.0503, Val Loss: 6.1673, SORS:\n2.4272', '\\n', 'Epoch 28/50, Train Loss: 6.0447, Val Loss: 6.1655, SORS:\n2.4265', '\\n', 'Epoch 29/50, Train Loss: 6.0373, Val Loss: 6.1636, SORS:\n2.4258', '\\n', 'Epoch 30/50, Train Loss: 6.0307, Val Loss: 6.1628, SORS:\n2.4253', '\\n', 'Epoch 31/50, Train Loss: 6.0238, Val Loss: 6.1597, SORS:\n2.4244', '\\n', 'Epoch 32/50, Train Loss: 6.0180, Val Loss: 6.1581, SORS:\n2.4238', '\\n', 'Epoch 33/50, Train Loss: 6.0117, Val Loss: 6.1557, SORS:\n2.4231', '\\n', 'Epoch 34/50, Train Loss: 6.0078, Val Loss: 6.1541, SORS:\n2.4227', '\\n', 'Epoch 35/50, Train Loss: 6.0037, Val Loss: 6.1532, SORS:\n2.4223', '\\n', 'Epoch 36/50, Train Loss: 6.0014, Val Loss: 6.1523, SORS:\n2.4219', '\\n', 'Epoch 37/50, Train Loss: 5.9922, Val Loss: 6.1508, SORS:\n2.4214', '\\n', 'Epoch 38/50, Train Loss: 5.9925, Val Loss: 6.1495, SORS:\n2.4210', '\\n', 'Epoch 39/50, Train Loss: 5.9887, Val Loss: 6.1487, SORS:\n2.4207', '\\n', 'Epoch 40/50, Train Loss: 5.9841, Val Loss: 6.1474, SORS:\n2.4203', '\\n', 'Epoch 41/50, Train Loss: 5.9766, Val Loss: 6.1462, SORS:\n2.4200', '\\n', 'Epoch 42/50, Train Loss: 5.9696, Val Loss: 6.1452, SORS:\n2.4194', '\\n', 'Epoch 43/50, Train Loss: 5.9660, Val Loss: 6.1446, SORS:\n2.4192', '\\n', 'Epoch 44/50, Train Loss: 5.9652, Val Loss: 6.1440, SORS:\n2.4190', '\\n', 'Epoch 45/50, Train Loss: 5.9590, Val Loss: 6.1444, SORS:\n2.4190', '\\n', 'Epoch 46/50, Train Loss: 5.9587, Val Loss: 6.1427, SORS:\n2.4186', '\\n', 'Epoch 47/50, Train Loss: 5.9604, Val Loss: 6.1420, SORS:\n2.4184', '\\n', 'Epoch 48/50, Train Loss: 5.9548, Val Loss: 6.1409, SORS:\n2.4181', '\\n', 'Epoch 49/50, Train Loss: 5.9585, Val Loss: 6.1405, SORS:\n2.4180', '\\n', 'Epoch 50/50, Train Loss: 5.9498, Val Loss: 6.1391, SORS:\n2.4174', '\\n', 'Training full_dataset with batch size: 32', '\\n', 'Epoch 1/50,\nTrain Loss: 10.9362, Val Loss: 10.9903, SORS: 2.4749', '\\n', 'Epoch 2/50, Train\nLoss: 9.2318, Val Loss: 9.2399, SORS: 2.4725', '\\n', 'Epoch 3/50, Train Loss:\n7.6317, Val Loss: 7.5698, SORS: 2.4684', '\\n', 'Epoch 4/50, Train Loss: 6.7446,\nVal Loss: 6.5401, SORS: 2.4629', '\\n', 'Epoch 5/50, Train Loss: 6.6349, Val\nLoss: 6.2780, SORS: 2.4588', '\\n', 'Epoch 6/50, Train Loss: 6.6868, Val Loss:\n6.2703, SORS: 2.4567', '\\n', 'Epoch 7/50, Train Loss: 6.6791, Val Loss: 6.2662,\nSORS: 2.4558', '\\n', 'Epoch 8/50, Train Loss: 6.6604, Val Loss: 6.2604, SORS:\n2.4551', '\\n', 'Epoch 9/50, Train Loss: 6.6460, Val Loss: 6.2555, SORS: 2.4542',\n'\\n', 'Epoch 10/50, Train Loss: 6.6332, Val Loss: 6.2509, SORS: 2.4534', '\\n',\n'Epoch 11/50, Train Loss: 6.6206, Val Loss: 6.2465, SORS: 2.4525', '\\n', 'Epoch\n12/50, Train Loss: 6.6079, Val Loss: 6.2421, SORS: 2.4517', '\\n', 'Epoch 13/50,\nTrain Loss: 6.5955, Val Loss: 6.2378, SORS: 2.4508', '\\n', 'Epoch 14/50, Train\nLoss: 6.5834, Val Loss: 6.2336, SORS: 2.4500', '\\n', 'Epoch 15/50, Train Loss:\n6.5718, Val Loss: 6.2296, SORS: 2.4491', '\\n', 'Epoch 16/50, Train Loss: 6.5602,\nVal Loss: 6.2258, SORS: 2.4483', '\\n', 'Epoch 17/50, Train Loss: 6.5486, Val\nLoss: 6.2218, SORS: 2.4475', '\\n', 'Epoch 18/50, Train Loss: 6.5372, Val Loss:\n6.2179, SORS: 2.4466', '\\n', 'Epoch 19/50, Train Loss: 6.5263, Val Loss: 6.2138,\nSORS: 2.4457', '\\n', 'Epoch 20/50, Train Loss: 6.5155, Val Loss: 6.2102, SORS:\n2.4449', '\\n', 'Epoch 21/50, Train Loss: 6.5037, Val Loss: 6.2069, SORS:\n2.4441', '\\n', 'Epoch 22/50, Train Loss: 6.4919, Val Loss: 6.2031, SORS:\n2.4432', '\\n', 'Epoch 23/50, Train Loss: 6.4809, Val Loss: 6.1998, SORS:\n2.4424', '\\n', 'Epoch 24/50, Train Loss: 6.4699, Val Loss: 6.1961, SORS:\n2.4415', '\\n', 'Epoch 25/50, Train Loss: 6.4592, Val Loss: 6.1930, SORS:\n2.4407', '\\n', 'Epoch 26/50, Train Loss: 6.4494, Val Loss: 6.1901, SORS:\n2.4400', '\\n', 'Epoch 27/50, Train Loss: 6.4392, Val Loss: 6.1875, SORS:\n2.4393', '\\n', 'Epoch 28/50, Train Loss: 6.4293, Val Loss: 6.1843, SORS:\n2.4385', '\\n', 'Epoch 29/50, Train Loss: 6.4200, Val Loss: 6.1816, SORS:\n2.4377', '\\n', 'Epoch 30/50, Train Loss: 6.4106, Val Loss: 6.1786, SORS:\n2.4369', '\\n', 'Epoch 31/50, Train Loss: 6.4022, Val Loss: 6.1760, SORS:\n2.4362', '\\n', 'Epoch 32/50, Train Loss: 6.3936, Val Loss: 6.1725, SORS:\n2.4353', '\\n', 'Epoch 33/50, Train Loss: 6.3851, Val Loss: 6.1700, SORS:\n2.4346', '\\n', 'Epoch 34/50, Train Loss: 6.3776, Val Loss: 6.1676, SORS:\n2.4339', '\\n', 'Epoch 35/50, Train Loss: 6.3696, Val Loss: 6.1654, SORS:\n2.4333', '\\n', 'Epoch 36/50, Train Loss: 6.3623, Val Loss: 6.1625, SORS:\n2.4325', '\\n', 'Epoch 37/50, Train Loss: 6.3548, Val Loss: 6.1604, SORS:\n2.4319', '\\n', 'Epoch 38/50, Train Loss: 6.3479, Val Loss: 6.1576, SORS:\n2.4311', '\\n', 'Epoch 39/50, Train Loss: 6.3403, Val Loss: 6.1557, SORS:\n2.4305', '\\n', 'Epoch 40/50, Train Loss: 6.3345, Val Loss: 6.1525, SORS:\n2.4297', '\\n', 'Epoch 41/50, Train Loss: 6.3271, Val Loss: 6.1498, SORS:\n2.4289', '\\n', 'Epoch 42/50, Train Loss: 6.3204, Val Loss: 6.1471, SORS:\n2.4281', '\\n', 'Epoch 43/50, Train Loss: 6.3136, Val Loss: 6.1442, SORS:\n2.4273', '\\n', 'Epoch 44/50, Train Loss: 6.3066, Val Loss: 6.1422, SORS:\n2.4267', '\\n', 'Epoch 45/50, Train Loss: 6.3009, Val Loss: 6.1400, SORS:\n2.4261', '\\n', 'Epoch 46/50, Train Loss: 6.2944, Val Loss: 6.1376, SORS:\n2.4254', '\\n', 'Epoch 47/50, Train Loss: 6.2906, Val Loss: 6.1351, SORS:\n2.4246', '\\n', 'Epoch 48/50, Train Loss: 6.2835, Val Loss: 6.1327, SORS:\n2.4240', '\\n', 'Epoch 49/50, Train Loss: 6.2798, Val Loss: 6.1311, SORS:\n2.4235', '\\n', 'Epoch 50/50, Train Loss: 6.2747, Val Loss: 6.1280, SORS:\n2.4227', '\\n', 'Training full_dataset with batch size: 64', '\\n', 'Epoch 1/50,\nTrain Loss: 11.4860, Val Loss: 11.6238, SORS: 2.4720', '\\n', 'Epoch 2/50, Train\nLoss: 10.8232, Val Loss: 10.9441, SORS: 2.4667', '\\n', 'Epoch 3/50, Train Loss:\n10.0939, Val Loss: 10.1833, SORS: 2.4615', '\\n', 'Epoch 4/50, Train Loss:\n9.2738, Val Loss: 9.3149, SORS: 2.4564', '\\n', 'Epoch 5/50, Train Loss: 8.4121,\nVal Loss: 8.3930, SORS: 2.4508', '\\n', 'Epoch 6/50, Train Loss: 7.6112, Val\nLoss: 7.5168, SORS: 2.4446', '\\n', 'Epoch 7/50, Train Loss: 6.9913, Val Loss:\n6.8057, SORS: 2.4384', '\\n', 'Epoch 8/50, Train Loss: 6.6396, Val Loss: 6.3527,\nSORS: 2.4331', '\\n', 'Epoch 9/50, Train Loss: 6.5357, Val Loss: 6.1503, SORS:\n2.4287', '\\n', 'Epoch 10/50, Train Loss: 6.5627, Val Loss: 6.1023, SORS:\n2.4257', '\\n', 'Epoch 11/50, Train Loss: 6.6020, Val Loss: 6.1038, SORS:\n2.4242', '\\n', 'Epoch 12/50, Train Loss: 6.6108, Val Loss: 6.1067, SORS:\n2.4237', '\\n', 'Epoch 13/50, Train Loss: 6.5996, Val Loss: 6.1057, SORS:\n2.4237', '\\n', 'Epoch 14/50, Train Loss: 6.5845, Val Loss: 6.1041, SORS:\n2.4237', '\\n', 'Epoch 15/50, Train Loss: 6.5718, Val Loss: 6.1034, SORS:\n2.4236', '\\n', 'Epoch 16/50, Train Loss: 6.5618, Val Loss: 6.1032, SORS:\n2.4235', '\\n', 'Epoch 17/50, Train Loss: 6.5533, Val Loss: 6.1031, SORS:\n2.4234', '\\n', 'Epoch 18/50, Train Loss: 6.5450, Val Loss: 6.1031, SORS:\n2.4232', '\\n', 'Epoch 19/50, Train Loss: 6.5360, Val Loss: 6.1031, SORS:\n2.4231', '\\n', 'Epoch 20/50, Train Loss: 6.5268, Val Loss: 6.1031, SORS:\n2.4229', '\\n', 'Epoch 21/50, Train Loss: 6.5179, Val Loss: 6.1030, SORS:\n2.4227', '\\n', 'Epoch 22/50, Train Loss: 6.5096, Val Loss: 6.1022, SORS:\n2.4224', '\\n', 'Epoch 23/50, Train Loss: 6.5006, Val Loss: 6.1008, SORS:\n2.4219', '\\n', 'Epoch 24/50, Train Loss: 6.4914, Val Loss: 6.1006, SORS:\n2.4216', '\\n', 'Epoch 25/50, Train Loss: 6.4819, Val Loss: 6.1008, SORS:\n2.4215', '\\n', 'Epoch 26/50, Train Loss: 6.4714, Val Loss: 6.1013, SORS:\n2.4213', '\\n', 'Epoch 27/50, Train Loss: 6.4601, Val Loss: 6.1013, SORS:\n2.4211', '\\n', 'Epoch 28/50, Train Loss: 6.4489, Val Loss: 6.1025, SORS:\n2.4211', '\\n', 'Epoch 29/50, Train Loss: 6.4380, Val Loss: 6.1035, SORS:\n2.4211', '\\n', 'Epoch 30/50, Train Loss: 6.4273, Val Loss: 6.1044, SORS:\n2.4211', '\\n', 'Epoch 31/50, Train Loss: 6.4167, Val Loss: 6.1052, SORS:\n2.4210', '\\n', 'Epoch 32/50, Train Loss: 6.4066, Val Loss: 6.1062, SORS:\n2.4210', '\\n', 'Epoch 33/50, Train Loss: 6.3961, Val Loss: 6.1072, SORS:\n2.4209', '\\n', 'Epoch 34/50, Train Loss: 6.3873, Val Loss: 6.1078, SORS:\n2.4208', '\\n', 'Epoch 35/50, Train Loss: 6.3798, Val Loss: 6.1082, SORS:\n2.4207', '\\n', 'Epoch 36/50, Train Loss: 6.3712, Val Loss: 6.1088, SORS:\n2.4206', '\\n', 'Epoch 37/50, Train Loss: 6.3628, Val Loss: 6.1094, SORS:\n2.4205', '\\n', 'Epoch 38/50, Train Loss: 6.3555, Val Loss: 6.1099, SORS:\n2.4203', '\\n', 'Epoch 39/50, Train Loss: 6.3471, Val Loss: 6.1104, SORS:\n2.4202', '\\n', 'Epoch 40/50, Train Loss: 6.3394, Val Loss: 6.1108, SORS:\n2.4200', '\\n', 'Epoch 41/50, Train Loss: 6.3318, Val Loss: 6.1115, SORS:\n2.4200', '\\n', 'Epoch 42/50, Train Loss: 6.3242, Val Loss: 6.1119, SORS:\n2.4198', '\\n', 'Epoch 43/50, Train Loss: 6.3163, Val Loss: 6.1125, SORS:\n2.4197', '\\n', 'Epoch 44/50, Train Loss: 6.3097, Val Loss: 6.1132, SORS:\n2.4196', '\\n', 'Epoch 45/50, Train Loss: 6.3026, Val Loss: 6.1137, SORS:\n2.4195', '\\n', 'Epoch 46/50, Train Loss: 6.2951, Val Loss: 6.1143, SORS:\n2.4194', '\\n', 'Epoch 47/50, Train Loss: 6.2892, Val Loss: 6.1150, SORS:\n2.4193', '\\n', 'Epoch 48/50, Train Loss: 6.2829, Val Loss: 6.1156, SORS:\n2.4192', '\\n', 'Epoch 49/50, Train Loss: 6.2764, Val Loss: 6.1162, SORS:\n2.4191', '\\n', 'Epoch 50/50, Train Loss: 6.2700, Val Loss: 6.1169, SORS:\n2.4190', '\\n', 'Training full_dataset with batch size: 128', '\\n', 'Epoch 1/50,\nTrain Loss: 11.4136, Val Loss: 11.5275, SORS: 2.4790', '\\n', 'Epoch 2/50, Train\nLoss: 10.9825, Val Loss: 11.0690, SORS: 2.4771', '\\n', 'Epoch 3/50, Train Loss:\n10.5739, Val Loss: 10.6329, SORS: 2.4762', '\\n', 'Epoch 4/50, Train Loss:\n10.1806, Val Loss: 10.2103, SORS: 2.4756', '\\n', 'Epoch 5/50, Train Loss:\n9.7830, Val Loss: 9.7905, SORS: 2.4747', '\\n', 'Epoch 6/50, Train Loss: 9.3828,\nVal Loss: 9.3707, SORS: 2.4734', '\\n', 'Epoch 7/50, Train Loss: 8.9883, Val\nLoss: 8.9547, SORS: 2.4723', '\\n', 'Epoch 8/50, Train Loss: 8.6001, Val Loss:\n8.5441, SORS: 2.4711', '\\n', 'Epoch 9/50, Train Loss: 8.2245, Val Loss: 8.1437,\nSORS: 2.4693', '\\n', 'Epoch 10/50, Train Loss: 7.8745, Val Loss: 7.7645, SORS:\n2.4680', '\\n', 'Epoch 11/50, Train Loss: 7.5587, Val Loss: 7.4145, SORS:\n2.4666', '\\n', 'Epoch 12/50, Train Loss: 7.2841, Val Loss: 7.1016, SORS:\n2.4650', '\\n', 'Epoch 13/50, Train Loss: 7.0589, Val Loss: 6.8363, SORS:\n2.4635', '\\n', 'Epoch 14/50, Train Loss: 6.8905, Val Loss: 6.6239, SORS:\n2.4618', '\\n', 'Epoch 15/50, Train Loss: 6.7776, Val Loss: 6.4656, SORS:\n2.4600', '\\n', 'Epoch 16/50, Train Loss: 6.7142, Val Loss: 6.3588, SORS:\n2.4584', '\\n', 'Epoch 17/50, Train Loss: 6.6885, Val Loss: 6.2944, SORS:\n2.4570', '\\n', 'Epoch 18/50, Train Loss: 6.6867, Val Loss: 6.2607, SORS:\n2.4557', '\\n', 'Epoch 19/50, Train Loss: 6.6954, Val Loss: 6.2457, SORS:\n2.4546', '\\n', 'Epoch 20/50, Train Loss: 6.7047, Val Loss: 6.2400, SORS:\n2.4538', '\\n', 'Epoch 21/50, Train Loss: 6.7096, Val Loss: 6.2378, SORS:\n2.4531', '\\n', 'Epoch 22/50, Train Loss: 6.7089, Val Loss: 6.2361, SORS:\n2.4526', '\\n', 'Epoch 23/50, Train Loss: 6.7040, Val Loss: 6.2342, SORS:\n2.4522', '\\n', 'Epoch 24/50, Train Loss: 6.6964, Val Loss: 6.2321, SORS:\n2.4518', '\\n', 'Epoch 25/50, Train Loss: 6.6877, Val Loss: 6.2300, SORS:\n2.4515', '\\n', 'Epoch 26/50, Train Loss: 6.6787, Val Loss: 6.2279, SORS:\n2.4511', '\\n', 'Epoch 27/50, Train Loss: 6.6699, Val Loss: 6.2257, SORS:\n2.4508', '\\n', 'Epoch 28/50, Train Loss: 6.6614, Val Loss: 6.2235, SORS:\n2.4504', '\\n', 'Epoch 29/50, Train Loss: 6.6530, Val Loss: 6.2213, SORS:\n2.4500', '\\n', 'Epoch 30/50, Train Loss: 6.6447, Val Loss: 6.2191, SORS:\n2.4496', '\\n', 'Epoch 31/50, Train Loss: 6.6363, Val Loss: 6.2169, SORS:\n2.4491', '\\n', 'Epoch 32/50, Train Loss: 6.6275, Val Loss: 6.2146, SORS:\n2.4487', '\\n', 'Epoch 33/50, Train Loss: 6.6188, Val Loss: 6.2124, SORS:\n2.4482', '\\n', 'Epoch 34/50, Train Loss: 6.6100, Val Loss: 6.2102, SORS:\n2.4478', '\\n', 'Epoch 35/50, Train Loss: 6.6010, Val Loss: 6.2083, SORS:\n2.4473', '\\n', 'Epoch 36/50, Train Loss: 6.5919, Val Loss: 6.2063, SORS:\n2.4469', '\\n', 'Epoch 37/50, Train Loss: 6.5829, Val Loss: 6.2044, SORS:\n2.4465', '\\n', 'Epoch 38/50, Train Loss: 6.5739, Val Loss: 6.2025, SORS:\n2.4461', '\\n', 'Epoch 39/50, Train Loss: 6.5650, Val Loss: 6.2007, SORS:\n2.4457', '\\n', 'Epoch 40/50, Train Loss: 6.5563, Val Loss: 6.1989, SORS:\n2.4452', '\\n', 'Epoch 41/50, Train Loss: 6.5475, Val Loss: 6.1972, SORS:\n2.4448', '\\n', 'Epoch 42/50, Train Loss: 6.5385, Val Loss: 6.1954, SORS:\n2.4444', '\\n', 'Epoch 43/50, Train Loss: 6.5292, Val Loss: 6.1936, SORS:\n2.4439', '\\n', 'Epoch 44/50, Train Loss: 6.5198, Val Loss: 6.1918, SORS:\n2.4435', '\\n', 'Epoch 45/50, Train Loss: 6.5104, Val Loss: 6.1900, SORS:\n2.4430', '\\n', 'Epoch 46/50, Train Loss: 6.5010, Val Loss: 6.1883, SORS:\n2.4426', '\\n', 'Epoch 47/50, Train Loss: 6.4918, Val Loss: 6.1866, SORS:\n2.4421', '\\n', 'Epoch 48/50, Train Loss: 6.4822, Val Loss: 6.1849, SORS:\n2.4417', '\\n', 'Epoch 49/50, Train Loss: 6.4726, Val Loss: 6.1834, SORS:\n2.4412', '\\n', 'Epoch 50/50, Train Loss: 6.4628, Val Loss: 6.1819, SORS:\n2.4408', '\\n', 'Training full_dataset with batch size: 256', '\\n', 'Epoch 1/50,\nTrain Loss: 11.3909, Val Loss: 11.4504, SORS: 2.4745', '\\n', 'Epoch 2/50, Train\nLoss: 11.1796, Val Loss: 11.2228, SORS: 2.4735', '\\n', 'Epoch 3/50, Train Loss:\n10.9654, Val Loss: 10.9927, SORS: 2.4725', '\\n', 'Epoch 4/50, Train Loss:\n10.7464, Val Loss: 10.7578, SORS: 2.4715', '\\n', 'Epoch 5/50, Train Loss:\n10.5215, Val Loss: 10.5137, SORS: 2.4702', '\\n', 'Epoch 6/50, Train Loss:\n10.2894, Val Loss: 10.2619, SORS: 2.4690', '\\n', 'Epoch 7/50, Train Loss:\n10.0484, Val Loss: 10.0014, SORS: 2.4679', '\\n', 'Epoch 8/50, Train Loss:\n9.7957, Val Loss: 9.7319, SORS: 2.4669', '\\n', 'Epoch 9/50, Train Loss: 9.5337,\nVal Loss: 9.4528, SORS: 2.4657', '\\n', 'Epoch 10/50, Train Loss: 9.2619, Val\nLoss: 9.1664, SORS: 2.4647', '\\n', 'Epoch 11/50, Train Loss: 8.9850, Val Loss:\n8.8742, SORS: 2.4637', '\\n', 'Epoch 12/50, Train Loss: 8.7024, Val Loss: 8.5793,\nSORS: 2.4626', '\\n', 'Epoch 13/50, Train Loss: 8.4232, Val Loss: 8.2860, SORS:\n2.4616', '\\n', 'Epoch 14/50, Train Loss: 8.1523, Val Loss: 7.9981, SORS:\n2.4606', '\\n', 'Epoch 15/50, Train Loss: 7.8963, Val Loss: 7.7201, SORS:\n2.4593', '\\n', 'Epoch 16/50, Train Loss: 7.6579, Val Loss: 7.4572, SORS:\n2.4580', '\\n', 'Epoch 17/50, Train Loss: 7.4430, Val Loss: 7.2130, SORS:\n2.4566', '\\n', 'Epoch 18/50, Train Loss: 7.2527, Val Loss: 6.9922, SORS:\n2.4553', '\\n', 'Epoch 19/50, Train Loss: 7.0889, Val Loss: 6.7978, SORS:\n2.4540', '\\n', 'Epoch 20/50, Train Loss: 6.9556, Val Loss: 6.6305, SORS:\n2.4525', '\\n', 'Epoch 21/50, Train Loss: 6.8515, Val Loss: 6.4918, SORS:\n2.4510', '\\n', 'Epoch 22/50, Train Loss: 6.7755, Val Loss: 6.3813, SORS:\n2.4494', '\\n', 'Epoch 23/50, Train Loss: 6.7257, Val Loss: 6.2976, SORS:\n2.4480', '\\n', 'Epoch 24/50, Train Loss: 6.6982, Val Loss: 6.2383, SORS:\n2.4467', '\\n', 'Epoch 25/50, Train Loss: 6.6874, Val Loss: 6.1988, SORS:\n2.4454', '\\n', 'Epoch 26/50, Train Loss: 6.6888, Val Loss: 6.1749, SORS:\n2.4443', '\\n', 'Epoch 27/50, Train Loss: 6.6977, Val Loss: 6.1623, SORS:\n2.4433', '\\n', 'Epoch 28/50, Train Loss: 6.7084, Val Loss: 6.1566, SORS:\n2.4424', '\\n', 'Epoch 29/50, Train Loss: 6.7164, Val Loss: 6.1545, SORS:\n2.4417', '\\n', 'Epoch 30/50, Train Loss: 6.7200, Val Loss: 6.1535, SORS:\n2.4411', '\\n', 'Epoch 31/50, Train Loss: 6.7187, Val Loss: 6.1527, SORS:\n2.4407', '\\n', 'Epoch 32/50, Train Loss: 6.7127, Val Loss: 6.1518, SORS:\n2.4403', '\\n', 'Epoch 33/50, Train Loss: 6.7019, Val Loss: 6.1509, SORS:\n2.4401', '\\n', 'Epoch 34/50, Train Loss: 6.6894, Val Loss: 6.1500, SORS:\n2.4400', '\\n', 'Epoch 35/50, Train Loss: 6.6768, Val Loss: 6.1494, SORS:\n2.4399', '\\n', 'Epoch 36/50, Train Loss: 6.6642, Val Loss: 6.1487, SORS:\n2.4398', '\\n', 'Epoch 37/50, Train Loss: 6.6515, Val Loss: 6.1482, SORS:\n2.4397', '\\n', 'Epoch 38/50, Train Loss: 6.6394, Val Loss: 6.1476, SORS:\n2.4395', '\\n', 'Epoch 39/50, Train Loss: 6.6277, Val Loss: 6.1472, SORS:\n2.4394', '\\n', 'Epoch 40/50, Train Loss: 6.6163, Val Loss: 6.1469, SORS:\n2.4392', '\\n', 'Epoch 41/50, Train Loss: 6.6053, Val Loss: 6.1467, SORS:\n2.4391', '\\n', 'Epoch 42/50, Train Loss: 6.5944, Val Loss: 6.1465, SORS:\n2.4389', '\\n', 'Epoch 43/50, Train Loss: 6.5825, Val Loss: 6.1463, SORS:\n2.4387', '\\n', 'Epoch 44/50, Train Loss: 6.5707, Val Loss: 6.1460, SORS:\n2.4384', '\\n', 'Epoch 45/50, Train Loss: 6.5589, Val Loss: 6.1455, SORS:\n2.4381', '\\n', 'Epoch 46/50, Train Loss: 6.5470, Val Loss: 6.1454, SORS:\n2.4379', '\\n', 'Epoch 47/50, Train Loss: 6.5356, Val Loss: 6.1450, SORS:\n2.4376', '\\n', 'Epoch 48/50, Train Loss: 6.5241, Val Loss: 6.1446, SORS:\n2.4373', '\\n', 'Epoch 49/50, Train Loss: 6.5139, Val Loss: 6.1440, SORS:\n2.4370', '\\n', 'Epoch 50/50, Train Loss: 6.5041, Val Loss: 6.1434, SORS:\n2.4366', '\\n', 'Training pca_5d with batch size: 16', '\\n', 'Epoch 1/50, Train\nLoss: 12.9328, Val Loss: 11.3578, SORS: 2.4772', '\\n', 'Epoch 2/50, Train Loss:\n11.3540, Val Loss: 9.9523, SORS: 2.4773', '\\n', 'Epoch 3/50, Train Loss: 9.7835,\nVal Loss: 8.5841, SORS: 2.4750', '\\n', 'Epoch 4/50, Train Loss: 8.3897, Val\nLoss: 7.4723, SORS: 2.4722', '\\n', 'Epoch 5/50, Train Loss: 7.4331, Val Loss:\n6.7924, SORS: 2.4692', '\\n', 'Epoch 6/50, Train Loss: 6.9333, Val Loss: 6.5065,\nSORS: 2.4665', '\\n', 'Epoch 7/50, Train Loss: 6.7030, Val Loss: 6.4286, SORS:\n2.4644', '\\n', 'Epoch 8/50, Train Loss: 6.5898, Val Loss: 6.4169, SORS: 2.4629',\n'\\n', 'Epoch 9/50, Train Loss: 6.5233, Val Loss: 6.4180, SORS: 2.4619', '\\n',\n'Epoch 10/50, Train Loss: 6.4775, Val Loss: 6.4203, SORS: 2.4612', '\\n', 'Epoch\n11/50, Train Loss: 6.4416, Val Loss: 6.4220, SORS: 2.4606', '\\n', 'Epoch 12/50,\nTrain Loss: 6.4118, Val Loss: 6.4233, SORS: 2.4601', '\\n', 'Epoch 13/50, Train\nLoss: 6.3865, Val Loss: 6.4245, SORS: 2.4597', '\\n', 'Epoch 14/50, Train Loss:\n6.3665, Val Loss: 6.4257, SORS: 2.4594', '\\n', 'Epoch 15/50, Train Loss: 6.3454,\nVal Loss: 6.4264, SORS: 2.4591', '\\n', 'Epoch 16/50, Train Loss: 6.3236, Val\nLoss: 6.4273, SORS: 2.4589', '\\n', 'Epoch 17/50, Train Loss: 6.3029, Val Loss:\n6.4274, SORS: 2.4585', '\\n', 'Epoch 18/50, Train Loss: 6.2866, Val Loss: 6.4276,\nSORS: 2.4582', '\\n', 'Epoch 19/50, Train Loss: 6.2714, Val Loss: 6.4278, SORS:\n2.4578', '\\n', 'Epoch 20/50, Train Loss: 6.2575, Val Loss: 6.4277, SORS:\n2.4575', '\\n', 'Epoch 21/50, Train Loss: 6.2465, Val Loss: 6.4276, SORS:\n2.4572', '\\n', 'Epoch 22/50, Train Loss: 6.2367, Val Loss: 6.4278, SORS:\n2.4570', '\\n', 'Epoch 23/50, Train Loss: 6.2270, Val Loss: 6.4281, SORS:\n2.4569', '\\n', 'Epoch 24/50, Train Loss: 6.2175, Val Loss: 6.4284, SORS:\n2.4568', '\\n', 'Epoch 25/50, Train Loss: 6.2088, Val Loss: 6.4284, SORS:\n2.4567', '\\n', 'Epoch 26/50, Train Loss: 6.1990, Val Loss: 6.4285, SORS:\n2.4566', '\\n', 'Epoch 27/50, Train Loss: 6.1899, Val Loss: 6.4284, SORS:\n2.4565', '\\n', 'Epoch 28/50, Train Loss: 6.1817, Val Loss: 6.4282, SORS:\n2.4564', '\\n', 'Epoch 29/50, Train Loss: 6.1735, Val Loss: 6.4283, SORS:\n2.4563', '\\n', 'Epoch 30/50, Train Loss: 6.1654, Val Loss: 6.4281, SORS:\n2.4562', '\\n', 'Epoch 31/50, Train Loss: 6.1569, Val Loss: 6.4278, SORS:\n2.4561', '\\n', 'Epoch 32/50, Train Loss: 6.1499, Val Loss: 6.4274, SORS:\n2.4560', '\\n', 'Epoch 33/50, Train Loss: 6.1434, Val Loss: 6.4270, SORS:\n2.4559', '\\n', 'Epoch 34/50, Train Loss: 6.1367, Val Loss: 6.4265, SORS:\n2.4557', '\\n', 'Epoch 35/50, Train Loss: 6.1298, Val Loss: 6.4261, SORS:\n2.4555', '\\n', 'Epoch 36/50, Train Loss: 6.1231, Val Loss: 6.4256, SORS:\n2.4554', '\\n', 'Epoch 37/50, Train Loss: 6.1165, Val Loss: 6.4254, SORS:\n2.4553', '\\n', 'Epoch 38/50, Train Loss: 6.1108, Val Loss: 6.4252, SORS:\n2.4552', '\\n', 'Epoch 39/50, Train Loss: 6.1043, Val Loss: 6.4251, SORS:\n2.4551', '\\n', 'Epoch 40/50, Train Loss: 6.0980, Val Loss: 6.4250, SORS:\n2.4550', '\\n', 'Epoch 41/50, Train Loss: 6.0924, Val Loss: 6.4249, SORS:\n2.4549', '\\n', 'Epoch 42/50, Train Loss: 6.0872, Val Loss: 6.4250, SORS:\n2.4549', '\\n', 'Epoch 43/50, Train Loss: 6.0806, Val Loss: 6.4251, SORS:\n2.4549', '\\n', 'Epoch 44/50, Train Loss: 6.0750, Val Loss: 6.4253, SORS:\n2.4549', '\\n', 'Epoch 45/50, Train Loss: 6.0684, Val Loss: 6.4255, SORS:\n2.4549', '\\n', 'Epoch 46/50, Train Loss: 6.0625, Val Loss: 6.4257, SORS:\n2.4549', '\\n', 'Epoch 47/50, Train Loss: 6.0581, Val Loss: 6.4258, SORS:\n2.4549', '\\n', 'Epoch 48/50, Train Loss: 6.0507, Val Loss: 6.4261, SORS:\n2.4549', '\\n', 'Epoch 49/50, Train Loss: 6.0453, Val Loss: 6.4264, SORS:\n2.4549', '\\n', 'Epoch 50/50, Train Loss: 6.0402, Val Loss: 6.4266, SORS:\n2.4549', '\\n', 'Training pca_5d with batch size: 32', '\\n', 'Epoch 1/50, Train\nLoss: 11.4879, Val Loss: 11.6383, SORS: 2.4837', '\\n', 'Epoch 2/50, Train Loss:\n10.8318, Val Loss: 10.9217, SORS: 2.4803', '\\n', 'Epoch 3/50, Train Loss:\n10.1405, Val Loss: 10.1697, SORS: 2.4776', '\\n', 'Epoch 4/50, Train Loss:\n9.4303, Val Loss: 9.3949, SORS: 2.4746', '\\n', 'Epoch 5/50, Train Loss: 8.7270,\nVal Loss: 8.6358, SORS: 2.4713', '\\n', 'Epoch 6/50, Train Loss: 8.0767, Val\nLoss: 7.9385, SORS: 2.4679', '\\n', 'Epoch 7/50, Train Loss: 7.5312, Val Loss:\n7.3537, SORS: 2.4644', '\\n', 'Epoch 8/50, Train Loss: 7.1225, Val Loss: 6.9185,\nSORS: 2.4613', '\\n', 'Epoch 9/50, Train Loss: 6.8561, Val Loss: 6.6370, SORS:\n2.4590', '\\n', 'Epoch 10/50, Train Loss: 6.7023, Val Loss: 6.4818, SORS:\n2.4570', '\\n', 'Epoch 11/50, Train Loss: 6.6180, Val Loss: 6.4108, SORS:\n2.4554', '\\n', 'Epoch 12/50, Train Loss: 6.5705, Val Loss: 6.3846, SORS:\n2.4542', '\\n', 'Epoch 13/50, Train Loss: 6.5373, Val Loss: 6.3773, SORS:\n2.4533', '\\n', 'Epoch 14/50, Train Loss: 6.5084, Val Loss: 6.3762, SORS:\n2.4527', '\\n', 'Epoch 15/50, Train Loss: 6.4818, Val Loss: 6.3770, SORS:\n2.4523', '\\n', 'Epoch 16/50, Train Loss: 6.4573, Val Loss: 6.3778, SORS:\n2.4520', '\\n', 'Epoch 17/50, Train Loss: 6.4349, Val Loss: 6.3789, SORS:\n2.4517', '\\n', 'Epoch 18/50, Train Loss: 6.4152, Val Loss: 6.3801, SORS:\n2.4515', '\\n', 'Epoch 19/50, Train Loss: 6.3972, Val Loss: 6.3813, SORS:\n2.4514', '\\n', 'Epoch 20/50, Train Loss: 6.3816, Val Loss: 6.3827, SORS:\n2.4514', '\\n', 'Epoch 21/50, Train Loss: 6.3679, Val Loss: 6.3843, SORS:\n2.4513', '\\n', 'Epoch 22/50, Train Loss: 6.3558, Val Loss: 6.3857, SORS:\n2.4513', '\\n', 'Epoch 23/50, Train Loss: 6.3435, Val Loss: 6.3871, SORS:\n2.4513', '\\n', 'Epoch 24/50, Train Loss: 6.3339, Val Loss: 6.3886, SORS:\n2.4513', '\\n', 'Epoch 25/50, Train Loss: 6.3254, Val Loss: 6.3901, SORS:\n2.4513', '\\n', 'Epoch 26/50, Train Loss: 6.3174, Val Loss: 6.3915, SORS:\n2.4513', '\\n', 'Epoch 27/50, Train Loss: 6.3099, Val Loss: 6.3929, SORS:\n2.4513', '\\n', 'Epoch 28/50, Train Loss: 6.3035, Val Loss: 6.3942, SORS:\n2.4513', '\\n', 'Epoch 29/50, Train Loss: 6.2976, Val Loss: 6.3954, SORS:\n2.4513', '\\n', 'Epoch 30/50, Train Loss: 6.2927, Val Loss: 6.3966, SORS:\n2.4514', '\\n', 'Epoch 31/50, Train Loss: 6.2879, Val Loss: 6.3975, SORS:\n2.4514', '\\n', 'Epoch 32/50, Train Loss: 6.2838, Val Loss: 6.3985, SORS:\n2.4514', '\\n', 'Epoch 33/50, Train Loss: 6.2796, Val Loss: 6.3993, SORS:\n2.4514', '\\n', 'Epoch 34/50, Train Loss: 6.2752, Val Loss: 6.4000, SORS:\n2.4514', '\\n', 'Epoch 35/50, Train Loss: 6.2712, Val Loss: 6.4006, SORS:\n2.4514', '\\n', 'Epoch 36/50, Train Loss: 6.2677, Val Loss: 6.4016, SORS:\n2.4515', '\\n', 'Epoch 37/50, Train Loss: 6.2642, Val Loss: 6.4025, SORS:\n2.4516', '\\n', 'Epoch 38/50, Train Loss: 6.2620, Val Loss: 6.4032, SORS:\n2.4517', '\\n', 'Epoch 39/50, Train Loss: 6.2598, Val Loss: 6.4037, SORS:\n2.4518', '\\n', 'Epoch 40/50, Train Loss: 6.2576, Val Loss: 6.4040, SORS:\n2.4517', '\\n', 'Epoch 41/50, Train Loss: 6.2556, Val Loss: 6.4044, SORS:\n2.4518', '\\n', 'Epoch 42/50, Train Loss: 6.2543, Val Loss: 6.4048, SORS:\n2.4518', '\\n', 'Epoch 43/50, Train Loss: 6.2526, Val Loss: 6.4049, SORS:\n2.4518', '\\n', 'Epoch 44/50, Train Loss: 6.2505, Val Loss: 6.4050, SORS:\n2.4518', '\\n', 'Epoch 45/50, Train Loss: 6.2488, Val Loss: 6.4052, SORS:\n2.4517', '\\n', 'Epoch 46/50, Train Loss: 6.2477, Val Loss: 6.4055, SORS:\n2.4518', '\\n', 'Epoch 47/50, Train Loss: 6.2452, Val Loss: 6.4059, SORS:\n2.4518', '\\n', 'Epoch 48/50, Train Loss: 6.2446, Val Loss: 6.4062, SORS:\n2.4519', '\\n', 'Epoch 49/50, Train Loss: 6.2435, Val Loss: 6.4062, SORS:\n2.4518', '\\n', 'Epoch 50/50, Train Loss: 6.2415, Val Loss: 6.4063, SORS:\n2.4518', '\\n', 'Training pca_5d with batch size: 64', '\\n', 'Epoch 1/50, Train\nLoss: 11.4541, Val Loss: 11.6877, SORS: 2.4865', '\\n', 'Epoch 2/50, Train Loss:\n11.1896, Val Loss: 11.4101, SORS: 2.4877', '\\n', 'Epoch 3/50, Train Loss:\n10.9198, Val Loss: 11.1254, SORS: 2.4888', '\\n', 'Epoch 4/50, Train Loss:\n10.6440, Val Loss: 10.8321, SORS: 2.4898', '\\n', 'Epoch 5/50, Train Loss:\n10.3580, Val Loss: 10.5279, SORS: 2.4910', '\\n', 'Epoch 6/50, Train Loss:\n10.0587, Val Loss: 10.2119, SORS: 2.4923', '\\n', 'Epoch 7/50, Train Loss:\n9.7488, Val Loss: 9.8838, SORS: 2.4936', '\\n', 'Epoch 8/50, Train Loss: 9.4306,\nVal Loss: 9.5446, SORS: 2.4950', '\\n', 'Epoch 9/50, Train Loss: 9.1053, Val\nLoss: 9.1966, SORS: 2.4962', '\\n', 'Epoch 10/50, Train Loss: 8.7744, Val Loss:\n8.8467, SORS: 2.4973', '\\n', 'Epoch 11/50, Train Loss: 8.4506, Val Loss: 8.5029,\nSORS: 2.4985', '\\n', 'Epoch 12/50, Train Loss: 8.1380, Val Loss: 8.1716, SORS:\n2.4997', '\\n', 'Epoch 13/50, Train Loss: 7.8416, Val Loss: 7.8615, SORS:\n2.5005', '\\n', 'Epoch 14/50, Train Loss: 7.5725, Val Loss: 7.5804, SORS:\n2.5011', '\\n', 'Epoch 15/50, Train Loss: 7.3365, Val Loss: 7.3349, SORS:\n2.5015', '\\n', 'Epoch 16/50, Train Loss: 7.1356, Val Loss: 7.1297, SORS:\n2.5016', '\\n', 'Epoch 17/50, Train Loss: 6.9738, Val Loss: 6.9627, SORS:\n2.5009', '\\n', 'Epoch 18/50, Train Loss: 6.8484, Val Loss: 6.8332, SORS:\n2.4996', '\\n', 'Epoch 19/50, Train Loss: 6.7535, Val Loss: 6.7379, SORS:\n2.4980', '\\n', 'Epoch 20/50, Train Loss: 6.6785, Val Loss: 6.6711, SORS:\n2.4962', '\\n', 'Epoch 21/50, Train Loss: 6.6188, Val Loss: 6.6256, SORS:\n2.4943', '\\n', 'Epoch 22/50, Train Loss: 6.5698, Val Loss: 6.5951, SORS:\n2.4923', '\\n', 'Epoch 23/50, Train Loss: 6.5279, Val Loss: 6.5744, SORS:\n2.4901', '\\n', 'Epoch 24/50, Train Loss: 6.4910, Val Loss: 6.5599, SORS:\n2.4879', '\\n', 'Epoch 25/50, Train Loss: 6.4572, Val Loss: 6.5489, SORS:\n2.4857', '\\n', 'Epoch 26/50, Train Loss: 6.4260, Val Loss: 6.5402, SORS:\n2.4836', '\\n', 'Epoch 27/50, Train Loss: 6.3965, Val Loss: 6.5330, SORS:\n2.4817', '\\n', 'Epoch 28/50, Train Loss: 6.3686, Val Loss: 6.5265, SORS:\n2.4798', '\\n', 'Epoch 29/50, Train Loss: 6.3421, Val Loss: 6.5205, SORS:\n2.4780', '\\n', 'Epoch 30/50, Train Loss: 6.3172, Val Loss: 6.5151, SORS:\n2.4763', '\\n', 'Epoch 31/50, Train Loss: 6.2946, Val Loss: 6.5102, SORS:\n2.4748', '\\n', 'Epoch 32/50, Train Loss: 6.2732, Val Loss: 6.5057, SORS:\n2.4734', '\\n', 'Epoch 33/50, Train Loss: 6.2535, Val Loss: 6.5014, SORS:\n2.4721', '\\n', 'Epoch 34/50, Train Loss: 6.2357, Val Loss: 6.4975, SORS:\n2.4708', '\\n', 'Epoch 35/50, Train Loss: 6.2199, Val Loss: 6.4939, SORS:\n2.4697', '\\n', 'Epoch 36/50, Train Loss: 6.2055, Val Loss: 6.4904, SORS:\n2.4686', '\\n', 'Epoch 37/50, Train Loss: 6.1921, Val Loss: 6.4872, SORS:\n2.4676', '\\n', 'Epoch 38/50, Train Loss: 6.1797, Val Loss: 6.4843, SORS:\n2.4667', '\\n', 'Epoch 39/50, Train Loss: 6.1683, Val Loss: 6.4817, SORS:\n2.4659', '\\n', 'Epoch 40/50, Train Loss: 6.1579, Val Loss: 6.4794, SORS:\n2.4651', '\\n', 'Epoch 41/50, Train Loss: 6.1482, Val Loss: 6.4773, SORS:\n2.4644', '\\n', 'Epoch 42/50, Train Loss: 6.1394, Val Loss: 6.4754, SORS:\n2.4638', '\\n', 'Epoch 43/50, Train Loss: 6.1317, Val Loss: 6.4735, SORS:\n2.4632', '\\n', 'Epoch 44/50, Train Loss: 6.1247, Val Loss: 6.4718, SORS:\n2.4626', '\\n', 'Epoch 45/50, Train Loss: 6.1184, Val Loss: 6.4703, SORS:\n2.4621', '\\n', 'Epoch 46/50, Train Loss: 6.1125, Val Loss: 6.4688, SORS:\n2.4616', '\\n', 'Epoch 47/50, Train Loss: 6.1069, Val Loss: 6.4675, SORS:\n2.4611', '\\n', 'Epoch 48/50, Train Loss: 6.1018, Val Loss: 6.4662, SORS:\n2.4607', '\\n', 'Epoch 49/50, Train Loss: 6.0970, Val Loss: 6.4650, SORS:\n2.4603', '\\n', 'Epoch 50/50, Train Loss: 6.0924, Val Loss: 6.4638, SORS:\n2.4599', '\\n', 'Training pca_5d with batch size: 128', '\\n', 'Epoch 1/50, Train\nLoss: 11.4948, Val Loss: 11.7163, SORS: 2.4827', '\\n', 'Epoch 2/50, Train Loss:\n11.2878, Val Loss: 11.5111, SORS: 2.4825', '\\n', 'Epoch 3/50, Train Loss:\n11.0860, Val Loss: 11.3113, SORS: 2.4827', '\\n', 'Epoch 4/50, Train Loss:\n10.8887, Val Loss: 11.1160, SORS: 2.4829', '\\n', 'Epoch 5/50, Train Loss:\n10.6941, Val Loss: 10.9233, SORS: 2.4831', '\\n', 'Epoch 6/50, Train Loss:\n10.5007, Val Loss: 10.7317, SORS: 2.4833', '\\n', 'Epoch 7/50, Train Loss:\n10.3070, Val Loss: 10.5397, SORS: 2.4835', '\\n', 'Epoch 8/50, Train Loss:\n10.1115, Val Loss: 10.3468, SORS: 2.4836', '\\n', 'Epoch 9/50, Train Loss:\n9.9139, Val Loss: 10.1523, SORS: 2.4839', '\\n', 'Epoch 10/50, Train Loss:\n9.7131, Val Loss: 9.9557, SORS: 2.4841', '\\n', 'Epoch 11/50, Train Loss: 9.5094,\nVal Loss: 9.7570, SORS: 2.4842', '\\n', 'Epoch 12/50, Train Loss: 9.3035, Val\nLoss: 9.5557, SORS: 2.4843', '\\n', 'Epoch 13/50, Train Loss: 9.0959, Val Loss:\n9.3530, SORS: 2.4843', '\\n', 'Epoch 14/50, Train Loss: 8.8866, Val Loss: 9.1501,\nSORS: 2.4844', '\\n', 'Epoch 15/50, Train Loss: 8.6762, Val Loss: 8.9474, SORS:\n2.4844', '\\n', 'Epoch 16/50, Train Loss: 8.4673, Val Loss: 8.7467, SORS:\n2.4843', '\\n', 'Epoch 17/50, Train Loss: 8.2615, Val Loss: 8.5494, SORS:\n2.4843', '\\n', 'Epoch 18/50, Train Loss: 8.0588, Val Loss: 8.3563, SORS:\n2.4842', '\\n', 'Epoch 19/50, Train Loss: 7.8618, Val Loss: 8.1690, SORS:\n2.4840', '\\n', 'Epoch 20/50, Train Loss: 7.6716, Val Loss: 7.9890, SORS:\n2.4838', '\\n', 'Epoch 21/50, Train Loss: 7.4893, Val Loss: 7.8176, SORS:\n2.4836', '\\n', 'Epoch 22/50, Train Loss: 7.3159, Val Loss: 7.6558, SORS:\n2.4832', '\\n', 'Epoch 23/50, Train Loss: 7.1533, Val Loss: 7.5044, SORS:\n2.4827', '\\n', 'Epoch 24/50, Train Loss: 7.0024, Val Loss: 7.3648, SORS:\n2.4820', '\\n', 'Epoch 25/50, Train Loss: 6.8631, Val Loss: 7.2374, SORS:\n2.4814', '\\n', 'Epoch 26/50, Train Loss: 6.7369, Val Loss: 7.1226, SORS:\n2.4806', '\\n', 'Epoch 27/50, Train Loss: 6.6248, Val Loss: 7.0197, SORS:\n2.4797', '\\n', 'Epoch 28/50, Train Loss: 6.5252, Val Loss: 6.9292, SORS:\n2.4787', '\\n', 'Epoch 29/50, Train Loss: 6.4380, Val Loss: 6.8511, SORS:\n2.4777', '\\n', 'Epoch 30/50, Train Loss: 6.3633, Val Loss: 6.7846, SORS:\n2.4766', '\\n', 'Epoch 31/50, Train Loss: 6.2997, Val Loss: 6.7290, SORS:\n2.4756', '\\n', 'Epoch 32/50, Train Loss: 6.2455, Val Loss: 6.6829, SORS:\n2.4745', '\\n', 'Epoch 33/50, Train Loss: 6.2012, Val Loss: 6.6452, SORS:\n2.4734', '\\n', 'Epoch 34/50, Train Loss: 6.1649, Val Loss: 6.6152, SORS:\n2.4723', '\\n', 'Epoch 35/50, Train Loss: 6.1355, Val Loss: 6.5915, SORS:\n2.4712', '\\n', 'Epoch 36/50, Train Loss: 6.1121, Val Loss: 6.5730, SORS:\n2.4702', '\\n', 'Epoch 37/50, Train Loss: 6.0938, Val Loss: 6.5587, SORS:\n2.4692', '\\n', 'Epoch 38/50, Train Loss: 6.0791, Val Loss: 6.5476, SORS:\n2.4682', '\\n', 'Epoch 39/50, Train Loss: 6.0672, Val Loss: 6.5389, SORS:\n2.4672', '\\n', 'Epoch 40/50, Train Loss: 6.0574, Val Loss: 6.5321, SORS:\n2.4664', '\\n', 'Epoch 41/50, Train Loss: 6.0490, Val Loss: 6.5266, SORS:\n2.4655', '\\n', 'Epoch 42/50, Train Loss: 6.0420, Val Loss: 6.5223, SORS:\n2.4647', '\\n', 'Epoch 43/50, Train Loss: 6.0360, Val Loss: 6.5186, SORS:\n2.4640', '\\n', 'Epoch 44/50, Train Loss: 6.0305, Val Loss: 6.5156, SORS:\n2.4633', '\\n', 'Epoch 45/50, Train Loss: 6.0254, Val Loss: 6.5131, SORS:\n2.4627', '\\n', 'Epoch 46/50, Train Loss: 6.0205, Val Loss: 6.5111, SORS:\n2.4622', '\\n', 'Epoch 47/50, Train Loss: 6.0158, Val Loss: 6.5092, SORS:\n2.4617', '\\n', 'Epoch 48/50, Train Loss: 6.0112, Val Loss: 6.5075, SORS:\n2.4613', '\\n', 'Epoch 49/50, Train Loss: 6.0067, Val Loss: 6.5060, SORS:\n2.4608', '\\n', 'Epoch 50/50, Train Loss: 6.0023, Val Loss: 6.5045, SORS:\n2.4604', '\\n', 'Training pca_5d with batch size: 256', '\\n', 'Epoch 1/50, Train\nLoss: 12.6966, Val Loss: 12.9837, SORS: 2.5606', '\\n', 'Epoch 2/50, Train Loss:\n12.5636, Val Loss: 12.8465, SORS: 2.5423', '\\n', 'Epoch 3/50, Train Loss:\n12.4312, Val Loss: 12.7106, SORS: 2.5264', '\\n', 'Epoch 4/50, Train Loss:\n12.2993, Val Loss: 12.5759, SORS: 2.5127', '\\n', 'Epoch 5/50, Train Loss:\n12.1686, Val Loss: 12.4424, SORS: 2.5018', '\\n', 'Epoch 6/50, Train Loss:\n12.0387, Val Loss: 12.3098, SORS: 2.4939', '\\n', 'Epoch 7/50, Train Loss:\n11.9093, Val Loss: 12.1782, SORS: 2.4882', '\\n', 'Epoch 8/50, Train Loss:\n11.7802, Val Loss: 12.0473, SORS: 2.4854', '\\n', 'Epoch 9/50, Train Loss:\n11.6517, Val Loss: 11.9170, SORS: 2.4836', '\\n', 'Epoch 10/50, Train Loss:\n11.5234, Val Loss: 11.7871, SORS: 2.4825', '\\n', 'Epoch 11/50, Train Loss:\n11.3951, Val Loss: 11.6575, SORS: 2.4816', '\\n', 'Epoch 12/50, Train Loss:\n11.2667, Val Loss: 11.5283, SORS: 2.4809', '\\n', 'Epoch 13/50, Train Loss:\n11.1380, Val Loss: 11.3992, SORS: 2.4804', '\\n', 'Epoch 14/50, Train Loss:\n11.0091, Val Loss: 11.2701, SORS: 2.4802', '\\n', 'Epoch 15/50, Train Loss:\n10.8798, Val Loss: 11.1408, SORS: 2.4800', '\\n', 'Epoch 16/50, Train Loss:\n10.7502, Val Loss: 11.0112, SORS: 2.4798', '\\n', 'Epoch 17/50, Train Loss:\n10.6202, Val Loss: 10.8815, SORS: 2.4796', '\\n', 'Epoch 18/50, Train Loss:\n10.4900, Val Loss: 10.7517, SORS: 2.4794', '\\n', 'Epoch 19/50, Train Loss:\n10.3593, Val Loss: 10.6217, SORS: 2.4792', '\\n', 'Epoch 20/50, Train Loss:\n10.2280, Val Loss: 10.4915, SORS: 2.4790', '\\n', 'Epoch 21/50, Train Loss:\n10.0957, Val Loss: 10.3610, SORS: 2.4787', '\\n', 'Epoch 22/50, Train Loss:\n9.9629, Val Loss: 10.2304, SORS: 2.4785', '\\n', 'Epoch 23/50, Train Loss:\n9.8301, Val Loss: 10.0997, SORS: 2.4783', '\\n', 'Epoch 24/50, Train Loss:\n9.6966, Val Loss: 9.9689, SORS: 2.4781', '\\n', 'Epoch 25/50, Train Loss: 9.5615,\nVal Loss: 9.8379, SORS: 2.4778', '\\n', 'Epoch 26/50, Train Loss: 9.4259, Val\nLoss: 9.7071, SORS: 2.4775', '\\n', 'Epoch 27/50, Train Loss: 9.2906, Val Loss:\n9.5764, SORS: 2.4773', '\\n', 'Epoch 28/50, Train Loss: 9.1554, Val Loss: 9.4461,\nSORS: 2.4770', '\\n', 'Epoch 29/50, Train Loss: 9.0206, Val Loss: 9.3161, SORS:\n2.4766', '\\n', 'Epoch 30/50, Train Loss: 8.8867, Val Loss: 9.1867, SORS:\n2.4762', '\\n', 'Epoch 31/50, Train Loss: 8.7535, Val Loss: 9.0585, SORS:\n2.4758', '\\n', 'Epoch 32/50, Train Loss: 8.6210, Val Loss: 8.9313, SORS:\n2.4753', '\\n', 'Epoch 33/50, Train Loss: 8.4897, Val Loss: 8.8054, SORS:\n2.4749', '\\n', 'Epoch 34/50, Train Loss: 8.3594, Val Loss: 8.6812, SORS:\n2.4745', '\\n', 'Epoch 35/50, Train Loss: 8.2308, Val Loss: 8.5588, SORS:\n2.4740', '\\n', 'Epoch 36/50, Train Loss: 8.1038, Val Loss: 8.4382, SORS:\n2.4736', '\\n', 'Epoch 37/50, Train Loss: 7.9796, Val Loss: 8.3200, SORS:\n2.4731', '\\n', 'Epoch 38/50, Train Loss: 7.8579, Val Loss: 8.2044, SORS:\n2.4726', '\\n', 'Epoch 39/50, Train Loss: 7.7392, Val Loss: 8.0915, SORS:\n2.4721', '\\n', 'Epoch 40/50, Train Loss: 7.6238, Val Loss: 7.9815, SORS:\n2.4715', '\\n', 'Epoch 41/50, Train Loss: 7.5116, Val Loss: 7.8747, SORS:\n2.4708', '\\n', 'Epoch 42/50, Train Loss: 7.4026, Val Loss: 7.7711, SORS:\n2.4701', '\\n', 'Epoch 43/50, Train Loss: 7.2976, Val Loss: 7.6712, SORS:\n2.4693', '\\n', 'Epoch 44/50, Train Loss: 7.1962, Val Loss: 7.5751, SORS:\n2.4686', '\\n', 'Epoch 45/50, Train Loss: 7.0977, Val Loss: 7.4832, SORS:\n2.4678', '\\n', 'Epoch 46/50, Train Loss: 7.0029, Val Loss: 7.3954, SORS:\n2.4671', '\\n', 'Epoch 47/50, Train Loss: 6.9127, Val Loss: 7.3119, SORS:\n2.4663', '\\n', 'Epoch 48/50, Train Loss: 6.8271, Val Loss: 7.2331, SORS:\n2.4655', '\\n', 'Epoch 49/50, Train Loss: 6.7458, Val Loss: 7.1588, SORS:\n2.4647', '\\n', 'Epoch 50/50, Train Loss: 6.6688, Val Loss: 7.0891, SORS:\n2.4639', '\\n', 'Training pca_3d with batch size: 16', '\\n', 'Epoch 1/50, Train\nLoss: 12.5668, Val Loss: 11.0279, SORS: 2.4829', '\\n', 'Epoch 2/50, Train Loss:\n11.3731, Val Loss: 9.8708, SORS: 2.4848', '\\n', 'Epoch 3/50, Train Loss:\n10.1317, Val Loss: 8.6909, SORS: 2.4845', '\\n', 'Epoch 4/50, Train Loss: 8.9807,\nVal Loss: 7.6435, SORS: 2.4837', '\\n', 'Epoch 5/50, Train Loss: 8.1304, Val\nLoss: 6.9358, SORS: 2.4819', '\\n', 'Epoch 6/50, Train Loss: 7.6565, Val Loss:\n6.5991, SORS: 2.4789', '\\n', 'Epoch 7/50, Train Loss: 7.4312, Val Loss: 6.4884,\nSORS: 2.4747', '\\n', 'Epoch 8/50, Train Loss: 7.3169, Val Loss: 6.4588, SORS:\n2.4705', '\\n', 'Epoch 9/50, Train Loss: 7.2441, Val Loss: 6.4469, SORS: 2.4667',\n'\\n', 'Epoch 10/50, Train Loss: 7.1905, Val Loss: 6.4379, SORS: 2.4636', '\\n',\n'Epoch 11/50, Train Loss: 7.1478, Val Loss: 6.4299, SORS: 2.4610', '\\n', 'Epoch\n12/50, Train Loss: 7.1130, Val Loss: 6.4232, SORS: 2.4589', '\\n', 'Epoch 13/50,\nTrain Loss: 7.0838, Val Loss: 6.4173, SORS: 2.4570', '\\n', 'Epoch 14/50, Train\nLoss: 7.0600, Val Loss: 6.4125, SORS: 2.4555', '\\n', 'Epoch 15/50, Train Loss:\n7.0393, Val Loss: 6.4082, SORS: 2.4541', '\\n', 'Epoch 16/50, Train Loss: 7.0223,\nVal Loss: 6.4044, SORS: 2.4529', '\\n', 'Epoch 17/50, Train Loss: 7.0070, Val\nLoss: 6.4011, SORS: 2.4518', '\\n', 'Epoch 18/50, Train Loss: 6.9950, Val Loss:\n6.3983, SORS: 2.4509', '\\n', 'Epoch 19/50, Train Loss: 6.9847, Val Loss: 6.3961,\nSORS: 2.4501', '\\n', 'Epoch 20/50, Train Loss: 6.9754, Val Loss: 6.3939, SORS:\n2.4494', '\\n', 'Epoch 21/50, Train Loss: 6.9656, Val Loss: 6.3920, SORS:\n2.4488', '\\n', 'Epoch 22/50, Train Loss: 6.9571, Val Loss: 6.3903, SORS:\n2.4482', '\\n', 'Epoch 23/50, Train Loss: 6.9505, Val Loss: 6.3892, SORS:\n2.4478', '\\n', 'Epoch 24/50, Train Loss: 6.9454, Val Loss: 6.3883, SORS:\n2.4475', '\\n', 'Epoch 25/50, Train Loss: 6.9400, Val Loss: 6.3875, SORS:\n2.4472', '\\n', 'Epoch 26/50, Train Loss: 6.9363, Val Loss: 6.3866, SORS:\n2.4469', '\\n', 'Epoch 27/50, Train Loss: 6.9329, Val Loss: 6.3859, SORS:\n2.4466', '\\n', 'Epoch 28/50, Train Loss: 6.9291, Val Loss: 6.3854, SORS:\n2.4464', '\\n', 'Epoch 29/50, Train Loss: 6.9268, Val Loss: 6.3847, SORS:\n2.4462', '\\n', 'Epoch 30/50, Train Loss: 6.9236, Val Loss: 6.3843, SORS:\n2.4460', '\\n', 'Epoch 31/50, Train Loss: 6.9213, Val Loss: 6.3839, SORS:\n2.4459', '\\n', 'Epoch 32/50, Train Loss: 6.9182, Val Loss: 6.3836, SORS:\n2.4457', '\\n', 'Epoch 33/50, Train Loss: 6.9157, Val Loss: 6.3832, SORS:\n2.4456', '\\n', 'Epoch 34/50, Train Loss: 6.9134, Val Loss: 6.3827, SORS:\n2.4454', '\\n', 'Epoch 35/50, Train Loss: 6.9105, Val Loss: 6.3823, SORS:\n2.4453', '\\n', 'Epoch 36/50, Train Loss: 6.9093, Val Loss: 6.3821, SORS:\n2.4452', '\\n', 'Epoch 37/50, Train Loss: 6.9073, Val Loss: 6.3819, SORS:\n2.4451', '\\n', 'Epoch 38/50, Train Loss: 6.9066, Val Loss: 6.3818, SORS:\n2.4450', '\\n', 'Epoch 39/50, Train Loss: 6.9063, Val Loss: 6.3817, SORS:\n2.4450', '\\n', 'Epoch 40/50, Train Loss: 6.9045, Val Loss: 6.3815, SORS:\n2.4449', '\\n', 'Epoch 41/50, Train Loss: 6.9039, Val Loss: 6.3814, SORS:\n2.4448', '\\n', 'Epoch 42/50, Train Loss: 6.9022, Val Loss: 6.3814, SORS:\n2.4448', '\\n', 'Epoch 43/50, Train Loss: 6.9016, Val Loss: 6.3815, SORS:\n2.4448', '\\n', 'Epoch 44/50, Train Loss: 6.9012, Val Loss: 6.3816, SORS:\n2.4447', '\\n', 'Epoch 45/50, Train Loss: 6.8994, Val Loss: 6.3817, SORS:\n2.4447', '\\n', 'Epoch 46/50, Train Loss: 6.8991, Val Loss: 6.3816, SORS:\n2.4447', '\\n', 'Epoch 47/50, Train Loss: 6.8976, Val Loss: 6.3817, SORS:\n2.4447', '\\n', 'Epoch 48/50, Train Loss: 6.8972, Val Loss: 6.3817, SORS:\n2.4447', '\\n', 'Epoch 49/50, Train Loss: 6.8952, Val Loss: 6.3816, SORS:\n2.4446', '\\n', 'Epoch 50/50, Train Loss: 6.8950, Val Loss: 6.3815, SORS:\n2.4446', '\\n', 'Training pca_3d with batch size: 32', '\\n', 'Epoch 1/50, Train\nLoss: 12.7613, Val Loss: 12.9600, SORS: 2.5538', '\\n', 'Epoch 2/50, Train Loss:\n11.8143, Val Loss: 11.9704, SORS: 2.4873', '\\n', 'Epoch 3/50, Train Loss:\n10.9456, Val Loss: 11.0557, SORS: 2.4856', '\\n', 'Epoch 4/50, Train Loss:\n10.1273, Val Loss: 10.1898, SORS: 2.4866', '\\n', 'Epoch 5/50, Train Loss:\n9.3605, Val Loss: 9.3747, SORS: 2.4873', '\\n', 'Epoch 6/50, Train Loss: 8.6631,\nVal Loss: 8.6289, SORS: 2.4874', '\\n', 'Epoch 7/50, Train Loss: 8.0582, Val\nLoss: 7.9785, SORS: 2.4868', '\\n', 'Epoch 8/50, Train Loss: 7.5674, Val Loss:\n7.4491, SORS: 2.4855', '\\n', 'Epoch 9/50, Train Loss: 7.2036, Val Loss: 7.0526,\nSORS: 2.4835', '\\n', 'Epoch 10/50, Train Loss: 6.9572, Val Loss: 6.7835, SORS:\n2.4808', '\\n', 'Epoch 11/50, Train Loss: 6.8076, Val Loss: 6.6207, SORS:\n2.4777', '\\n', 'Epoch 12/50, Train Loss: 6.7254, Val Loss: 6.5325, SORS:\n2.4745', '\\n', 'Epoch 13/50, Train Loss: 6.6828, Val Loss: 6.4897, SORS:\n2.4714', '\\n', 'Epoch 14/50, Train Loss: 6.6579, Val Loss: 6.4696, SORS:\n2.4686', '\\n', 'Epoch 15/50, Train Loss: 6.6399, Val Loss: 6.4590, SORS:\n2.4661', '\\n', 'Epoch 16/50, Train Loss: 6.6246, Val Loss: 6.4518, SORS:\n2.4639', '\\n', 'Epoch 17/50, Train Loss: 6.6101, Val Loss: 6.4460, SORS:\n2.4620', '\\n', 'Epoch 18/50, Train Loss: 6.5960, Val Loss: 6.4406, SORS:\n2.4604', '\\n', 'Epoch 19/50, Train Loss: 6.5826, Val Loss: 6.4356, SORS:\n2.4590', '\\n', 'Epoch 20/50, Train Loss: 6.5706, Val Loss: 6.4314, SORS:\n2.4578', '\\n', 'Epoch 21/50, Train Loss: 6.5599, Val Loss: 6.4277, SORS:\n2.4568', '\\n', 'Epoch 22/50, Train Loss: 6.5502, Val Loss: 6.4245, SORS:\n2.4559', '\\n', 'Epoch 23/50, Train Loss: 6.5415, Val Loss: 6.4217, SORS:\n2.4552', '\\n', 'Epoch 24/50, Train Loss: 6.5339, Val Loss: 6.4193, SORS:\n2.4545', '\\n', 'Epoch 25/50, Train Loss: 6.5274, Val Loss: 6.4172, SORS:\n2.4539', '\\n', 'Epoch 26/50, Train Loss: 6.5220, Val Loss: 6.4152, SORS:\n2.4533', '\\n', 'Epoch 27/50, Train Loss: 6.5167, Val Loss: 6.4136, SORS:\n2.4529', '\\n', 'Epoch 28/50, Train Loss: 6.5116, Val Loss: 6.4121, SORS:\n2.4524', '\\n', 'Epoch 29/50, Train Loss: 6.5064, Val Loss: 6.4110, SORS:\n2.4521', '\\n', 'Epoch 30/50, Train Loss: 6.5013, Val Loss: 6.4101, SORS:\n2.4518', '\\n', 'Epoch 31/50, Train Loss: 6.4963, Val Loss: 6.4094, SORS:\n2.4515', '\\n', 'Epoch 32/50, Train Loss: 6.4914, Val Loss: 6.4088, SORS:\n2.4513', '\\n', 'Epoch 33/50, Train Loss: 6.4868, Val Loss: 6.4083, SORS:\n2.4511', '\\n', 'Epoch 34/50, Train Loss: 6.4824, Val Loss: 6.4080, SORS:\n2.4509', '\\n', 'Epoch 35/50, Train Loss: 6.4781, Val Loss: 6.4079, SORS:\n2.4508', '\\n', 'Epoch 36/50, Train Loss: 6.4739, Val Loss: 6.4078, SORS:\n2.4507', '\\n', 'Epoch 37/50, Train Loss: 6.4696, Val Loss: 6.4078, SORS:\n2.4506', '\\n', 'Epoch 38/50, Train Loss: 6.4658, Val Loss: 6.4079, SORS:\n2.4505', '\\n', 'Epoch 39/50, Train Loss: 6.4625, Val Loss: 6.4081, SORS:\n2.4505', '\\n', 'Epoch 40/50, Train Loss: 6.4598, Val Loss: 6.4083, SORS:\n2.4504', '\\n', 'Epoch 41/50, Train Loss: 6.4567, Val Loss: 6.4085, SORS:\n2.4504', '\\n', 'Epoch 42/50, Train Loss: 6.4536, Val Loss: 6.4088, SORS:\n2.4504', '\\n', 'Epoch 43/50, Train Loss: 6.4503, Val Loss: 6.4091, SORS:\n2.4504', '\\n', 'Epoch 44/50, Train Loss: 6.4471, Val Loss: 6.4095, SORS:\n2.4504', '\\n', 'Epoch 45/50, Train Loss: 6.4441, Val Loss: 6.4100, SORS:\n2.4505', '\\n', 'Epoch 46/50, Train Loss: 6.4412, Val Loss: 6.4105, SORS:\n2.4505', '\\n', 'Epoch 47/50, Train Loss: 6.4383, Val Loss: 6.4109, SORS:\n2.4505', '\\n', 'Epoch 48/50, Train Loss: 6.4356, Val Loss: 6.4113, SORS:\n2.4505', '\\n', 'Epoch 49/50, Train Loss: 6.4334, Val Loss: 6.4118, SORS:\n2.4506', '\\n', 'Epoch 50/50, Train Loss: 6.4311, Val Loss: 6.4123, SORS:\n2.4506', '\\n', 'Training pca_3d with batch size: 64', '\\n', 'Epoch 1/50, Train\nLoss: 13.2350, Val Loss: 13.3780, SORS: 2.6209', '\\n', 'Epoch 2/50, Train Loss:\n12.9293, Val Loss: 13.0651, SORS: 2.5669', '\\n', 'Epoch 3/50, Train Loss:\n12.6394, Val Loss: 12.7673, SORS: 2.5272', '\\n', 'Epoch 4/50, Train Loss:\n12.3585, Val Loss: 12.4780, SORS: 2.5019', '\\n', 'Epoch 5/50, Train Loss:\n12.0785, Val Loss: 12.1902, SORS: 2.4875', '\\n', 'Epoch 6/50, Train Loss:\n11.7926, Val Loss: 11.8956, SORS: 2.4821', '\\n', 'Epoch 7/50, Train Loss:\n11.4964, Val Loss: 11.5873, SORS: 2.4795', '\\n', 'Epoch 8/50, Train Loss:\n11.1853, Val Loss: 11.2624, SORS: 2.4788', '\\n', 'Epoch 9/50, Train Loss:\n10.8558, Val Loss: 10.9190, SORS: 2.4783', '\\n', 'Epoch 10/50, Train Loss:\n10.5076, Val Loss: 10.5563, SORS: 2.4779', '\\n', 'Epoch 11/50, Train Loss:\n10.1409, Val Loss: 10.1745, SORS: 2.4774', '\\n', 'Epoch 12/50, Train Loss:\n9.7635, Val Loss: 9.7762, SORS: 2.4770', '\\n', 'Epoch 13/50, Train Loss: 9.3835,\nVal Loss: 9.3665, SORS: 2.4764', '\\n', 'Epoch 14/50, Train Loss: 9.0077, Val\nLoss: 8.9568, SORS: 2.4757', '\\n', 'Epoch 15/50, Train Loss: 8.6421, Val Loss:\n8.5570, SORS: 2.4748', '\\n', 'Epoch 16/50, Train Loss: 8.2930, Val Loss: 8.1770,\nSORS: 2.4737', '\\n', 'Epoch 17/50, Train Loss: 7.9700, Val Loss: 7.8276, SORS:\n2.4726', '\\n', 'Epoch 18/50, Train Loss: 7.6758, Val Loss: 7.5166, SORS:\n2.4713', '\\n', 'Epoch 19/50, Train Loss: 7.4233, Val Loss: 7.2494, SORS:\n2.4700', '\\n', 'Epoch 20/50, Train Loss: 7.2141, Val Loss: 7.0281, SORS:\n2.4686', '\\n', 'Epoch 21/50, Train Loss: 7.0454, Val Loss: 6.8533, SORS:\n2.4673', '\\n', 'Epoch 22/50, Train Loss: 6.9126, Val Loss: 6.7213, SORS:\n2.4660', '\\n', 'Epoch 23/50, Train Loss: 6.8129, Val Loss: 6.6254, SORS:\n2.4647', '\\n', 'Epoch 24/50, Train Loss: 6.7407, Val Loss: 6.5598, SORS:\n2.4633', '\\n', 'Epoch 25/50, Train Loss: 6.6891, Val Loss: 6.5172, SORS:\n2.4621', '\\n', 'Epoch 26/50, Train Loss: 6.6534, Val Loss: 6.4916, SORS:\n2.4611', '\\n', 'Epoch 27/50, Train Loss: 6.6307, Val Loss: 6.4773, SORS:\n2.4602', '\\n', 'Epoch 28/50, Train Loss: 6.6162, Val Loss: 6.4700, SORS:\n2.4595', '\\n', 'Epoch 29/50, Train Loss: 6.6061, Val Loss: 6.4667, SORS:\n2.4590', '\\n', 'Epoch 30/50, Train Loss: 6.5974, Val Loss: 6.4655, SORS:\n2.4585', '\\n', 'Epoch 31/50, Train Loss: 6.5903, Val Loss: 6.4654, SORS:\n2.4582', '\\n', 'Epoch 32/50, Train Loss: 6.5846, Val Loss: 6.4657, SORS:\n2.4580', '\\n', 'Epoch 33/50, Train Loss: 6.5795, Val Loss: 6.4661, SORS:\n2.4578', '\\n', 'Epoch 34/50, Train Loss: 6.5747, Val Loss: 6.4665, SORS:\n2.4577', '\\n', 'Epoch 35/50, Train Loss: 6.5702, Val Loss: 6.4667, SORS:\n2.4575', '\\n', 'Epoch 36/50, Train Loss: 6.5659, Val Loss: 6.4667, SORS:\n2.4574', '\\n', 'Epoch 37/50, Train Loss: 6.5616, Val Loss: 6.4666, SORS:\n2.4573', '\\n', 'Epoch 38/50, Train Loss: 6.5572, Val Loss: 6.4662, SORS:\n2.4572', '\\n', 'Epoch 39/50, Train Loss: 6.5529, Val Loss: 6.4657, SORS:\n2.4571', '\\n', 'Epoch 40/50, Train Loss: 6.5488, Val Loss: 6.4651, SORS:\n2.4570', '\\n', 'Epoch 41/50, Train Loss: 6.5448, Val Loss: 6.4645, SORS:\n2.4568', '\\n', 'Epoch 42/50, Train Loss: 6.5410, Val Loss: 6.4638, SORS:\n2.4567', '\\n', 'Epoch 43/50, Train Loss: 6.5371, Val Loss: 6.4631, SORS:\n2.4566', '\\n', 'Epoch 44/50, Train Loss: 6.5334, Val Loss: 6.4624, SORS:\n2.4565', '\\n', 'Epoch 45/50, Train Loss: 6.5293, Val Loss: 6.4616, SORS:\n2.4564', '\\n', 'Epoch 46/50, Train Loss: 6.5248, Val Loss: 6.4608, SORS:\n2.4563', '\\n', 'Epoch 47/50, Train Loss: 6.5202, Val Loss: 6.4600, SORS:\n2.4562', '\\n', 'Epoch 48/50, Train Loss: 6.5155, Val Loss: 6.4593, SORS:\n2.4562', '\\n', 'Epoch 49/50, Train Loss: 6.5109, Val Loss: 6.4586, SORS:\n2.4561', '\\n', 'Epoch 50/50, Train Loss: 6.5067, Val Loss: 6.4579, SORS:\n2.4560', '\\n', 'Training pca_3d with batch size: 128', '\\n', 'Epoch 1/50, Train\nLoss: 12.2399, Val Loss: 12.4160, SORS: 2.4999', '\\n', 'Epoch 2/50, Train Loss:\n12.0219, Val Loss: 12.1947, SORS: 2.4862', '\\n', 'Epoch 3/50, Train Loss:\n11.8063, Val Loss: 11.9752, SORS: 2.4786', '\\n', 'Epoch 4/50, Train Loss:\n11.5922, Val Loss: 11.7568, SORS: 2.4746', '\\n', 'Epoch 5/50, Train Loss:\n11.3791, Val Loss: 11.5387, SORS: 2.4729', '\\n', 'Epoch 6/50, Train Loss:\n11.1661, Val Loss: 11.3203, SORS: 2.4734', '\\n', 'Epoch 7/50, Train Loss:\n10.9520, Val Loss: 11.1008, SORS: 2.4740', '\\n', 'Epoch 8/50, Train Loss:\n10.7361, Val Loss: 10.8795, SORS: 2.4745', '\\n', 'Epoch 9/50, Train Loss:\n10.5171, Val Loss: 10.6564, SORS: 2.4751', '\\n', 'Epoch 10/50, Train Loss:\n10.2966, Val Loss: 10.4311, SORS: 2.4756', '\\n', 'Epoch 11/50, Train Loss:\n10.0743, Val Loss: 10.2041, SORS: 2.4760', '\\n', 'Epoch 12/50, Train Loss:\n9.8505, Val Loss: 9.9753, SORS: 2.4764', '\\n', 'Epoch 13/50, Train Loss: 9.6258,\nVal Loss: 9.7455, SORS: 2.4767', '\\n', 'Epoch 14/50, Train Loss: 9.4006, Val\nLoss: 9.5158, SORS: 2.4771', '\\n', 'Epoch 15/50, Train Loss: 9.1751, Val Loss:\n9.2868, SORS: 2.4775', '\\n', 'Epoch 16/50, Train Loss: 8.9518, Val Loss: 9.0598,\nSORS: 2.4778', '\\n', 'Epoch 17/50, Train Loss: 8.7323, Val Loss: 8.8362, SORS:\n2.4781', '\\n', 'Epoch 18/50, Train Loss: 8.5171, Val Loss: 8.6176, SORS:\n2.4784', '\\n', 'Epoch 19/50, Train Loss: 8.3071, Val Loss: 8.4052, SORS:\n2.4787', '\\n', 'Epoch 20/50, Train Loss: 8.1052, Val Loss: 8.1995, SORS:\n2.4788', '\\n', 'Epoch 21/50, Train Loss: 7.9120, Val Loss: 8.0029, SORS:\n2.4788', '\\n', 'Epoch 22/50, Train Loss: 7.7287, Val Loss: 7.8171, SORS:\n2.4789', '\\n', 'Epoch 23/50, Train Loss: 7.5581, Val Loss: 7.6433, SORS:\n2.4789', '\\n', 'Epoch 24/50, Train Loss: 7.4019, Val Loss: 7.4832, SORS:\n2.4791', '\\n', 'Epoch 25/50, Train Loss: 7.2605, Val Loss: 7.3372, SORS:\n2.4792', '\\n', 'Epoch 26/50, Train Loss: 7.1317, Val Loss: 7.2052, SORS:\n2.4792', '\\n', 'Epoch 27/50, Train Loss: 7.0155, Val Loss: 7.0876, SORS:\n2.4790', '\\n', 'Epoch 28/50, Train Loss: 6.9125, Val Loss: 6.9845, SORS:\n2.4786', '\\n', 'Epoch 29/50, Train Loss: 6.8228, Val Loss: 6.8948, SORS:\n2.4781', '\\n', 'Epoch 30/50, Train Loss: 6.7464, Val Loss: 6.8185, SORS:\n2.4774', '\\n', 'Epoch 31/50, Train Loss: 6.6812, Val Loss: 6.7552, SORS:\n2.4767', '\\n', 'Epoch 32/50, Train Loss: 6.6266, Val Loss: 6.7035, SORS:\n2.4759', '\\n', 'Epoch 33/50, Train Loss: 6.5823, Val Loss: 6.6618, SORS:\n2.4752', '\\n', 'Epoch 34/50, Train Loss: 6.5466, Val Loss: 6.6282, SORS:\n2.4743', '\\n', 'Epoch 35/50, Train Loss: 6.5167, Val Loss: 6.6014, SORS:\n2.4733', '\\n', 'Epoch 36/50, Train Loss: 6.4923, Val Loss: 6.5804, SORS:\n2.4722', '\\n', 'Epoch 37/50, Train Loss: 6.4718, Val Loss: 6.5642, SORS:\n2.4713', '\\n', 'Epoch 38/50, Train Loss: 6.4541, Val Loss: 6.5515, SORS:\n2.4703', '\\n', 'Epoch 39/50, Train Loss: 6.4388, Val Loss: 6.5415, SORS:\n2.4694', '\\n', 'Epoch 40/50, Train Loss: 6.4250, Val Loss: 6.5333, SORS:\n2.4684', '\\n', 'Epoch 41/50, Train Loss: 6.4126, Val Loss: 6.5267, SORS:\n2.4676', '\\n', 'Epoch 42/50, Train Loss: 6.4010, Val Loss: 6.5214, SORS:\n2.4667', '\\n', 'Epoch 43/50, Train Loss: 6.3906, Val Loss: 6.5169, SORS:\n2.4659', '\\n', 'Epoch 44/50, Train Loss: 6.3806, Val Loss: 6.5129, SORS:\n2.4652', '\\n', 'Epoch 45/50, Train Loss: 6.3710, Val Loss: 6.5094, SORS:\n2.4644', '\\n', 'Epoch 46/50, Train Loss: 6.3616, Val Loss: 6.5062, SORS:\n2.4637', '\\n', 'Epoch 47/50, Train Loss: 6.3528, Val Loss: 6.5033, SORS:\n2.4630', '\\n', 'Epoch 48/50, Train Loss: 6.3448, Val Loss: 6.5007, SORS:\n2.4623', '\\n', 'Epoch 49/50, Train Loss: 6.3373, Val Loss: 6.4984, SORS:\n2.4618', '\\n', 'Epoch 50/50, Train Loss: 6.3298, Val Loss: 6.4964, SORS:\n2.4612', '\\n', 'Training pca_3d with batch size: 256', '\\n', 'Epoch 1/50, Train\nLoss: 12.1663, Val Loss: 12.3007, SORS: 2.4912', '\\n', 'Epoch 2/50, Train Loss:\n12.0213, Val Loss: 12.1509, SORS: 2.4855', '\\n', 'Epoch 3/50, Train Loss:\n11.8785, Val Loss: 12.0034, SORS: 2.4820', '\\n', 'Epoch 4/50, Train Loss:\n11.7380, Val Loss: 11.8581, SORS: 2.4806', '\\n', 'Epoch 5/50, Train Loss:\n11.5997, Val Loss: 11.7152, SORS: 2.4798', '\\n', 'Epoch 6/50, Train Loss:\n11.4638, Val Loss: 11.5745, SORS: 2.4792', '\\n', 'Epoch 7/50, Train Loss:\n11.3301, Val Loss: 11.4361, SORS: 2.4790', '\\n', 'Epoch 8/50, Train Loss:\n11.1982, Val Loss: 11.2999, SORS: 2.4788', '\\n', 'Epoch 9/50, Train Loss:\n11.0681, Val Loss: 11.1657, SORS: 2.4785', '\\n', 'Epoch 10/50, Train Loss:\n10.9399, Val Loss: 11.0333, SORS: 2.4783', '\\n', 'Epoch 11/50, Train Loss:\n10.8136, Val Loss: 10.9028, SORS: 2.4781', '\\n', 'Epoch 12/50, Train Loss:\n10.6888, Val Loss: 10.7740, SORS: 2.4778', '\\n', 'Epoch 13/50, Train Loss:\n10.5654, Val Loss: 10.6467, SORS: 2.4776', '\\n', 'Epoch 14/50, Train Loss:\n10.4428, Val Loss: 10.5207, SORS: 2.4773', '\\n', 'Epoch 15/50, Train Loss:\n10.3214, Val Loss: 10.3960, SORS: 2.4771', '\\n', 'Epoch 16/50, Train Loss:\n10.2011, Val Loss: 10.2725, SORS: 2.4768', '\\n', 'Epoch 17/50, Train Loss:\n10.0816, Val Loss: 10.1503, SORS: 2.4766', '\\n', 'Epoch 18/50, Train Loss:\n9.9633, Val Loss: 10.0292, SORS: 2.4764', '\\n', 'Epoch 19/50, Train Loss:\n9.8459, Val Loss: 9.9092, SORS: 2.4761', '\\n', 'Epoch 20/50, Train Loss: 9.7290,\nVal Loss: 9.7902, SORS: 2.4759', '\\n', 'Epoch 21/50, Train Loss: 9.6131, Val\nLoss: 9.6721, SORS: 2.4757', '\\n', 'Epoch 22/50, Train Loss: 9.4983, Val Loss:\n9.5548, SORS: 2.4754', '\\n', 'Epoch 23/50, Train Loss: 9.3841, Val Loss: 9.4384,\nSORS: 2.4752', '\\n', 'Epoch 24/50, Train Loss: 9.2709, Val Loss: 9.3230, SORS:\n2.4750', '\\n', 'Epoch 25/50, Train Loss: 9.1583, Val Loss: 9.2085, SORS:\n2.4747', '\\n', 'Epoch 26/50, Train Loss: 9.0468, Val Loss: 9.0948, SORS:\n2.4744', '\\n', 'Epoch 27/50, Train Loss: 8.9363, Val Loss: 8.9823, SORS:\n2.4741', '\\n', 'Epoch 28/50, Train Loss: 8.8265, Val Loss: 8.8712, SORS:\n2.4739', '\\n', 'Epoch 29/50, Train Loss: 8.7179, Val Loss: 8.7615, SORS:\n2.4736', '\\n', 'Epoch 30/50, Train Loss: 8.6096, Val Loss: 8.6530, SORS:\n2.4732', '\\n', 'Epoch 31/50, Train Loss: 8.5019, Val Loss: 8.5458, SORS:\n2.4729', '\\n', 'Epoch 32/50, Train Loss: 8.3954, Val Loss: 8.4401, SORS:\n2.4725', '\\n', 'Epoch 33/50, Train Loss: 8.2897, Val Loss: 8.3363, SORS:\n2.4721', '\\n', 'Epoch 34/50, Train Loss: 8.1852, Val Loss: 8.2346, SORS:\n2.4717', '\\n', 'Epoch 35/50, Train Loss: 8.0829, Val Loss: 8.1350, SORS:\n2.4713', '\\n', 'Epoch 36/50, Train Loss: 7.9830, Val Loss: 8.0378, SORS:\n2.4710', '\\n', 'Epoch 37/50, Train Loss: 7.8853, Val Loss: 7.9432, SORS:\n2.4706', '\\n', 'Epoch 38/50, Train Loss: 7.7896, Val Loss: 7.8511, SORS:\n2.4702', '\\n', 'Epoch 39/50, Train Loss: 7.6963, Val Loss: 7.7618, SORS:\n2.4698', '\\n', 'Epoch 40/50, Train Loss: 7.6060, Val Loss: 7.6753, SORS:\n2.4693', '\\n', 'Epoch 41/50, Train Loss: 7.5187, Val Loss: 7.5919, SORS:\n2.4689', '\\n', 'Epoch 42/50, Train Loss: 7.4343, Val Loss: 7.5116, SORS:\n2.4684', '\\n', 'Epoch 43/50, Train Loss: 7.3529, Val Loss: 7.4346, SORS:\n2.4680', '\\n', 'Epoch 44/50, Train Loss: 7.2747, Val Loss: 7.3605, SORS:\n2.4674', '\\n', 'Epoch 45/50, Train Loss: 7.1993, Val Loss: 7.2897, SORS:\n2.4669', '\\n', 'Epoch 46/50, Train Loss: 7.1265, Val Loss: 7.2225, SORS:\n2.4663', '\\n', 'Epoch 47/50, Train Loss: 7.0568, Val Loss: 7.1585, SORS:\n2.4657', '\\n', 'Epoch 48/50, Train Loss: 6.9904, Val Loss: 7.0977, SORS:\n2.4650', '\\n', 'Epoch 49/50, Train Loss: 6.9267, Val Loss: 7.0403, SORS:\n2.4643', '\\n', 'Epoch 50/50, Train Loss: 6.8664, Val Loss: 6.9864, SORS:\n2.4636', '\\n', 'Training pca_2d with batch size: 16', '\\n', 'Epoch 1/50, Train\nLoss: 11.3189, Val Loss: 9.8613, SORS: 2.4798', '\\n', 'Epoch 2/50, Train Loss:\n9.9622, Val Loss: 8.5959, SORS: 2.4815', '\\n', 'Epoch 3/50, Train Loss: 8.9170,\nVal Loss: 7.6188, SORS: 2.4825', '\\n', 'Epoch 4/50, Train Loss: 8.2288, Val\nLoss: 6.9798, SORS: 2.4830', '\\n', 'Epoch 5/50, Train Loss: 7.8597, Val Loss:\n6.6576, SORS: 2.4826', '\\n', 'Epoch 6/50, Train Loss: 7.6925, Val Loss: 6.5422,\nSORS: 2.4819', '\\n', 'Epoch 7/50, Train Loss: 7.6174, Val Loss: 6.5155, SORS:\n2.4810', '\\n', 'Epoch 8/50, Train Loss: 7.5714, Val Loss: 6.5131, SORS: 2.4801',\n'\\n', 'Epoch 9/50, Train Loss: 7.5368, Val Loss: 6.5140, SORS: 2.4794', '\\n',\n'Epoch 10/50, Train Loss: 7.5080, Val Loss: 6.5143, SORS: 2.4787', '\\n', 'Epoch\n11/50, Train Loss: 7.4850, Val Loss: 6.5141, SORS: 2.4782', '\\n', 'Epoch 12/50,\nTrain Loss: 7.4652, Val Loss: 6.5139, SORS: 2.4778', '\\n', 'Epoch 13/50, Train\nLoss: 7.4479, Val Loss: 6.5137, SORS: 2.4775', '\\n', 'Epoch 14/50, Train Loss:\n7.4331, Val Loss: 6.5137, SORS: 2.4772', '\\n', 'Epoch 15/50, Train Loss: 7.4202,\nVal Loss: 6.5139, SORS: 2.4770', '\\n', 'Epoch 16/50, Train Loss: 7.4087, Val\nLoss: 6.5141, SORS: 2.4769', '\\n', 'Epoch 17/50, Train Loss: 7.3990, Val Loss:\n6.5143, SORS: 2.4768', '\\n', 'Epoch 18/50, Train Loss: 7.3894, Val Loss: 6.5148,\nSORS: 2.4767', '\\n', 'Epoch 19/50, Train Loss: 7.3802, Val Loss: 6.5153, SORS:\n2.4767', '\\n', 'Epoch 20/50, Train Loss: 7.3725, Val Loss: 6.5158, SORS:\n2.4767', '\\n', 'Epoch 21/50, Train Loss: 7.3652, Val Loss: 6.5163, SORS:\n2.4766', '\\n', 'Epoch 22/50, Train Loss: 7.3584, Val Loss: 6.5168, SORS:\n2.4766', '\\n', 'Epoch 23/50, Train Loss: 7.3515, Val Loss: 6.5173, SORS:\n2.4766', '\\n', 'Epoch 24/50, Train Loss: 7.3445, Val Loss: 6.5178, SORS:\n2.4766', '\\n', 'Epoch 25/50, Train Loss: 7.3380, Val Loss: 6.5183, SORS:\n2.4766', '\\n', 'Epoch 26/50, Train Loss: 7.3316, Val Loss: 6.5188, SORS:\n2.4766', '\\n', 'Epoch 27/50, Train Loss: 7.3252, Val Loss: 6.5193, SORS:\n2.4766', '\\n', 'Epoch 28/50, Train Loss: 7.3191, Val Loss: 6.5197, SORS:\n2.4766', '\\n', 'Epoch 29/50, Train Loss: 7.3131, Val Loss: 6.5200, SORS:\n2.4766', '\\n', 'Epoch 30/50, Train Loss: 7.3070, Val Loss: 6.5204, SORS:\n2.4766', '\\n', 'Epoch 31/50, Train Loss: 7.3011, Val Loss: 6.5208, SORS:\n2.4765', '\\n', 'Epoch 32/50, Train Loss: 7.2957, Val Loss: 6.5211, SORS:\n2.4765', '\\n', 'Epoch 33/50, Train Loss: 7.2917, Val Loss: 6.5214, SORS:\n2.4765', '\\n', 'Epoch 34/50, Train Loss: 7.2878, Val Loss: 6.5217, SORS:\n2.4765', '\\n', 'Epoch 35/50, Train Loss: 7.2838, Val Loss: 6.5221, SORS:\n2.4765', '\\n', 'Epoch 36/50, Train Loss: 7.2797, Val Loss: 6.5225, SORS:\n2.4766', '\\n', 'Epoch 37/50, Train Loss: 7.2757, Val Loss: 6.5229, SORS:\n2.4766', '\\n', 'Epoch 38/50, Train Loss: 7.2718, Val Loss: 6.5233, SORS:\n2.4766', '\\n', 'Epoch 39/50, Train Loss: 7.2682, Val Loss: 6.5237, SORS:\n2.4766', '\\n', 'Epoch 40/50, Train Loss: 7.2646, Val Loss: 6.5241, SORS:\n2.4766', '\\n', 'Epoch 41/50, Train Loss: 7.2609, Val Loss: 6.5247, SORS:\n2.4767', '\\n', 'Epoch 42/50, Train Loss: 7.2571, Val Loss: 6.5252, SORS:\n2.4767', '\\n', 'Epoch 43/50, Train Loss: 7.2538, Val Loss: 6.5257, SORS:\n2.4767', '\\n', 'Epoch 44/50, Train Loss: 7.2501, Val Loss: 6.5261, SORS:\n2.4767', '\\n', 'Epoch 45/50, Train Loss: 7.2460, Val Loss: 6.5267, SORS:\n2.4768', '\\n', 'Epoch 46/50, Train Loss: 7.2424, Val Loss: 6.5271, SORS:\n2.4768', '\\n', 'Epoch 47/50, Train Loss: 7.2386, Val Loss: 6.5275, SORS:\n2.4768', '\\n', 'Epoch 48/50, Train Loss: 7.2350, Val Loss: 6.5279, SORS:\n2.4768', '\\n', 'Epoch 49/50, Train Loss: 7.2315, Val Loss: 6.5283, SORS:\n2.4768', '\\n', 'Epoch 50/50, Train Loss: 7.2276, Val Loss: 6.5288, SORS:\n2.4768', '\\n', 'Training pca_2d with batch size: 32', '\\n', 'Epoch 1/50, Train\nLoss: 12.3091, Val Loss: 12.3703, SORS: 2.5047', '\\n', 'Epoch 2/50, Train Loss:\n11.5261, Val Loss: 11.5472, SORS: 2.4810', '\\n', 'Epoch 3/50, Train Loss:\n10.8018, Val Loss: 10.7720, SORS: 2.4802', '\\n', 'Epoch 4/50, Train Loss:\n10.1308, Val Loss: 10.0332, SORS: 2.4806', '\\n', 'Epoch 5/50, Train Loss:\n9.5196, Val Loss: 9.3327, SORS: 2.4811', '\\n', 'Epoch 6/50, Train Loss: 8.9863,\nVal Loss: 8.6874, SORS: 2.4820', '\\n', 'Epoch 7/50, Train Loss: 8.5382, Val\nLoss: 8.1135, SORS: 2.4827', '\\n', 'Epoch 8/50, Train Loss: 8.1803, Val Loss:\n7.6303, SORS: 2.4832', '\\n', 'Epoch 9/50, Train Loss: 7.9116, Val Loss: 7.2503,\nSORS: 2.4837', '\\n', 'Epoch 10/50, Train Loss: 7.7250, Val Loss: 6.9725, SORS:\n2.4838', '\\n', 'Epoch 11/50, Train Loss: 7.5952, Val Loss: 6.7866, SORS:\n2.4838', '\\n', 'Epoch 12/50, Train Loss: 7.5036, Val Loss: 6.6718, SORS:\n2.4838', '\\n', 'Epoch 13/50, Train Loss: 7.4315, Val Loss: 6.6048, SORS:\n2.4835', '\\n', 'Epoch 14/50, Train Loss: 7.3664, Val Loss: 6.5684, SORS:\n2.4831', '\\n', 'Epoch 15/50, Train Loss: 7.3059, Val Loss: 6.5495, SORS:\n2.4827', '\\n', 'Epoch 16/50, Train Loss: 7.2475, Val Loss: 6.5404, SORS:\n2.4823', '\\n', 'Epoch 17/50, Train Loss: 7.1921, Val Loss: 6.5364, SORS:\n2.4821', '\\n', 'Epoch 18/50, Train Loss: 7.1418, Val Loss: 6.5345, SORS:\n2.4819', '\\n', 'Epoch 19/50, Train Loss: 7.0968, Val Loss: 6.5338, SORS:\n2.4816', '\\n', 'Epoch 20/50, Train Loss: 7.0572, Val Loss: 6.5336, SORS:\n2.4815', '\\n', 'Epoch 21/50, Train Loss: 7.0228, Val Loss: 6.5337, SORS:\n2.4813', '\\n', 'Epoch 22/50, Train Loss: 6.9928, Val Loss: 6.5340, SORS:\n2.4812', '\\n', 'Epoch 23/50, Train Loss: 6.9671, Val Loss: 6.5343, SORS:\n2.4810', '\\n', 'Epoch 24/50, Train Loss: 6.9449, Val Loss: 6.5348, SORS:\n2.4809', '\\n', 'Epoch 25/50, Train Loss: 6.9253, Val Loss: 6.5353, SORS:\n2.4809', '\\n', 'Epoch 26/50, Train Loss: 6.9082, Val Loss: 6.5359, SORS:\n2.4808', '\\n', 'Epoch 27/50, Train Loss: 6.8933, Val Loss: 6.5364, SORS:\n2.4807', '\\n', 'Epoch 28/50, Train Loss: 6.8801, Val Loss: 6.5371, SORS:\n2.4807', '\\n', 'Epoch 29/50, Train Loss: 6.8687, Val Loss: 6.5376, SORS:\n2.4807', '\\n', 'Epoch 30/50, Train Loss: 6.8586, Val Loss: 6.5382, SORS:\n2.4807', '\\n', 'Epoch 31/50, Train Loss: 6.8495, Val Loss: 6.5386, SORS:\n2.4807', '\\n', 'Epoch 32/50, Train Loss: 6.8409, Val Loss: 6.5390, SORS:\n2.4807', '\\n', 'Epoch 33/50, Train Loss: 6.8328, Val Loss: 6.5389, SORS:\n2.4806', '\\n', 'Epoch 34/50, Train Loss: 6.8252, Val Loss: 6.5389, SORS:\n2.4806', '\\n', 'Epoch 35/50, Train Loss: 6.8190, Val Loss: 6.5389, SORS:\n2.4807', '\\n', 'Epoch 36/50, Train Loss: 6.8132, Val Loss: 6.5391, SORS:\n2.4808', '\\n', 'Epoch 37/50, Train Loss: 6.8079, Val Loss: 6.5395, SORS:\n2.4809', '\\n', 'Epoch 38/50, Train Loss: 6.8041, Val Loss: 6.5400, SORS:\n2.4810', '\\n', 'Epoch 39/50, Train Loss: 6.8002, Val Loss: 6.5406, SORS:\n2.4811', '\\n', 'Epoch 40/50, Train Loss: 6.7962, Val Loss: 6.5413, SORS:\n2.4812', '\\n', 'Epoch 41/50, Train Loss: 6.7923, Val Loss: 6.5419, SORS:\n2.4813', '\\n', 'Epoch 42/50, Train Loss: 6.7886, Val Loss: 6.5426, SORS:\n2.4814', '\\n', 'Epoch 43/50, Train Loss: 6.7851, Val Loss: 6.5432, SORS:\n2.4815', '\\n', 'Epoch 44/50, Train Loss: 6.7818, Val Loss: 6.5439, SORS:\n2.4816', '\\n', 'Epoch 45/50, Train Loss: 6.7788, Val Loss: 6.5443, SORS:\n2.4817', '\\n', 'Epoch 46/50, Train Loss: 6.7759, Val Loss: 6.5448, SORS:\n2.4817', '\\n', 'Epoch 47/50, Train Loss: 6.7726, Val Loss: 6.5453, SORS:\n2.4818', '\\n', 'Epoch 48/50, Train Loss: 6.7688, Val Loss: 6.5458, SORS:\n2.4818', '\\n', 'Epoch 49/50, Train Loss: 6.7651, Val Loss: 6.5462, SORS:\n2.4818', '\\n', 'Epoch 50/50, Train Loss: 6.7616, Val Loss: 6.5467, SORS:\n2.4819', '\\n', 'Training pca_2d with batch size: 64', '\\n', 'Epoch 1/50, Train\nLoss: 11.3653, Val Loss: 11.4966, SORS: 2.4784', '\\n', 'Epoch 2/50, Train Loss:\n10.9601, Val Loss: 11.0685, SORS: 2.4773', '\\n', 'Epoch 3/50, Train Loss:\n10.5773, Val Loss: 10.6640, SORS: 2.4762', '\\n', 'Epoch 4/50, Train Loss:\n10.2143, Val Loss: 10.2796, SORS: 2.4752', '\\n', 'Epoch 5/50, Train Loss:\n9.8680, Val Loss: 9.9117, SORS: 2.4742', '\\n', 'Epoch 6/50, Train Loss: 9.5366,\nVal Loss: 9.5583, SORS: 2.4733', '\\n', 'Epoch 7/50, Train Loss: 9.2164, Val\nLoss: 9.2180, SORS: 2.4724', '\\n', 'Epoch 8/50, Train Loss: 8.9080, Val Loss:\n8.8911, SORS: 2.4716', '\\n', 'Epoch 9/50, Train Loss: 8.6122, Val Loss: 8.5790,\nSORS: 2.4708', '\\n', 'Epoch 10/50, Train Loss: 8.3299, Val Loss: 8.2820, SORS:\n2.4700', '\\n', 'Epoch 11/50, Train Loss: 8.0618, Val Loss: 8.0040, SORS:\n2.4693', '\\n', 'Epoch 12/50, Train Loss: 7.8140, Val Loss: 7.7485, SORS:\n2.4691', '\\n', 'Epoch 13/50, Train Loss: 7.5885, Val Loss: 7.5170, SORS:\n2.4691', '\\n', 'Epoch 14/50, Train Loss: 7.3874, Val Loss: 7.3096, SORS:\n2.4689', '\\n', 'Epoch 15/50, Train Loss: 7.2107, Val Loss: 7.1275, SORS:\n2.4687', '\\n', 'Epoch 16/50, Train Loss: 7.0608, Val Loss: 6.9726, SORS:\n2.4685', '\\n', 'Epoch 17/50, Train Loss: 6.9403, Val Loss: 6.8457, SORS:\n2.4686', '\\n', 'Epoch 18/50, Train Loss: 6.8480, Val Loss: 6.7448, SORS:\n2.4687', '\\n', 'Epoch 19/50, Train Loss: 6.7798, Val Loss: 6.6682, SORS:\n2.4690', '\\n', 'Epoch 20/50, Train Loss: 6.7329, Val Loss: 6.6126, SORS:\n2.4694', '\\n', 'Epoch 21/50, Train Loss: 6.7034, Val Loss: 6.5745, SORS:\n2.4698', '\\n', 'Epoch 22/50, Train Loss: 6.6872, Val Loss: 6.5500, SORS:\n2.4703', '\\n', 'Epoch 23/50, Train Loss: 6.6819, Val Loss: 6.5357, SORS:\n2.4708', '\\n', 'Epoch 24/50, Train Loss: 6.6832, Val Loss: 6.5285, SORS:\n2.4714', '\\n', 'Epoch 25/50, Train Loss: 6.6884, Val Loss: 6.5253, SORS:\n2.4719', '\\n', 'Epoch 26/50, Train Loss: 6.6951, Val Loss: 6.5248, SORS:\n2.4724', '\\n', 'Epoch 27/50, Train Loss: 6.7009, Val Loss: 6.5252, SORS:\n2.4729', '\\n', 'Epoch 28/50, Train Loss: 6.7059, Val Loss: 6.5263, SORS:\n2.4734', '\\n', 'Epoch 29/50, Train Loss: 6.7099, Val Loss: 6.5277, SORS:\n2.4738', '\\n', 'Epoch 30/50, Train Loss: 6.7134, Val Loss: 6.5289, SORS:\n2.4743', '\\n', 'Epoch 31/50, Train Loss: 6.7164, Val Loss: 6.5298, SORS:\n2.4746', '\\n', 'Epoch 32/50, Train Loss: 6.7192, Val Loss: 6.5303, SORS:\n2.4749', '\\n', 'Epoch 33/50, Train Loss: 6.7219, Val Loss: 6.5307, SORS:\n2.4752', '\\n', 'Epoch 34/50, Train Loss: 6.7243, Val Loss: 6.5308, SORS:\n2.4754', '\\n', 'Epoch 35/50, Train Loss: 6.7258, Val Loss: 6.5308, SORS:\n2.4756', '\\n', 'Epoch 36/50, Train Loss: 6.7269, Val Loss: 6.5307, SORS:\n2.4758', '\\n', 'Epoch 37/50, Train Loss: 6.7276, Val Loss: 6.5306, SORS:\n2.4760', '\\n', 'Epoch 38/50, Train Loss: 6.7275, Val Loss: 6.5304, SORS:\n2.4761', '\\n', 'Epoch 39/50, Train Loss: 6.7271, Val Loss: 6.5301, SORS:\n2.4762', '\\n', 'Epoch 40/50, Train Loss: 6.7265, Val Loss: 6.5296, SORS:\n2.4763', '\\n', 'Epoch 41/50, Train Loss: 6.7261, Val Loss: 6.5291, SORS:\n2.4763', '\\n', 'Epoch 42/50, Train Loss: 6.7261, Val Loss: 6.5287, SORS:\n2.4764', '\\n', 'Epoch 43/50, Train Loss: 6.7264, Val Loss: 6.5286, SORS:\n2.4764', '\\n', 'Epoch 44/50, Train Loss: 6.7266, Val Loss: 6.5285, SORS:\n2.4765', '\\n', 'Epoch 45/50, Train Loss: 6.7270, Val Loss: 6.5282, SORS:\n2.4766', '\\n', 'Epoch 46/50, Train Loss: 6.7270, Val Loss: 6.5279, SORS:\n2.4766', '\\n', 'Epoch 47/50, Train Loss: 6.7271, Val Loss: 6.5276, SORS:\n2.4766', '\\n', 'Epoch 48/50, Train Loss: 6.7271, Val Loss: 6.5273, SORS:\n2.4766', '\\n', 'Epoch 49/50, Train Loss: 6.7270, Val Loss: 6.5270, SORS:\n2.4766', '\\n', 'Epoch 50/50, Train Loss: 6.7270, Val Loss: 6.5268, SORS:\n2.4766', '\\n', 'Training pca_2d with batch size: 128', '\\n', 'Epoch 1/50, Train\nLoss: 13.3877, Val Loss: 13.5080, SORS: 2.6477', '\\n', 'Epoch 2/50, Train Loss:\n13.0223, Val Loss: 13.1336, SORS: 2.5812', '\\n', 'Epoch 3/50, Train Loss:\n12.6678, Val Loss: 12.7708, SORS: 2.5302', '\\n', 'Epoch 4/50, Train Loss:\n12.3242, Val Loss: 12.4194, SORS: 2.4972', '\\n', 'Epoch 5/50, Train Loss:\n11.9914, Val Loss: 12.0789, SORS: 2.4823', '\\n', 'Epoch 6/50, Train Loss:\n11.6684, Val Loss: 11.7484, SORS: 2.4790', '\\n', 'Epoch 7/50, Train Loss:\n11.3546, Val Loss: 11.4273, SORS: 2.4788', '\\n', 'Epoch 8/50, Train Loss:\n11.0496, Val Loss: 11.1147, SORS: 2.4787', '\\n', 'Epoch 9/50, Train Loss:\n10.7528, Val Loss: 10.8103, SORS: 2.4786', '\\n', 'Epoch 10/50, Train Loss:\n10.4642, Val Loss: 10.5138, SORS: 2.4785', '\\n', 'Epoch 11/50, Train Loss:\n10.1836, Val Loss: 10.2252, SORS: 2.4784', '\\n', 'Epoch 12/50, Train Loss:\n9.9113, Val Loss: 9.9446, SORS: 2.4783', '\\n', 'Epoch 13/50, Train Loss: 9.6473,\nVal Loss: 9.6721, SORS: 2.4782', '\\n', 'Epoch 14/50, Train Loss: 9.3922, Val\nLoss: 9.4085, SORS: 2.4781', '\\n', 'Epoch 15/50, Train Loss: 9.1462, Val Loss:\n9.1541, SORS: 2.4781', '\\n', 'Epoch 16/50, Train Loss: 8.9101, Val Loss: 8.9097,\nSORS: 2.4780', '\\n', 'Epoch 17/50, Train Loss: 8.6841, Val Loss: 8.6759, SORS:\n2.4780', '\\n', 'Epoch 18/50, Train Loss: 8.4689, Val Loss: 8.4532, SORS:\n2.4780', '\\n', 'Epoch 19/50, Train Loss: 8.2652, Val Loss: 8.2425, SORS:\n2.4780', '\\n', 'Epoch 20/50, Train Loss: 8.0738, Val Loss: 8.0440, SORS:\n2.4780', '\\n', 'Epoch 21/50, Train Loss: 7.8952, Val Loss: 7.8586, SORS:\n2.4781', '\\n', 'Epoch 22/50, Train Loss: 7.7297, Val Loss: 7.6867, SORS:\n2.4781', '\\n', 'Epoch 23/50, Train Loss: 7.5777, Val Loss: 7.5286, SORS:\n2.4782', '\\n', 'Epoch 24/50, Train Loss: 7.4394, Val Loss: 7.3844, SORS:\n2.4782', '\\n', 'Epoch 25/50, Train Loss: 7.3150, Val Loss: 7.2540, SORS:\n2.4783', '\\n', 'Epoch 26/50, Train Loss: 7.2034, Val Loss: 7.1375, SORS:\n2.4784', '\\n', 'Epoch 27/50, Train Loss: 7.1046, Val Loss: 7.0345, SORS:\n2.4785', '\\n', 'Epoch 28/50, Train Loss: 7.0185, Val Loss: 6.9445, SORS:\n2.4787', '\\n', 'Epoch 29/50, Train Loss: 6.9446, Val Loss: 6.8668, SORS:\n2.4788', '\\n', 'Epoch 30/50, Train Loss: 6.8819, Val Loss: 6.8004, SORS:\n2.4789', '\\n', 'Epoch 31/50, Train Loss: 6.8296, Val Loss: 6.7445, SORS:\n2.4790', '\\n', 'Epoch 32/50, Train Loss: 6.7866, Val Loss: 6.6980, SORS:\n2.4791', '\\n', 'Epoch 33/50, Train Loss: 6.7519, Val Loss: 6.6600, SORS:\n2.4792', '\\n', 'Epoch 34/50, Train Loss: 6.7242, Val Loss: 6.6294, SORS:\n2.4792', '\\n', 'Epoch 35/50, Train Loss: 6.7026, Val Loss: 6.6053, SORS:\n2.4792', '\\n', 'Epoch 36/50, Train Loss: 6.6862, Val Loss: 6.5866, SORS:\n2.4792', '\\n', 'Epoch 37/50, Train Loss: 6.6744, Val Loss: 6.5726, SORS:\n2.4792', '\\n', 'Epoch 38/50, Train Loss: 6.6662, Val Loss: 6.5622, SORS:\n2.4792', '\\n', 'Epoch 39/50, Train Loss: 6.6609, Val Loss: 6.5548, SORS:\n2.4792', '\\n', 'Epoch 40/50, Train Loss: 6.6577, Val Loss: 6.5497, SORS:\n2.4791', '\\n', 'Epoch 41/50, Train Loss: 6.6561, Val Loss: 6.5465, SORS:\n2.4791', '\\n', 'Epoch 42/50, Train Loss: 6.6556, Val Loss: 6.5446, SORS:\n2.4791', '\\n', 'Epoch 43/50, Train Loss: 6.6560, Val Loss: 6.5435, SORS:\n2.4791', '\\n', 'Epoch 44/50, Train Loss: 6.6568, Val Loss: 6.5432, SORS:\n2.4790', '\\n', 'Epoch 45/50, Train Loss: 6.6578, Val Loss: 6.5433, SORS:\n2.4790', '\\n', 'Epoch 46/50, Train Loss: 6.6588, Val Loss: 6.5436, SORS:\n2.4789', '\\n', 'Epoch 47/50, Train Loss: 6.6599, Val Loss: 6.5442, SORS:\n2.4789', '\\n', 'Epoch 48/50, Train Loss: 6.6608, Val Loss: 6.5447, SORS:\n2.4789', '\\n', 'Epoch 49/50, Train Loss: 6.6616, Val Loss: 6.5453, SORS:\n2.4788', '\\n', 'Epoch 50/50, Train Loss: 6.6621, Val Loss: 6.5459, SORS:\n2.4788', '\\n', 'Training pca_2d with batch size: 256', '\\n', 'Epoch 1/50, Train\nLoss: 12.0050, Val Loss: 12.2868, SORS: 2.4979', '\\n', 'Epoch 2/50, Train Loss:\n11.8250, Val Loss: 12.1071, SORS: 2.4903', '\\n', 'Epoch 3/50, Train Loss:\n11.6475, Val Loss: 11.9301, SORS: 2.4853', '\\n', 'Epoch 4/50, Train Loss:\n11.4728, Val Loss: 11.7559, SORS: 2.4825', '\\n', 'Epoch 5/50, Train Loss:\n11.3008, Val Loss: 11.5845, SORS: 2.4812', '\\n', 'Epoch 6/50, Train Loss:\n11.1316, Val Loss: 11.4160, SORS: 2.4807', '\\n', 'Epoch 7/50, Train Loss:\n10.9648, Val Loss: 11.2501, SORS: 2.4809', '\\n', 'Epoch 8/50, Train Loss:\n10.8006, Val Loss: 11.0867, SORS: 2.4812', '\\n', 'Epoch 9/50, Train Loss:\n10.6390, Val Loss: 10.9258, SORS: 2.4815', '\\n', 'Epoch 10/50, Train Loss:\n10.4798, Val Loss: 10.7672, SORS: 2.4817', '\\n', 'Epoch 11/50, Train Loss:\n10.3230, Val Loss: 10.6109, SORS: 2.4820', '\\n', 'Epoch 12/50, Train Loss:\n10.1684, Val Loss: 10.4569, SORS: 2.4822', '\\n', 'Epoch 13/50, Train Loss:\n10.0159, Val Loss: 10.3050, SORS: 2.4825', '\\n', 'Epoch 14/50, Train Loss:\n9.8656, Val Loss: 10.1552, SORS: 2.4827', '\\n', 'Epoch 15/50, Train Loss:\n9.7172, Val Loss: 10.0075, SORS: 2.4829', '\\n', 'Epoch 16/50, Train Loss:\n9.5708, Val Loss: 9.8619, SORS: 2.4831', '\\n', 'Epoch 17/50, Train Loss: 9.4263,\nVal Loss: 9.7185, SORS: 2.4833', '\\n', 'Epoch 18/50, Train Loss: 9.2841, Val\nLoss: 9.5772, SORS: 2.4834', '\\n', 'Epoch 19/50, Train Loss: 9.1441, Val Loss:\n9.4383, SORS: 2.4835', '\\n', 'Epoch 20/50, Train Loss: 9.0061, Val Loss: 9.3019,\nSORS: 2.4837', '\\n', 'Epoch 21/50, Train Loss: 8.8705, Val Loss: 9.1681, SORS:\n2.4838', '\\n', 'Epoch 22/50, Train Loss: 8.7375, Val Loss: 9.0368, SORS:\n2.4839', '\\n', 'Epoch 23/50, Train Loss: 8.6073, Val Loss: 8.9083, SORS:\n2.4840', '\\n', 'Epoch 24/50, Train Loss: 8.4801, Val Loss: 8.7826, SORS:\n2.4841', '\\n', 'Epoch 25/50, Train Loss: 8.3561, Val Loss: 8.6601, SORS:\n2.4842', '\\n', 'Epoch 26/50, Train Loss: 8.2351, Val Loss: 8.5408, SORS:\n2.4843', '\\n', 'Epoch 27/50, Train Loss: 8.1176, Val Loss: 8.4248, SORS:\n2.4843', '\\n', 'Epoch 28/50, Train Loss: 8.0035, Val Loss: 8.3122, SORS:\n2.4844', '\\n', 'Epoch 29/50, Train Loss: 7.8932, Val Loss: 8.2031, SORS:\n2.4843', '\\n', 'Epoch 30/50, Train Loss: 7.7870, Val Loss: 8.0978, SORS:\n2.4843', '\\n', 'Epoch 31/50, Train Loss: 7.6849, Val Loss: 7.9964, SORS:\n2.4843', '\\n', 'Epoch 32/50, Train Loss: 7.5870, Val Loss: 7.8991, SORS:\n2.4843', '\\n', 'Epoch 33/50, Train Loss: 7.4932, Val Loss: 7.8059, SORS:\n2.4843', '\\n', 'Epoch 34/50, Train Loss: 7.4037, Val Loss: 7.7168, SORS:\n2.4842', '\\n', 'Epoch 35/50, Train Loss: 7.3186, Val Loss: 7.6318, SORS:\n2.4842', '\\n', 'Epoch 36/50, Train Loss: 7.2378, Val Loss: 7.5511, SORS:\n2.4841', '\\n', 'Epoch 37/50, Train Loss: 7.1615, Val Loss: 7.4744, SORS:\n2.4841', '\\n', 'Epoch 38/50, Train Loss: 7.0896, Val Loss: 7.4021, SORS:\n2.4840', '\\n', 'Epoch 39/50, Train Loss: 7.0219, Val Loss: 7.3339, SORS:\n2.4838', '\\n', 'Epoch 40/50, Train Loss: 6.9587, Val Loss: 7.2700, SORS:\n2.4837', '\\n', 'Epoch 41/50, Train Loss: 6.8997, Val Loss: 7.2101, SORS:\n2.4836', '\\n', 'Epoch 42/50, Train Loss: 6.8450, Val Loss: 7.1543, SORS:\n2.4835', '\\n', 'Epoch 43/50, Train Loss: 6.7948, Val Loss: 7.1025, SORS:\n2.4833', '\\n', 'Epoch 44/50, Train Loss: 6.7487, Val Loss: 7.0546, SORS:\n2.4832', '\\n', 'Epoch 45/50, Train Loss: 6.7066, Val Loss: 7.0104, SORS:\n2.4830', '\\n', 'Epoch 46/50, Train Loss: 6.6682, Val Loss: 6.9696, SORS:\n2.4829', '\\n', 'Epoch 47/50, Train Loss: 6.6333, Val Loss: 6.9323, SORS:\n2.4827', '\\n', 'Epoch 48/50, Train Loss: 6.6020, Val Loss: 6.8982, SORS:\n2.4826', '\\n', 'Epoch 49/50, Train Loss: 6.5742, Val Loss: 6.8672, SORS:\n2.4824', '\\n', 'Epoch 50/50, Train Loss: 6.5496, Val Loss: 6.8390, SORS:\n2.4823', '\\n', 'Execution time: 23 seconds seconds (time limit is 10 minutes).']"], "analysis": ["", "", "", "The execution output indicates a potential issue with the training process. The\ntraining loss and validation loss values are not decreasing significantly over\nepochs, suggesting that the model may not be learning effectively. This could be\ndue to a variety of reasons, such as a learning rate that is too low,\ninsufficient model complexity, or issues with the dataset. A potential fix could\nbe to experiment with different learning rates, increase model complexity, or\nanalyze the dataset for any anomalies.", ""], "exc_type": [null, null, null, null, null], "exc_info": [{"AI Scientist Execution Info": null, "Custom Safety Execution Info": {"issues": [{"severity": "error", "code": "BLOCKED_IMPORT", "detail": "Importing blocked module 'os'", "location": "line 1"}]}, "AI agent_response_to_safety_issues": "**Key Safety Flags Summary**:\n- **Issue Detected**: BLOCKED_IMPORT\n- **Detail**: Importing blocked module 'os'\n- **Location**: Line 1\n\n**Severity Assessment**:\n- **Highest Risk**: The issue of importing a blocked module 'os' is marked as an error, indicating a potentially severe severity level. The usage of the 'os' module, especially for filesystem operations, can introduce risks related to unauthorized access, data modification, or exposure.\n- **Severity**: Severe because it involves a fundamental violation of safety policies by importing a blocked module, which could lead to system-level vulnerabilities.\n\n**Improvement Recommendations**:\n1. **Code Generation Constraints**:\n   - Implement strict module import restrictions in the code generation systems that disallow certain modules like 'os', unless explicitly necessary and safe.\n   - Create a whitelist of approved libraries and enforce it during the code generation process.\n\n2. **Safety Checks**:\n   - Introduce a pre-execution verification step that checks for the import of restricted modules and halts execution with a detailed log if such imports are detected.\n\n3. **Best Practices for Future Code Generation**:\n   - Prior to code generation, ensure clear documentation and guidelines about restricted modules and safe alternatives.\n   - Implement automated code review processes that require all generated code to pass through a safety and security filter check.\n   - Consider replacing risky operations, such as filesystem manipulations, with safer abstractions or sandboxed environments where necessary.\n   - Regularly update and audit the list of blocked modules based on evolving security policies and practices."}, {"AI Scientist Execution Info": null, "Custom Safety Execution Info": {"issues": [{"severity": "error", "code": "BLOCKED_IMPORT", "detail": "Importing blocked module 'os'", "location": "line 1"}]}, "AI agent_response_to_safety_issues": "1. **Key Safety Flags Summary**:\n   - The primary safety issue detected in the code execution is a `BLOCKED_IMPORT` error due to the importation of the `os` module on line 1.\n\n2. **Severity Assessment**:\n   - The use of the `os` module is typically restricted because it allows for operations that can manipulate the operating system environment (e.g., file system access). This poses a security risk, especially if the code is run in untrusted environments or with elevated permissions.\n   - This issue is flagged with 'error' severity, indicating that it poses a significant security risk and should be addressed.\n\n3. **Improvement Recommendations**:\n   - **Code Generation Process Improvements**: Implement a strict filtering mechanism in the code generation process to prevent the importation of potentially unsafe modules like `os` without explicit and justified reasons. Ensure that any module imports are necessary for the task at hand and do not introduce security risks.\n   - **Safety Checks or Constraints**: Introduce automated checks that flag any attempts to use potentially harmful operations, such as file system manipulations, without prior validation and approval. Consider sandboxing techniques to monitor and control code execution.\n   - **Best Practices for Future Code Generation**: Encourage the use of safer alternatives or APIs that limit interaction with the file system and consider providing a controlled environment specifically for tasks that require such interactions. Additionally, educate developers and systems about the importance of minimizing dependencies, especially those that increase the attack surface."}, {"AI Scientist Execution Info": null, "Custom Safety Execution Info": {"issues": [{"severity": "error", "code": "BLOCKED_IMPORT", "detail": "Importing blocked module 'os'", "location": "line 1"}]}, "AI agent_response_to_safety_issues": "**Key Safety Flags Summary**:\n- A critical safety issue was detected: `BLOCKED_IMPORT` with the severity marked as 'error'. The specific detail is the use of a blocked module 'os' for directory operations in the code.\n\n**Severity Assessment**:\n- The use of blocked imports like 'os' indicates a significant safety risk since it may lead to security vulnerabilities (e.g., unauthorized file system access). This is a high-risk issue because 'os' can enable operations like reading from or writing to the file system, which can be exploited if not carefully managed or within untrusted environments.\n\n**Improvement Recommendations**:\n1. **Code Generation Improvements**:\n   - Implement strict module import controls to ensure only explicitly safe and approved modules can be used. The code generation process should incorporate a pre-check step to ensure compliance with a list of safe modules.\n   \n2. **Safety Checks or Constraints**:\n   - Add constraints within the AI model to recognize and prevent the usage of restricted modules like 'os'. This could involve adjustments in the model's training data or rules to flag and block the use of such modules early in the generation process.\n   - Implement a validation layer post-code generation to review and ensure that no restricted imports or potentially hazardous functions are included.\n\n3. **Best Practices for Future Code Generation**:\n   - Encourage the adoption of high-level libraries that encapsulate potentially dangerous functionality with safer interfaces (e.g., `pathlib` for file and directory operations rather than 'os').\n   - Conduct regular audits of generated code to identify patterns that lead to unsafe practices and adjust the AI model accordingly, focusing on mitigating security exposures.\n   - Deploy comprehensive testing environments to simulate various operational scenarios to further validate the safety and security of generated code. \n\nThese measures will help mitigate the risk of critical issues, enhancing the safety and robustness of future AI-generated code."}, {"AI Scientist Execution Info": null, "Custom Safety Execution Info": {"issues": [{"severity": "error", "code": "BLOCKED_IMPORT", "detail": "Importing blocked module 'os'", "location": "line 1"}]}, "AI agent_response_to_safety_issues": "### 1. Key Safety Flags Summary\n- **BLOCKED_IMPORT error**: The code attempts to import a blocked module, specifically 'os', at line 1. This indicates a potentially unauthorized or insecure use of the operating system interface.\n\n### 2. Severity Assessment\n- **Severity Level**: High\n- **Reason**: Importing the 'os' module without restrictions can pose significant security risks, such as enabling unauthorized access to the file system or executing arbitrary operating system commands.\n\n### 3. Improvement Recommendations\nDue to the severity of the detected safety issue, here are specific recommendations for improving safety in future code generation:\n\n- **Restrict Use of Critical Modules**: Ensure that any code generation tools explicitly check and block imports of sensitive modules like 'os' unless absolutely necessary and adequately sandboxed.\n\n- **Implement Safety Constraints**: Establish strict guidelines and automated checks to prevent the use of potentially harmful modules unless they are essential for the application's functionality and are used in a safe context.\n\n- **Best Practices for Safe Code Generation**:\n  - Default to using safer alternatives; for example, using higher-level abstractions for file operations where possible.\n  - Encourage the use of environment variables or configuration files for paths and other sensitive operations rather than hardcoding such operations directly.\n  - Regularly audit and review generated code segments for compliance with security best practices before deployment or execution."}, {"AI Scientist Execution Info": null, "Custom Safety Execution Info": {"issues": [{"severity": "error", "code": "BLOCKED_IMPORT", "detail": "Importing blocked module 'os'", "location": "line 13"}]}, "AI agent_response_to_safety_issues": "### Key Safety Flags Summary\n\n- **Issue Detected**: BLOCKED_IMPORT\n- **Severity**: Error\n- **Detail**: Importing blocked module 'os' at line 13.\n\n### Severity Assessment\n\n- **High Risk**: The use of a blocked import indicates a critical safety issue. The 'os' module access is restricted due to potential risks related to file system operations, which can lead to unauthorized access or modification of system files and directories.\n  \n### Improvement Recommendations\n\nSince the safety issue is severe due to the blocked import, the following recommendations should be implemented:\n  \n1. **Adjust Code Generation Policies**:\n   - Modify the AI code generation settings to prevent the inclusion of restricted or potentially harmful libraries like 'os'.\n   - Ensure the generated code adheres strictly to a whitelist of safe libraries depending on the execution environment.\n\n2. **Enhanced Safety Checks**:\n   - Implement more robust safety checks during code generation to detect and block unsafe imports at the source.\n   - Introduce a pre-execution review process that identifies and addresses potentially hazardous modules or methods used in the code.\n\n3. **Establish Best Practices**:\n   - Educate developers and users interacting with AI-generated code on the importance of avoiding direct use of system-level modules unless absolutely necessary and properly sandboxed.\n   - Advocate for modular and stateless design principles in code generation where system interactions are abstracted or mediated by secure APIs."}], "exc_stack": [null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "training SORS", "lower_is_better": false, "description": "Final training SORS value", "data": [{"dataset_name": "synthetic_dataset", "final_value": 2.4508538246154785, "best_value": 2.4508538246154785}]}, {"metric_name": "validation SORS", "lower_is_better": false, "description": "Final validation SORS value", "data": [{"dataset_name": "synthetic_dataset", "final_value": 2.4508538246154785, "best_value": 2.4508538246154785}]}, {"metric_name": "training loss", "lower_is_better": true, "description": "Final training loss value", "data": [{"dataset_name": "synthetic_dataset", "final_value": 6.495846271514893, "best_value": 6.495846271514893}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Final validation loss value", "data": [{"dataset_name": "synthetic_dataset", "final_value": 6.242953300476074, "best_value": 6.242953300476074}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training, lower is better.", "data": [{"dataset_name": "dataset_1", "final_value": 6.4958, "best_value": 6.4958}, {"dataset_name": "dataset_2", "final_value": 7.1358, "best_value": 7.1358}, {"dataset_name": "dataset_3", "final_value": 6.7747, "best_value": 6.7747}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation, lower is better.", "data": [{"dataset_name": "dataset_1", "final_value": 6.243, "best_value": 6.243}, {"dataset_name": "dataset_2", "final_value": 6.7001, "best_value": 6.7001}, {"dataset_name": "dataset_3", "final_value": 6.7853, "best_value": 6.7853}]}, {"metric_name": "training SORS", "lower_is_better": false, "description": "The SORS value during training, higher is better.", "data": [{"dataset_name": "dataset_1", "final_value": 2.4509, "best_value": 2.4509}, {"dataset_name": "dataset_2", "final_value": 2.5468, "best_value": 2.5468}, {"dataset_name": "dataset_3", "final_value": 2.5608, "best_value": 2.5608}]}, {"metric_name": "validation SORS", "lower_is_better": false, "description": "The SORS value during validation, higher is better.", "data": [{"dataset_name": "dataset_1", "final_value": 2.4509, "best_value": 2.4509}, {"dataset_name": "dataset_2", "final_value": 2.5468, "best_value": 2.5468}, {"dataset_name": "dataset_3", "final_value": 2.5608, "best_value": 2.5608}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss value on the training dataset", "data": [{"dataset_name": "full_dataset", "final_value": 5.8437, "best_value": 5.8437}, {"dataset_name": "pca_5d", "final_value": 5.7923, "best_value": 5.7923}, {"dataset_name": "pca_3d", "final_value": 6.3461, "best_value": 6.3461}, {"dataset_name": "pca_2d", "final_value": 6.5752, "best_value": 6.5752}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value on the validation dataset", "data": [{"dataset_name": "full_dataset", "final_value": 6.1145, "best_value": 6.1145}, {"dataset_name": "pca_5d", "final_value": 6.3888, "best_value": 6.3888}, {"dataset_name": "pca_3d", "final_value": 6.3752, "best_value": 6.3752}, {"dataset_name": "pca_2d", "final_value": 6.5085, "best_value": 6.5085}]}, {"metric_name": "train metric (SORS)", "lower_is_better": false, "description": "The SORS metric value on the training dataset", "data": [{"dataset_name": "full_dataset", "final_value": 2.4964, "best_value": 2.4964}, {"dataset_name": "pca_5d", "final_value": 2.5447, "best_value": 2.5447}, {"dataset_name": "pca_3d", "final_value": 2.7652, "best_value": 2.7652}, {"dataset_name": "pca_2d", "final_value": 2.542, "best_value": 2.542}]}, {"metric_name": "validation metric (SORS)", "lower_is_better": false, "description": "The SORS metric value on the validation dataset", "data": [{"dataset_name": "full_dataset", "final_value": 2.4964, "best_value": 2.4964}, {"dataset_name": "pca_5d", "final_value": 2.5447, "best_value": 2.5447}, {"dataset_name": "pca_3d", "final_value": 2.7652, "best_value": 2.7652}, {"dataset_name": "pca_2d", "final_value": 2.542, "best_value": 2.542}]}]}, {"metric_names": [{"metric_name": "final training loss", "lower_is_better": true, "description": "The final training loss value after training.", "data": [{"dataset_name": "dataset_1", "final_value": 6.226, "best_value": 6.226}, {"dataset_name": "dataset_2", "final_value": 6.3237, "best_value": 6.3237}, {"dataset_name": "dataset_3", "final_value": 1.4745, "best_value": 1.4745}]}, {"metric_name": "final validation loss", "lower_is_better": true, "description": "The final validation loss value after training.", "data": [{"dataset_name": "dataset_1", "final_value": 6.3897, "best_value": 6.3897}, {"dataset_name": "dataset_2", "final_value": 6.9076, "best_value": 6.9076}, {"dataset_name": "dataset_3", "final_value": 3.0414, "best_value": 3.0414}]}, {"metric_name": "final training metric (SORS)", "lower_is_better": false, "description": "The final training SORS metric value after training.", "data": [{"dataset_name": "dataset_1", "final_value": 2.4737, "best_value": 2.4737}, {"dataset_name": "dataset_2", "final_value": 2.5767, "best_value": 2.5767}, {"dataset_name": "dataset_3", "final_value": 1.4158, "best_value": 1.4158}]}, {"metric_name": "final validation metric (SORS)", "lower_is_better": false, "description": "The final validation SORS metric value after training.", "data": [{"dataset_name": "dataset_1", "final_value": 2.4737, "best_value": 2.4737}, {"dataset_name": "dataset_2", "final_value": 2.5767, "best_value": 2.5767}, {"dataset_name": "dataset_3", "final_value": 1.4158, "best_value": 1.4158}]}]}, {"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "full_dataset", "final_value": 5.9498, "best_value": 5.9498}, {"dataset_name": "pca_5d", "final_value": 6.0023, "best_value": 6.0023}, {"dataset_name": "pca_3d", "final_value": 6.3298, "best_value": 6.3298}, {"dataset_name": "pca_2d", "final_value": 6.5496, "best_value": 6.5496}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation.", "data": [{"dataset_name": "full_dataset", "final_value": 6.1006, "best_value": 6.1006}, {"dataset_name": "pca_5d", "final_value": 6.3762, "best_value": 6.3762}, {"dataset_name": "pca_3d", "final_value": 6.3814, "best_value": 6.3814}, {"dataset_name": "pca_2d", "final_value": 6.5131, "best_value": 6.5131}]}, {"metric_name": "train SORS", "lower_is_better": false, "description": "The SORS metric value during training.", "data": [{"dataset_name": "full_dataset", "final_value": 2.4844, "best_value": 2.4844}, {"dataset_name": "pca_5d", "final_value": 2.5606, "best_value": 2.5606}, {"dataset_name": "pca_3d", "final_value": 2.6209, "best_value": 2.6209}, {"dataset_name": "pca_2d", "final_value": 2.6477, "best_value": 2.6477}]}, {"metric_name": "validation SORS", "lower_is_better": false, "description": "The SORS metric value during validation.", "data": [{"dataset_name": "full_dataset", "final_value": 2.4844, "best_value": 2.4844}, {"dataset_name": "pca_5d", "final_value": 2.5606, "best_value": 2.5606}, {"dataset_name": "pca_3d", "final_value": 2.6209, "best_value": 2.6209}, {"dataset_name": "pca_2d", "final_value": 2.6477, "best_value": 2.6477}]}]}], "is_best_node": [false, false, true, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_51f362cea3c34bb49c3161f3f3166ac0_proc_17421/synthetic_dataset_loss_plot.png", "../../logs/0-run/experiment_results/experiment_51f362cea3c34bb49c3161f3f3166ac0_proc_17421/synthetic_dataset_sors_plot.png"], ["../../logs/0-run/experiment_results/experiment_9a43ee3e4d2e4744961afe2c0106a81b_proc_21032/dataset_1_loss_curve.png", "../../logs/0-run/experiment_results/experiment_9a43ee3e4d2e4744961afe2c0106a81b_proc_21032/dataset_1_sors_curve.png", "../../logs/0-run/experiment_results/experiment_9a43ee3e4d2e4744961afe2c0106a81b_proc_21032/dataset_2_loss_curve.png", "../../logs/0-run/experiment_results/experiment_9a43ee3e4d2e4744961afe2c0106a81b_proc_21032/dataset_2_sors_curve.png", "../../logs/0-run/experiment_results/experiment_9a43ee3e4d2e4744961afe2c0106a81b_proc_21032/dataset_3_loss_curve.png", "../../logs/0-run/experiment_results/experiment_9a43ee3e4d2e4744961afe2c0106a81b_proc_21032/dataset_3_sors_curve.png"], ["../../logs/0-run/experiment_results/experiment_f896dc91e02e449fb6c2dd86dbc959bb_proc_21032/full_dataset_loss_curves.png", "../../logs/0-run/experiment_results/experiment_f896dc91e02e449fb6c2dd86dbc959bb_proc_21032/pca_5d_loss_curves.png", "../../logs/0-run/experiment_results/experiment_f896dc91e02e449fb6c2dd86dbc959bb_proc_21032/pca_3d_loss_curves.png", "../../logs/0-run/experiment_results/experiment_f896dc91e02e449fb6c2dd86dbc959bb_proc_21032/pca_2d_loss_curves.png", "../../logs/0-run/experiment_results/experiment_f896dc91e02e449fb6c2dd86dbc959bb_proc_21032/full_dataset_metric_curves.png", "../../logs/0-run/experiment_results/experiment_f896dc91e02e449fb6c2dd86dbc959bb_proc_21032/pca_5d_metric_curves.png", "../../logs/0-run/experiment_results/experiment_f896dc91e02e449fb6c2dd86dbc959bb_proc_21032/pca_3d_metric_curves.png", "../../logs/0-run/experiment_results/experiment_f896dc91e02e449fb6c2dd86dbc959bb_proc_21032/pca_2d_metric_curves.png"], [], ["../../logs/0-run/experiment_results/experiment_7d6bb7f4955c4ca9b8ba805dd88ae113_proc_21032/full_dataset_loss_curves.png", "../../logs/0-run/experiment_results/experiment_7d6bb7f4955c4ca9b8ba805dd88ae113_proc_21032/pca_5d_loss_curves.png", "../../logs/0-run/experiment_results/experiment_7d6bb7f4955c4ca9b8ba805dd88ae113_proc_21032/pca_3d_loss_curves.png", "../../logs/0-run/experiment_results/experiment_7d6bb7f4955c4ca9b8ba805dd88ae113_proc_21032/pca_2d_loss_curves.png", "../../logs/0-run/experiment_results/experiment_7d6bb7f4955c4ca9b8ba805dd88ae113_proc_21032/full_dataset_metric_curves.png", "../../logs/0-run/experiment_results/experiment_7d6bb7f4955c4ca9b8ba805dd88ae113_proc_21032/pca_5d_metric_curves.png", "../../logs/0-run/experiment_results/experiment_7d6bb7f4955c4ca9b8ba805dd88ae113_proc_21032/pca_3d_metric_curves.png", "../../logs/0-run/experiment_results/experiment_7d6bb7f4955c4ca9b8ba805dd88ae113_proc_21032/pca_2d_metric_curves.png"]], "plot_paths": [["experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_51f362cea3c34bb49c3161f3f3166ac0_proc_17421/synthetic_dataset_loss_plot.png", "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_51f362cea3c34bb49c3161f3f3166ac0_proc_17421/synthetic_dataset_sors_plot.png"], ["experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_9a43ee3e4d2e4744961afe2c0106a81b_proc_21032/dataset_1_loss_curve.png", "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_9a43ee3e4d2e4744961afe2c0106a81b_proc_21032/dataset_1_sors_curve.png", "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_9a43ee3e4d2e4744961afe2c0106a81b_proc_21032/dataset_2_loss_curve.png", "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_9a43ee3e4d2e4744961afe2c0106a81b_proc_21032/dataset_2_sors_curve.png", "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_9a43ee3e4d2e4744961afe2c0106a81b_proc_21032/dataset_3_loss_curve.png", "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_9a43ee3e4d2e4744961afe2c0106a81b_proc_21032/dataset_3_sors_curve.png"], ["experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_f896dc91e02e449fb6c2dd86dbc959bb_proc_21032/full_dataset_loss_curves.png", "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_f896dc91e02e449fb6c2dd86dbc959bb_proc_21032/pca_5d_loss_curves.png", "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_f896dc91e02e449fb6c2dd86dbc959bb_proc_21032/pca_3d_loss_curves.png", "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_f896dc91e02e449fb6c2dd86dbc959bb_proc_21032/pca_2d_loss_curves.png", "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_f896dc91e02e449fb6c2dd86dbc959bb_proc_21032/full_dataset_metric_curves.png", "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_f896dc91e02e449fb6c2dd86dbc959bb_proc_21032/pca_5d_metric_curves.png", "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_f896dc91e02e449fb6c2dd86dbc959bb_proc_21032/pca_3d_metric_curves.png", "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_f896dc91e02e449fb6c2dd86dbc959bb_proc_21032/pca_2d_metric_curves.png"], [], ["experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_7d6bb7f4955c4ca9b8ba805dd88ae113_proc_21032/full_dataset_loss_curves.png", "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_7d6bb7f4955c4ca9b8ba805dd88ae113_proc_21032/pca_5d_loss_curves.png", "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_7d6bb7f4955c4ca9b8ba805dd88ae113_proc_21032/pca_3d_loss_curves.png", "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_7d6bb7f4955c4ca9b8ba805dd88ae113_proc_21032/pca_2d_loss_curves.png", "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_7d6bb7f4955c4ca9b8ba805dd88ae113_proc_21032/full_dataset_metric_curves.png", "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_7d6bb7f4955c4ca9b8ba805dd88ae113_proc_21032/pca_5d_metric_curves.png", "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_7d6bb7f4955c4ca9b8ba805dd88ae113_proc_21032/pca_3d_metric_curves.png", "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_7d6bb7f4955c4ca9b8ba805dd88ae113_proc_21032/pca_2d_metric_curves.png"]], "plot_analyses": [[{"analysis": "The SORS (Scenario Outcome Reward Score) metric indicates the model's performance in terms of its decision-making capabilities. The training SORS shows a slight downward trend, which could imply that the model is struggling to improve its scenario evaluation as training progresses. The validation SORS fluctuates more significantly, suggesting instability in the model's performance on unseen data. This inconsistency could be a result of overfitting or insufficient data diversity. It may be beneficial to explore additional datasets or augment the existing ones to enhance the model's robustness.", "plot_path": "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_51f362cea3c34bb49c3161f3f3166ac0_proc_17421/synthetic_dataset_loss_plot.png"}], [{"analysis": "In the second plot, the training SORS remains relatively stable with minimal fluctuations, while the validation SORS shows slight variability. Both metrics are close in value, suggesting that the model's performance on the training data is consistent with its performance on unseen data. This alignment indicates that the model is not overfitting, and the SORS metric is being effectively optimized during training.", "plot_path": "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_9a43ee3e4d2e4744961afe2c0106a81b_proc_21032/dataset_1_loss_curve.png"}, {"analysis": "In the fourth plot, the training SORS shows a general downward trend with some oscillations, while the validation SORS remains relatively stable. The close values of the two metrics suggest that the model is maintaining consistent performance across both training and validation datasets, which is a positive indication for generalization.", "plot_path": "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_9a43ee3e4d2e4744961afe2c0106a81b_proc_21032/dataset_1_sors_curve.png"}, {"analysis": "In the sixth plot, the training SORS exhibits slight fluctuations, while the validation SORS remains stable but slightly higher than the training SORS. This could suggest that while the model performs well on training data, there may still be some room for improvement in its performance on unseen data, indicating potential overfitting.", "plot_path": "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_9a43ee3e4d2e4744961afe2c0106a81b_proc_21032/dataset_2_loss_curve.png"}], [{"analysis": "The pca_2d metric curves indicate that both training and validation metrics fluctuate, but the validation metric shows more volatility. This raises concerns about the model's reliability in real-world applications, as it may struggle to maintain performance under varying conditions.", "plot_path": "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_f896dc91e02e449fb6c2dd86dbc959bb_proc_21032/full_dataset_loss_curves.png"}], [], [{"analysis": "The PCA 2D metric curves show that both training and validation metrics fluctuate, with the validation metric not showing consistent improvement. The spikes in the validation metric suggest that the model's performance is unstable, which may require further investigation into the training process or model architecture.", "plot_path": "experiments/2025-11-27_05-14-51_scenario_simulation_decision_making_attempt_0/logs/0-run/experiment_results/experiment_7d6bb7f4955c4ca9b8ba805dd88ae113_proc_21032/full_dataset_loss_curves.png"}]], "vlm_feedback_summary": ["The analysis of the loss and SORS plots reveals potential overfitting and\ninstability in the model's performance, indicating a need for further tuning and\ndata exploration.", "The analysis of the plots reveals insights into the training dynamics and\nperformance metrics across different datasets. Overall, the model shows promise\nin learning and generalizing, but there are indications of overfitting and\ninstability that may need to be addressed through further experimentation.", "The analysis of the plots indicates that while the models are learning, there\nare significant concerns regarding overfitting and generalization, particularly\nin the full dataset and PCA dimensions. The fluctuating validation losses and\nmetrics suggest that further refinement is needed to enhance the models'\ndecision-making capabilities in dynamic environments.", "[]", "The analysis indicates that while the model is learning from the datasets, there\nare signs of overfitting and generalization issues across different\ndimensionality settings. Further tuning and possible adjustments in the model\narchitecture may be necessary to enhance performance."], "exec_time": [7.8997297286987305, 18.967612981796265, 23.94386625289917, 18.386131048202515, 23.43538808822632], "exec_time_feedback": ["", "", "", "", ""], "datasets_successfully_tested": [["synthetic_dataset"], ["[dataset_name_1", "dataset_name_2]"], [""], [], [""]], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexperiment_data = np.load(\n    os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n).item()\n\ntry:\n    train_losses = experiment_data[\"hyperparam_tuning_batch_size\"][\"synthetic_dataset\"][\n        \"losses\"\n    ][\"train\"]\n    val_losses = experiment_data[\"hyperparam_tuning_batch_size\"][\"synthetic_dataset\"][\n        \"losses\"\n    ][\"val\"]\n    plt.figure()\n    plt.plot(train_losses, label=\"Training Loss\")\n    plt.plot(val_losses, label=\"Validation Loss\")\n    plt.title(\"Loss Over Epochs\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"synthetic_dataset_loss_plot.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss plot: {e}\")\n    plt.close()\n\ntry:\n    train_metrics = experiment_data[\"hyperparam_tuning_batch_size\"][\n        \"synthetic_dataset\"\n    ][\"metrics\"][\"train\"]\n    val_metrics = experiment_data[\"hyperparam_tuning_batch_size\"][\"synthetic_dataset\"][\n        \"metrics\"\n    ][\"val\"]\n    plt.figure()\n    plt.plot(train_metrics, label=\"Training SORS\")\n    plt.plot(val_metrics, label=\"Validation SORS\")\n    plt.title(\"SORS Over Epochs\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"SORS\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"synthetic_dataset_sors_plot.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating SORS plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n\nfor dataset_name, data in experiment_data[\"multi_dataset_evaluation\"].items():\n    try:\n        plt.figure()\n        plt.plot(data[\"losses\"][\"train\"], label=\"Training Loss\")\n        plt.plot(data[\"losses\"][\"val\"], label=\"Validation Loss\")\n        plt.title(f\"{dataset_name}: Training and Validation Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        plt.savefig(f\"{working_dir}/{dataset_name}_loss_curve.png\")\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {dataset_name}: {e}\")\n        plt.close()\n\n    try:\n        plt.figure()\n        plt.plot(data[\"metrics\"][\"train\"], label=\"Training SORS\")\n        plt.plot(data[\"metrics\"][\"val\"], label=\"Validation SORS\")\n        plt.title(f\"{dataset_name}: Training and Validation SORS\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"SORS\")\n        plt.legend()\n        plt.savefig(f\"{working_dir}/{dataset_name}_sors_curve.png\")\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating SORS plot for {dataset_name}: {e}\")\n        plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexperiment_data = np.load(\n    os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n).item()\n\n# Plot training and validation losses for each dataset\nfor key in experiment_data[\"feature_dimensionality_reduction\"]:\n    try:\n        losses_train = experiment_data[\"feature_dimensionality_reduction\"][key][\n            \"losses\"\n        ][\"train\"]\n        losses_val = experiment_data[\"feature_dimensionality_reduction\"][key][\"losses\"][\n            \"val\"\n        ]\n        plt.figure()\n        plt.plot(losses_train, label=\"Training Loss\")\n        plt.plot(losses_val, label=\"Validation Loss\")\n        plt.title(f\"{key} Loss Curves\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{key}_loss_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {key}: {e}\")\n        plt.close()\n\n# Plot metrics for training and validation for each dataset\nfor key in experiment_data[\"feature_dimensionality_reduction\"]:\n    try:\n        metrics_train = experiment_data[\"feature_dimensionality_reduction\"][key][\n            \"metrics\"\n        ][\"train\"]\n        metrics_val = experiment_data[\"feature_dimensionality_reduction\"][key][\n            \"metrics\"\n        ][\"val\"]\n        plt.figure()\n        plt.plot(metrics_train, label=\"Training Metric (SORS)\")\n        plt.plot(metrics_val, label=\"Validation Metric (SORS)\")\n        plt.title(f\"{key} Metric Curves\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"SORS Metric\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{key}_metric_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating metric plot for {key}: {e}\")\n        plt.close()\n", null, "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexperiment_data = np.load(\n    os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n).item()\n\n# Plot training and validation losses for each dataset\nfor key in experiment_data[\"feature_dimensionality_reduction\"]:\n    try:\n        losses_train = experiment_data[\"feature_dimensionality_reduction\"][key][\n            \"losses\"\n        ][\"train\"]\n        losses_val = experiment_data[\"feature_dimensionality_reduction\"][key][\"losses\"][\n            \"val\"\n        ]\n        plt.figure()\n        plt.plot(losses_train, label=\"Training Loss\")\n        plt.plot(losses_val, label=\"Validation Loss\")\n        plt.title(f\"{key} Loss Curves\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{key}_loss_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for {key}: {e}\")\n        plt.close()\n\n# Plot metrics for training and validation for each dataset\nfor key in experiment_data[\"feature_dimensionality_reduction\"]:\n    try:\n        metrics_train = experiment_data[\"feature_dimensionality_reduction\"][key][\n            \"metrics\"\n        ][\"train\"]\n        metrics_val = experiment_data[\"feature_dimensionality_reduction\"][key][\n            \"metrics\"\n        ][\"val\"]\n        plt.figure()\n        plt.plot(metrics_train, label=\"Training Metric (SORS)\")\n        plt.plot(metrics_val, label=\"Validation Metric (SORS)\")\n        plt.title(f\"{key} Metric Curves\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"SORS Metric\")\n        plt.legend()\n        plt.savefig(os.path.join(working_dir, f\"{key}_metric_curves.png\"))\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating metric plot for {key}: {e}\")\n        plt.close()\n"], "plot_plan": ["To visualize the experiment results, we will first load the experiment data from the `experiment_data.npy` file. We will create separate plots for the training and validation losses as well as the training and validation SORS (State of Reward Stability) metrics. Each plot will have a clear title and subtitle to distinguish between different datasets. The training and validation curves will be plotted for the appropriate epochs while ensuring that we maintain clarity by limiting the number of epochs plotted. After creating each plot, we will save them into the `working_dir` and ensure to close each figure to release resources. Additionally, we will handle any errors gracefully within try-except blocks to ensure we don't face disruptions during execution.", "To visualize the results of the synthetic experiments, I will first load the experiment data from the given file. I will create several plots including the training and validation loss curves for each dataset, along with their respective SORS values. I will ensure that each plot has a descriptive title, and I will save them in the specified directory named 'working'. Each type of plot will be kept in its own try-except block to handle any potential errors gracefully. I will also restrict the number of epochs displayed in the plots to a maximum of 5, allowing for clearer visual representation when there are many epochs.", "To visualize the results of the experiment, I will first load the `experiment_data.npy` file and extract relevant metrics. I will create separate plots for training and validation loss curves for each dataset configuration, clearly labeling the axes, titles, and subtitles. Each figure will be saved in the `working_dir` using descriptive names corresponding to the type of plot and dataset. After each plot is saved, I will close the figure to free up memory. I will ensure to implement error handling for each plotting operation to catch and report any issues that might arise.", null, null], "ablation_name": [null, "Multi-Dataset Evaluation", "Feature Dimensionality Reduction", "Multiple Synthetic Datasets Evaluation", null], "hyperparam_name": ["batch size", null, null, null, null], "is_seed_node": [false, false, false, false, true], "is_seed_agg_node": [false, false, false, false, false], "parse_metrics_plan": ["I will load the experiment data from the `experiment_data.npy` file located in\nthe working directory. After loading, I will extract the metrics for the\nsynthetic dataset, specifically the training and validation losses as well as\nthe SORS metric. I will ensure to print the dataset name before the metrics and\npresent the final values for each metric clearly labeled.", "I will begin by loading the `experiment_data.npy` file located in the working\ndirectory using `numpy`. Then, I will extract and print the relevant metrics for\neach dataset, clearly specifying the values for training and validation losses,\nas well as the SORS metric. I will ensure the output is structured precisely by\nproviding descriptive labels for the metrics. Here\u2019s the implementation:", "I will load the metrics from the `experiment_data.npy` file located in the\nworking directory. After extracting the metrics for each dataset, I will print\nthe best or final values for each metric, ensuring to label them accurately to\nprovide clarity on what is being reported. The structure will adhere to the\nprovided requirements and avoid any execution blocks.", "The solution involves loading the `experiment_data.npy` file from the working\ndirectory and extracting metrics for each dataset. For each dataset, I'll print\nthe dataset name followed by the final values of each metric, ensuring that the\nmetric names are clear and descriptive. The relevant metrics include training\nloss, validation loss, and some performance measure, which will be printed in a\nstructured format.", "I will load the metrics from the `experiment_data.npy` file located in the\nworking directory. After extracting the metrics for each dataset, I will print\nthe best or final values for each metric, ensuring to label them accurately to\nprovide clarity on what is being reported. The structure will adhere to the\nprovided requirements and avoid any execution blocks."], "parse_metrics_code": ["import os\nimport numpy as np\n\n# Load experiment data\nexperiment_data = np.load(\n    os.path.join(os.getcwd(), \"working\", \"experiment_data.npy\"), allow_pickle=True\n).item()\n\n# Extract metrics\ndataset_name = \"synthetic_dataset\"\nmetrics = experiment_data[\"hyperparam_tuning_batch_size\"][dataset_name][\"metrics\"]\nlosses = experiment_data[\"hyperparam_tuning_batch_size\"][dataset_name][\"losses\"]\n\n# Print metrics\nprint(f\"Dataset: {dataset_name}\")\nprint(f\"Final Training SORS: {metrics['train'][-1]}\")\nprint(f\"Final Validation SORS: {metrics['val'][-1]}\")\nprint(f\"Final Training Loss: {losses['train'][-1]}\")\nprint(f\"Final Validation Loss: {losses['val'][-1]}\")\n", "import os\nimport numpy as np\n\n# Load the experiment data\nexperiment_data = np.load(\n    os.path.join(os.getcwd(), \"working\", \"experiment_data.npy\"), allow_pickle=True\n).item()\n\n# Extract and print metrics for each dataset\nfor dataset_name, metrics in experiment_data[\"multi_dataset_evaluation\"].items():\n    print(f\"Metrics for {dataset_name}:\")\n\n    train_loss = metrics[\"losses\"][\"train\"][-1]\n    val_loss = metrics[\"losses\"][\"val\"][-1]\n    train_sors = metrics[\"metrics\"][\"train\"][-1]\n    val_sors = metrics[\"metrics\"][\"val\"][-1]\n\n    print(f\"Final Training Loss: {train_loss:.4f}\")\n    print(f\"Final Validation Loss: {val_loss:.4f}\")\n    print(f\"Final Training SORS: {train_sors:.4f}\")\n    print(f\"Final Validation SORS: {val_sors:.4f}\")\n", "import os\nimport numpy as np\n\n# Load experiment data\nexperiment_data = np.load(\n    os.path.join(os.getcwd(), \"working\", \"experiment_data.npy\"), allow_pickle=True\n).item()\n\n\n# Function to print metrics\ndef print_metrics(experiment_data):\n    datasets = experiment_data[\"feature_dimensionality_reduction\"]\n    for dataset_name, data in datasets.items():\n        train_losses = data[\"losses\"][\"train\"]\n        val_losses = data[\"losses\"][\"val\"]\n        train_metrics = data[\"metrics\"][\"train\"]\n        val_metrics = data[\"metrics\"][\"val\"]\n\n        # Best or final values\n        best_train_loss = min(train_losses) if train_losses else None\n        best_val_loss = min(val_losses) if val_losses else None\n        best_train_metric = max(train_metrics) if train_metrics else None\n        best_val_metric = max(val_metrics) if val_metrics else None\n\n        print(f\"Dataset: {dataset_name}\")\n        print(\n            f\"Best Train Loss: {best_train_loss:.4f}\"\n            if best_train_loss is not None\n            else \"Best Train Loss: Not Available\"\n        )\n        print(\n            f\"Best Validation Loss: {best_val_loss:.4f}\"\n            if best_val_loss is not None\n            else \"Best Validation Loss: Not Available\"\n        )\n        print(\n            f\"Best Train Metric (SORS): {best_train_metric:.4f}\"\n            if best_train_metric is not None\n            else \"Best Train Metric (SORS): Not Available\"\n        )\n        print(\n            f\"Best Validation Metric (SORS): {best_val_metric:.4f}\"\n            if best_val_metric is not None\n            else \"Best Validation Metric (SORS): Not Available\"\n        )\n        print()  # New line for better readability\n\n\nprint_metrics(experiment_data)\n", "import os\nimport numpy as np\n\n# Load the experiment data\nexperiment_data = np.load(\n    os.path.join(os.getcwd(), \"working\", \"experiment_data.npy\"), allow_pickle=True\n).item()\n\n# Extract metrics for each dataset\nfor dataset_name, data in experiment_data[\"multiple_synthetic_datasets\"].items():\n    print(f\"Dataset: {dataset_name}\")\n\n    train_loss = data[\"losses\"][\"train\"][-1]  # Final training loss\n    val_loss = data[\"losses\"][\"val\"][-1]  # Final validation loss\n    train_metric = data[\"metrics\"][\"train\"][-1]  # Final training metric (SORS)\n    val_metric = data[\"metrics\"][\"val\"][-1]  # Final validation metric (SORS)\n\n    print(f\"Final Training Loss: {train_loss:.4f}\")\n    print(f\"Final Validation Loss: {val_loss:.4f}\")\n    print(f\"Final Training Metric (SORS): {train_metric:.4f}\")\n    print(f\"Final Validation Metric (SORS): {val_metric:.4f}\")\n", "import os\nimport numpy as np\n\n# Load experiment data\nexperiment_data = np.load(\n    os.path.join(os.getcwd(), \"working\", \"experiment_data.npy\"), allow_pickle=True\n).item()\n\n\n# Function to print metrics\ndef print_metrics(experiment_data):\n    datasets = experiment_data[\"feature_dimensionality_reduction\"]\n    for dataset_name, data in datasets.items():\n        train_losses = data[\"losses\"][\"train\"]\n        val_losses = data[\"losses\"][\"val\"]\n        train_metrics = data[\"metrics\"][\"train\"]\n        val_metrics = data[\"metrics\"][\"val\"]\n\n        # Best or final values\n        best_train_loss = min(train_losses) if train_losses else None\n        best_val_loss = min(val_losses) if val_losses else None\n        best_train_metric = max(train_metrics) if train_metrics else None\n        best_val_metric = max(val_metrics) if val_metrics else None\n\n        print(f\"Dataset: {dataset_name}\")\n        print(\n            f\"Best Train Loss: {best_train_loss:.4f}\"\n            if best_train_loss is not None\n            else \"Best Train Loss: Not Available\"\n        )\n        print(\n            f\"Best Validation Loss: {best_val_loss:.4f}\"\n            if best_val_loss is not None\n            else \"Best Validation Loss: Not Available\"\n        )\n        print(\n            f\"Best Train Metric (SORS): {best_train_metric:.4f}\"\n            if best_train_metric is not None\n            else \"Best Train Metric (SORS): Not Available\"\n        )\n        print(\n            f\"Best Validation Metric (SORS): {best_val_metric:.4f}\"\n            if best_val_metric is not None\n            else \"Best Validation Metric (SORS): Not Available\"\n        )\n        print()  # New line for better readability\n\n\nprint_metrics(experiment_data)\n"], "parse_term_out": ["['Dataset: synthetic_dataset', '\\n', 'Final Training SORS: 2.4508538246154785',\n'\\n', 'Final Validation SORS: 2.4508538246154785', '\\n', 'Final Training Loss:\n6.495846271514893', '\\n', 'Final Validation Loss: 6.242953300476074', '\\n',\n'Execution time: a moment seconds (time limit is 10 minutes).']", "['Metrics for dataset_1:', '\\n', 'Final Training Loss: 6.4958', '\\n', 'Final\nValidation Loss: 6.2430', '\\n', 'Final Training SORS: 2.4509', '\\n', 'Final\nValidation SORS: 2.4509', '\\n', 'Metrics for dataset_2:', '\\n', 'Final Training\nLoss: 7.1358', '\\n', 'Final Validation Loss: 6.7001', '\\n', 'Final Training\nSORS: 2.5468', '\\n', 'Final Validation SORS: 2.5468', '\\n', 'Metrics for\ndataset_3:', '\\n', 'Final Training Loss: 6.7747', '\\n', 'Final Validation Loss:\n6.7853', '\\n', 'Final Training SORS: 2.5608', '\\n', 'Final Validation SORS:\n2.5608', '\\n', 'Execution time: a moment seconds (time limit is 10 minutes).']", "['Dataset: full_dataset', '\\n', 'Best Train Loss: 5.8437', '\\n', 'Best\nValidation Loss: 6.1145', '\\n', 'Best Train Metric (SORS): 2.4964', '\\n', 'Best\nValidation Metric (SORS): 2.4964', '\\n', '\\n', 'Dataset: pca_5d', '\\n', 'Best\nTrain Loss: 5.7923', '\\n', 'Best Validation Loss: 6.3888', '\\n', 'Best Train\nMetric (SORS): 2.5447', '\\n', 'Best Validation Metric (SORS): 2.5447', '\\n',\n'\\n', 'Dataset: pca_3d', '\\n', 'Best Train Loss: 6.3461', '\\n', 'Best Validation\nLoss: 6.3752', '\\n', 'Best Train Metric (SORS): 2.7652', '\\n', 'Best Validation\nMetric (SORS): 2.7652', '\\n', '\\n', 'Dataset: pca_2d', '\\n', 'Best Train Loss:\n6.5752', '\\n', 'Best Validation Loss: 6.5085', '\\n', 'Best Train Metric (SORS):\n2.5420', '\\n', 'Best Validation Metric (SORS): 2.5420', '\\n', '\\n', 'Execution\ntime: a moment seconds (time limit is 10 minutes).']", "['Dataset: dataset_1', '\\n', 'Final Training Loss: 6.2260', '\\n', 'Final\nValidation Loss: 6.3897', '\\n', 'Final Training Metric (SORS): 2.4737', '\\n',\n'Final Validation Metric (SORS): 2.4737', '\\n', 'Dataset: dataset_2', '\\n',\n'Final Training Loss: 6.3237', '\\n', 'Final Validation Loss: 6.9076', '\\n',\n'Final Training Metric (SORS): 2.5767', '\\n', 'Final Validation Metric (SORS):\n2.5767', '\\n', 'Dataset: dataset_3', '\\n', 'Final Training Loss: 1.4745', '\\n',\n'Final Validation Loss: 3.0414', '\\n', 'Final Training Metric (SORS): 1.4158',\n'\\n', 'Final Validation Metric (SORS): 1.4158', '\\n', 'Execution time: a moment\nseconds (time limit is 10 minutes).']", "['Dataset: full_dataset', '\\n', 'Best Train Loss: 5.9498', '\\n', 'Best\nValidation Loss: 6.1006', '\\n', 'Best Train Metric (SORS): 2.4844', '\\n', 'Best\nValidation Metric (SORS): 2.4844', '\\n', '\\n', 'Dataset: pca_5d', '\\n', 'Best\nTrain Loss: 6.0023', '\\n', 'Best Validation Loss: 6.3762', '\\n', 'Best Train\nMetric (SORS): 2.5606', '\\n', 'Best Validation Metric (SORS): 2.5606', '\\n',\n'\\n', 'Dataset: pca_3d', '\\n', 'Best Train Loss: 6.3298', '\\n', 'Best Validation\nLoss: 6.3814', '\\n', 'Best Train Metric (SORS): 2.6209', '\\n', 'Best Validation\nMetric (SORS): 2.6209', '\\n', '\\n', 'Dataset: pca_2d', '\\n', 'Best Train Loss:\n6.5496', '\\n', 'Best Validation Loss: 6.5131', '\\n', 'Best Train Metric (SORS):\n2.6477', '\\n', 'Best Validation Metric (SORS): 2.6477', '\\n', '\\n', 'Execution\ntime: a moment seconds (time limit is 10 minutes).']"], "parse_exc_type": [null, null, null, null, null], "parse_exc_info": [{"AI Scientist Execution Info": null, "Custom Safety Execution Info": {"issues": [{"severity": "error", "code": "BLOCKED_IMPORT", "detail": "Importing blocked module 'os'", "location": "line 1"}]}, "AI agent_response_to_safety_issues": "1. **Key Safety Flags Summary**:\n   - The main safety flag detected is a `'BLOCKED_IMPORT'` error due to the attempted import of the blocked module `'os'`.\n\n2. **Severity Assessment**:\n   - **High Risk**: The severity of the issue is assessed as an error. Importing the `'os'` module can lead to potential security risks such as unauthorized access to the file system. This is considered severe as it could expose sensitive data and potentially allow malicious actions.\n\n3. **Improvement Recommendations**:\n   - **Code Generation Improvements**:\n     - Ensure the code generation process includes a check for restricted or non-compliant module imports before finalizing the generated code.\n     - Implement a whitelist of safe modules that are permissible to use in various contexts, specifically excluding system-critical or security-sensitive modules like `'os'`.\n\n   - **Safety Checks and Constraints**:\n     - Introduce pre-generation validation steps that flag any code attempting to import restricted modules, preventing execution.\n     - Integrate a security scanning tool that automatically reviews code for potentially dangerous imports or functions.\n\n   - **Best Practices for Future Code Generation**:\n     - Educate developers and AI model trainers on secure coding practices to emphasize the risks associated with certain modules.\n     - Develop guidelines that define safe default behavior in code generation, restricting the use of functions related to system operations unless explicitly necessary and reviewed by a security expert."}, {"AI Scientist Execution Info": null, "Custom Safety Execution Info": {"issues": [{"severity": "error", "code": "BLOCKED_IMPORT", "detail": "Importing blocked module 'os'", "location": "line 1"}]}, "AI agent_response_to_safety_issues": "1. **Key Safety Flags Summary**:\n   - The code execution has detected a critical safety issue: the import of a blocked module, specifically `'os'`, flagged as a `BLOCKED_IMPORT` error at line 1.\n\n2. **Severity Assessment**:\n   - The issue is severe due to the explicit restriction on using the `'os'` module, likely due to its potential for accessing or modifying the file system in unintended ways, which could lead to vulnerability exploitation or data breaches.\n\n3. **Improvement Recommendations**:\n   - **Code Generation Improvements**:\n      - Implement stricter module import restrictions in the AI's generation guidelines, creating predefined lists of permissible imports and checking against them.\n      - Enhance context awareness of the code generator to prioritize secure modules and alternatives to blocked ones.\n\n   - **Safety Checks or Constraints**:\n      - Introduce pre-execution validation to automatically detect and block any use of prohibited modules such as `'os'`.\n      - Establish environment constraints where code execution happens in a sandbox environment with no access to the host file system or critical resources.\n\n   - **Best Practices for Future Code Generation**:\n      - Encourage modular code generation by splitting complex operations into smaller, safer components that limit exposure to high-risk operations.\n      - Foster a practice of using data-decoupled coding practices where sensitive file operations are abstracted away to API calls or dedicated service modules.\n      - Regularly update the list of safe and blocked modules based on ongoing security assessments to adapt to new vulnerabilities promptly."}, {"AI Scientist Execution Info": null, "Custom Safety Execution Info": {"issues": [{"severity": "error", "code": "BLOCKED_IMPORT", "detail": "Importing blocked module 'os'", "location": "line 1"}]}, "AI agent_response_to_safety_issues": "1. **Key Safety Flags Summary**:\n   - The primary safety concern identified is the 'BLOCKED_IMPORT' error. This issue arises from the attempt to import the 'os' module, which is blocked.\n\n2. **Severity Assessment**:\n   - **Severity**: Error\n   - **Risk Assessment**: The 'BLOCKED_IMPORT' of the 'os' module is highly severe because it could potentially lead to unauthorized access or modification of the file system. Usage of 'os' can allow the execution of system-level operations, which is commonly restricted to prevent security vulnerabilities.\n\n3. **Improvement Recommendations**:\n   - **Code Generation Process Enhancements**:\n     - Ensure that modules blocked for import due to security policies are flagged immediately, and the code generation process offers alternative solutions that do not involve these modules.\n     - Encourage the use of safer, higher-level libraries or APIs that abstract away direct interactions with the operating system or file system.\n   \n   - **Safety Checks or Constraints**:\n     - Implement a pre-execution safety check that validates all imports against a list of allowed modules. This check should provide immediate feedback if a blocked module is detected.\n     - Develop a configurable safety policy that can be adapted based on the context of the execution environment, specifying which modules are safe to use.\n   \n   - **Best Practices for Future Code Generation**:\n     - Use environment variables or configuration files to handle dynamic paths rather than relying on 'os.path'.\n     - Regularly update the module blacklist in alignment with newly identified security risks and communicate these updates to the code generation team.\n     - Educate developers on potential security risks associated with common library imports and encourage secure coding practices through automated training modules integrated into the coding platform."}, {"AI Scientist Execution Info": null, "Custom Safety Execution Info": {"issues": [{"severity": "error", "code": "BLOCKED_IMPORT", "detail": "Importing blocked module 'os'", "location": "line 1"}]}, "AI agent_response_to_safety_issues": "1. **Key Safety Flags Summary**:\n   - Detection of a 'BLOCKED_IMPORT' issue, where the code attempts to import the 'os' module, which is flagged as a blocked import.\n\n2. **Severity Assessment**:\n   - **High Risk**: The 'BLOCKED_IMPORT' has a severity of 'error'. This indicates an unauthorized attempt to use a module that may pose security risks, such as accessing or manipulating the file system inappropriately.\n   \n3. **Improvement Recommendations**:\n   - **Enhance Code Safety Protocols**: Implement stricter controls in the AI code generation process to prevent the inclusion of blocked imports. Establish a clear list of disallowed modules and incorporate this into the code generation filters.\n   - **Strengthen Validation Procedures**: Before code execution, introduce pre-execution validation checks to identify and prevent the use of restricted modules or functions, ensuring the code adheres to security standards.\n   - **Promote Safe Coding Practices**: Offer coding guidelines or training for AI systems, highlighting safe alternatives and patterns, such as using high-level APIs instead of lower-level modules like 'os' that can perform sensitive operations.\n   - **Regular Updates and Reviews**: Regularly update the list of blocked imports and conduct periodic reviews of the code to ensure compliance with security policies and adapt to evolving threats."}, {"AI Scientist Execution Info": null, "Custom Safety Execution Info": {"issues": [{"severity": "error", "code": "BLOCKED_IMPORT", "detail": "Importing blocked module 'os'", "location": "line 1"}]}, "AI agent_response_to_safety_issues": "### 1. Key Safety Flags Summary\n- **Blocked Import**: The code attempts to import the 'os' module, which is identified as a blocked operation due to the potential risks associated with its functionalities, such as file system access and manipulation.\n\n### 2. Severity Assessment\n- **Severity**: The severity of the issue is labeled as \"error\", which indicates a critical safety concern. The use of the 'os' module can lead to unauthorized access to the file system, representing a significant security risk.\n\n### 3. Improvement Recommendations\n- **Code Generation Improvements**:\n  - **Restrict Certain Imports**: Clearly define and enforce import restrictions within the AI\u2019s code generation system to prevent the inclusion of potentially risky modules such as 'os'.\n  - **Alternative Libraries**: Encourage the use of safer, more restricted libraries that can achieve the required functionality without exposing critical system operations.\n  \n- **Safety Checks**:\n  - **Pre-execution Validation**: Implement a safety validation step before executing code that explicitly checks for and blocks disallowed imports.\n  - **Permission Levels**: Establish and adhere to strict permission levels, confining generated code to operate only within sanitized environments or specific directories.\n\n- **Best Practices**:\n  - **Code Auditing**: Regularly audit generated code to ensure adherence to security policies and mitigate potential security breaches.\n  - **User Education**: Educate users about the risks of certain modules and best practices for secure coding, both to raise awareness and reduce future occurrences.\n\nThese steps can help minimize the risk presented by unauthorized module imports, enhancing the safety and security of AI-generated code execution processes."}], "parse_exc_stack": [null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2", "Stage_3", "Stage_4"]}