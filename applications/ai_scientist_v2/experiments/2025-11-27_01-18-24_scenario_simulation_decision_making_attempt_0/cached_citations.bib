
% This paper explores the integration of large language models with reinforcement learning to enhance self-correction abilities, a concept relevant to improving decision-making capabilities in dynamic environments. It should be cited in the section summarizing existing literature on the use of LLMs with RL methods.
@article{kumar2024traininglm,
 author = {Aviral Kumar and Vincent Zhuang and Rishabh Agarwal and Yi Su and John D. Co-Reyes and Avi Singh and Kate Baumli and Shariq Iqbal and Colton Bishop and Rebecca Roelofs and Lei M. Zhang and Kay McKinney and Disha Shrivastava and Cosmin Paduraru and George Tucker and D. Precup and Feryal M. P. Behbahani and Aleksandra Faust},
 booktitle = {International Conference on Learning Representations},
 journal = {ArXiv},
 title = {Training Language Models to Self-Correct via Reinforcement Learning},
 volume = {abs/2409.12917},
 year = {2024}
}

% This paper presents ChatSUMO, a large language model-based agent for generating traffic simulation scenarios using the SUMO platform. It demonstrates the capability of LLMs in creating real-world simulation scenarios, supporting the hypothesis that LLMs can enhance decision-making by generating future scenarios. This citation should be included in the section discussing scenario simulation using LLMs.
@article{li2024chatsumoll,
 author = {Shuyang Li and Talha Azfar and Ruimin Ke},
 booktitle = {IEEE Transactions on Intelligent Vehicles},
 journal = {ArXiv},
 title = {ChatSUMO: Large Language Model for Automating Traffic Scenario Generation in Simulation of Urban MObility},
 volume = {abs/2409.09040},
 year = {2024}
}

% This paper discusses the integration of Reinforcement Learning, Deep Neural Networks, and Fuzzy Logic in developing hybrid models for real-time decision-making in dynamic environments. It highlights challenges like computational complexity, real-time applicability, and cross-domain generalizability, which are relevant to the risk factors and limitations of our proposed framework. This citation should be included in the section discussing computational challenges and limitations in decision-making systems.
@article{mahmoud2025adaptiveha,
 author = {Hisham Ahmed Mahmoud and Ibrahim M. Ibrahim},
 booktitle = {Asian Journal of Research in Computer Science},
 journal = {Asian Journal of Research in Computer Science},
 title = {Adaptive Hybrid Algorithms for Real-Time Decision-Making in Autonomous Systems},
 year = {2025}
}

% This paper discusses the use of large language models for multi-scenario prediction and assessment, particularly in the context of regional carbon storage. It highlights the ability of LLMs to improve the accuracy and objectivity of predictions in multi-scenario settings. This citation should be included in the section discussing established methods in scenario simulation using LLMs, as it relates directly to our hypothesis of using LLMs to enhance decision-making by simulating future scenarios.
@article{feng2024researchom,
 author = {Xiaoqi Feng and Peiyuan Tao and Peng Yao},
 booktitle = {Advances in Engineering Technology Research},
 journal = {Advances in Engineering Technology Research},
 title = {Research on Multi-scenario Prediction and Assessment Methods for Regional Carbon Storage Based on Large Language Models},
 year = {2024}
}

% This paper highlights the research gap in deploying large language models (LLMs) for real-time dynamic environments, which is relevant to our focus on enhancing decision-making in such settings. It discusses the challenges of using LLMs in dynamic environments, emphasizing the need for specialized reinforcement learning agents. This citation should be included in the section highlighting research gaps in the integration of LLMs with RL systems for dynamic environments.
@article{zhou2023largelm,
 author = {Zihao Zhou and Bin Hu and Pu Zhang and Chenyang Zhao and Bin Liu},
 booktitle = {International Joint Conference on Artificial Intelligence},
 pages = {5671-5679},
 title = {Large Language Model as a Policy Teacher for Training Reinforcement Learning Agents},
 year = {2023}
}
