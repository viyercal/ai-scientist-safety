{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWlbLldUq6Jg",
        "outputId": "ee8da139-1327-4980-ea3a-24702d54ac34"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHjmqB6JsfFX"
      },
      "outputs": [],
      "source": [
        "# 1. Clone the repo\n",
        "%cd /content/drive/MyDrive\n",
        "!git clone https://github.com/viyercal/ai-scientist-safety.git\n",
        "%cd ai-scientist-safety/applications/ai_scientist_v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-0PfrpH6smmK",
        "outputId": "3806aaaf-8ad4-4043-bfe6-f47cd529f57d"
      },
      "outputs": [],
      "source": [
        "# 2. System packages for PDF + LaTeX-ish tooling\n",
        "!apt-get update -y\n",
        "!apt-get install -y poppler-utils chktex\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wG2gHx-BsmvR"
      },
      "outputs": [],
      "source": [
        "# 3. Python requirements\n",
        "!pip install anthropic backoff openai matplotlib pypdf pymupdf4llm seaborn numpy transformers datasets tiktoken wandb tqdm rich humanize dataclasses-json funcy black genson shutup python-igraph coolname jsonschema omegaconf botocore boto3 python-dotenv torch scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0l4Z4fP-smx7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = userdata.get('open_router')\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"OPENROUTER_API_KEY\"]\n",
        "os.environ[\"OPENAI_BASE_URL\"] = \"https://openrouter.ai/api/v1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS0DPSxI2tFw",
        "outputId": "284e1fb9-86f9-4da2-e7d0-5bc263c8d08c"
      },
      "outputs": [],
      "source": [
        "'''example cell to create your own experiments based on the ideas\n",
        "located in ai_scientist/ideas/curriculum_learning.json. To feed in\n",
        "your own ideas, create an md file with the format that\n",
        "curriculum_learning.md has, and place it in the ideas folder.\n",
        "Then, run the following script from the root (also listed in Sakana AI's readme)\n",
        "-->\n",
        "python ai_scientist/perform_ideation_temp_free.py \\\n",
        " --workshop-file \"ai_scientist/ideas/insert_path_to_your_file.md\" \\\n",
        " --model gpt-4o-2024-05-13 \\\n",
        " --max-num-generations 20 \\\n",
        " --num-reflections 5\n",
        "\n",
        "This will generate the json file associated with it, based on \n",
        "the agentic system researching possible research directions\n",
        "grounded in your .md file's domain, and noting these down for\n",
        "experimentation conducted by the script below.\n",
        "\n",
        "The last important note here: if you want to alter the execution\n",
        "parameters, edit bfts_config.yaml in the root directory to\n",
        "suit the experimentation to your computational constraints.\n",
        "\n",
        "For more information, please consult Sakana AI's readme.\n",
        "\n",
        "'''\n",
        "\n",
        "!python launch_scientist_bfts.py \\\n",
        " --load_ideas \"ai_scientist/ideas/curriculum_learning.json\" \\\n",
        " --add_dataset_ref \\\n",
        " --model_writeup gpt-4o \\\n",
        " --model_citation gpt-4o \\\n",
        " --model_review gpt-4o \\\n",
        " --model_agg_plots o1 \\\n",
        " --num_cite_rounds 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kO8YZp21PBE"
      },
      "outputs": [],
      "source": [
        "from ai_scientist.treesearch.interpreter import Interpreter\n",
        "\n",
        "interp = Interpreter(working_dir=\".\", timeout=5)\n",
        "\n",
        "print(\"=== UNSAFE ===\")\n",
        "r1 = interp.run(\"import subprocess\\nimport os\\nos.system('echo hi')\")\n",
        "print(\"\\n\".join(r1.term_out))\n",
        "\n",
        "print(\"\\n=== SAFE ===\")\n",
        "r2 = interp.run(\"x = 1 + 2\\nprint('x is', x)\")\n",
        "print(\"\\n\".join(r2.term_out))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
