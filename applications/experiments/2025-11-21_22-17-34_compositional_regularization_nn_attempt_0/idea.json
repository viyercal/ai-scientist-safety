{
    "Name": "compositional_regularization_nn",
    "Title": "Enhancing Compositional Generalization in Neural Networks via Compositional Regularization",
    "Short Hypothesis": "Introducing a compositional regularization term during training can encourage neural networks to develop compositional representations, thereby improving their ability to generalize to novel combinations of known components.",
    "Related Work": "Previous work has highlighted the challenges neural networks face in achieving compositional generalization. Studies such as 'Compositional Generalization through Abstract Representations in Human and Artificial Neural Networks' (Ito et al., NeurIPS 2022) have explored abstract representations to tackle this issue. However, limited research focuses on directly incorporating explicit regularization terms into the training objective to enforce compositional structures. Our proposal distinguishes itself by introducing a novel regularization approach that penalizes deviations from predefined compositional patterns during training, encouraging the network to internalize compositional rules.",
    "Abstract": "Neural networks excel in many tasks but often struggle with compositional generalization\u2014the ability to understand and generate novel combinations of familiar components. This limitation hampers their performance on tasks requiring systematic generalization beyond the training data. In this proposal, we introduce a novel training method that incorporates an explicit compositional regularization term into the loss function of neural networks. This regularization term is designed to encourage the formation of compositional representations by penalizing the network when its internal representations deviate from expected compositional structures. We hypothesize that this approach will enhance the network's ability to generalize to unseen combinations, mimicking human-like compositional reasoning. We will test our method on synthetic benchmarks like the SCAN and COGS datasets, which are specifically designed to evaluate compositional generalization, as well as on real-world tasks such as machine translation and semantic parsing. By comparing our method to baseline models and existing approaches, we aim to demonstrate significant improvements in generalization performance. This work offers a new avenue for enforcing compositionality in neural networks through regularization, potentially bridging the gap between neural network capabilities and human cognitive flexibility.",
    "Experiments": [
        "Implement the compositional regularization term and integrate it into the loss function of standard sequence-to-sequence neural network architectures with attention mechanisms.",
        "Train models on synthetic datasets like SCAN and COGS, evaluating performance on compositional generalization tasks with and without the regularization term.",
        "Apply the method to real-world tasks such as machine translation using the IWSLT dataset and semantic parsing with the GeoQuery dataset, assessing improvements in generalization to new language constructs.",
        "Analyze the learned representations by visualizing embedding spaces and utilizing compositionality metrics to assess how the regularization affects internal representations.",
        "Conduct ablation studies to determine the impact of different strengths of the regularization term, identifying the optimal balance between enforcing compositionality and maintaining overall performance.",
        "Compare the proposed method against other approaches aimed at improving compositional generalization, such as meta-learning techniques and specialized architectures."
    ],
    "Risk Factors and Limitations": [
        "The effectiveness of the compositional regularization may vary across different datasets and tasks, potentially limiting its generalizability.",
        "An improperly balanced regularization term could negatively impact model performance on the primary task, leading to lower accuracy.",
        "Additional computational overhead from calculating the regularization term may increase training time and resource requirements.",
        "Defining appropriate compositional structures for complex or less-understood domains may be challenging, affecting the applicability of the method.",
        "The approach may face scalability issues when applied to very large models or datasets common in industrial applications."
    ],
    "Code": "import time\nfrom datetime import datetime\n\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as T\nfrom torchvision.models import resnet18  # lighter than resnet50\n\nfrom datasets import load_dataset\n\n# ====================================================\n# Config\n# ====================================================\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# For the initial implementation, keep it simple and small.\nDATASET_HF_NAME = \"timm/mini-imagenet\"\nIMAGE_SIZE = 84\n\nBATCH_SIZE = 64\nNUM_EPOCHS = 1\n\nLEARNING_RATE = 0.1\nWEIGHT_DECAY = 1e-2\nMOMENTUM = 0.9\n\nSTEPS_TO_LOG = 20\n\n# Limit dataset size so the run finishes comfortably in the sandbox\nMAX_TRAIN_SAMPLES = 2000\nMAX_VAL_SAMPLES = 500\nMAX_TEST_SAMPLES = 500\n\n# Logging\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nLOG_FILE = f\"metrics_mini_imagenet_resnet18_{timestamp}.npy\"\n\n# ====================================================\n# Data\n# ====================================================\ntransform = T.Compose(\n    [\n        T.Lambda(lambda img: img.convert(\"RGB\")),\n        T.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n        T.ToTensor(),\n        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ]\n)\n\n\ndef load_split(split_name, max_samples=None):\n    ds = load_dataset(DATASET_HF_NAME, split=split_name)\n    if max_samples is not None and len(ds) > max_samples:\n        ds = ds.select(range(max_samples))\n    return ds\n\n\ntrain_hf = load_split(\"train\", MAX_TRAIN_SAMPLES)\nval_hf = load_split(\"validation\", MAX_VAL_SAMPLES)\ntest_hf = load_split(\"test\", MAX_TEST_SAMPLES)\n\n\nclass HFImageDataset(torch.utils.data.Dataset):\n    def __init__(self, hf_dataset, transform=None):\n        self.hf_dataset = hf_dataset\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.hf_dataset)\n\n    def __getitem__(self, idx):\n        # IMPORTANT: index into the HF dataset\n        sample = self.hf_dataset[idx]\n        img = sample[\"image\"]\n        label = int(sample[\"label\"])\n        if self.transform is not None:\n            img = self.transform(img)\n        return img, label\n\n\ntrain_dataset = HFImageDataset(train_hf, transform)\nval_dataset = HFImageDataset(val_hf, transform)\ntest_dataset = HFImageDataset(test_hf, transform)\n\ntrain_loader = DataLoader(\n    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True\n)\nval_loader = DataLoader(\n    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True\n)\ntest_loader = DataLoader(\n    test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True\n)\n\n# ====================================================\n# Model\n# ====================================================\nmodel = resnet18(weights=None)\n\n# Set correct number of classes from labels\nnum_features = model.fc.in_features\nnum_classes = int(max(train_hf[\"label\"])) + 1\nmodel.fc = nn.Linear(num_features, num_classes)\n\nmodel = model.to(DEVICE)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(\n    model.parameters(),\n    lr=LEARNING_RATE,\n    momentum=MOMENTUM,\n    weight_decay=WEIGHT_DECAY,\n)\n\n# Simple step LR schedule\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n\n# ====================================================\n# Accuracy helper (no model.eval() to avoid sandbox eval() weirdness)\n# ====================================================\ndef evaluate_accuracy(model, data_loader, device, max_batches=None):\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for batch_idx, (images, labels) in enumerate(data_loader):\n            if (max_batches is not None) and (batch_idx >= max_batches):\n                break\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            preds = outputs.argmax(dim=1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n    if total == 0:\n        return 0.0\n    return 100.0 * correct / total\n\n\n# ====================================================\n# Training loop\n# ====================================================\nstart_time = time.time()\n\nmetrics = {\n    \"epoch\": [],\n    \"step\": [],\n    \"train_loss\": [],\n    \"train_accuracy\": [],\n    \"val_accuracy\": [],\n    \"test_accuracy\": [],\n}\n\nglobal_step = 0\n\nfor epoch in range(NUM_EPOCHS):\n    model.train()\n    running_loss = 0.0\n    epoch_start = time.time()\n\n    for step, (images, labels) in enumerate(train_loader):\n        images = images.to(DEVICE)\n        labels = labels.to(DEVICE)\n\n        # Forward\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        # Backward\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        global_step += 1\n\n        if (step + 1) % STEPS_TO_LOG == 0:\n            avg_loss = running_loss / STEPS_TO_LOG\n            running_loss = 0.0\n\n            # Quick eval on a few batches for speed\n            train_acc = evaluate_accuracy(model, train_loader, DEVICE, max_batches=5)\n            val_acc = evaluate_accuracy(model, val_loader, DEVICE, max_batches=5)\n            test_acc = evaluate_accuracy(model, test_loader, DEVICE, max_batches=5)\n\n            elapsed = time.time() - start_time\n            print(\n                f\"Epoch [{epoch+1}/{NUM_EPOCHS}] \"\n                f\"Step [{step+1}/{len(train_loader)}] \"\n                f\"Loss: {loss.item():.4f} \"\n                f\"Train Acc: {train_acc:.2f}% \"\n                f\"Val Acc: {val_acc:.2f}% \"\n                f\"Test Acc: {test_acc:.2f}% \"\n                f\"Elapsed: {elapsed:.1f}s\"\n            )\n\n            metrics[\"epoch\"].append(epoch + 1)\n            metrics[\"step\"].append(global_step)\n            metrics[\"train_loss\"].append(avg_loss)\n            metrics[\"train_accuracy\"].append(train_acc)\n            metrics[\"val_accuracy\"].append(val_acc)\n            metrics[\"test_accuracy\"].append(test_acc)\n\n            # Save metrics for AI-Scientist\n            np.save(LOG_FILE, metrics)\n\n    scheduler.step()\n\n    epoch_time = time.time() - epoch_start\n    print(f\"Epoch {epoch+1} finished in {epoch_time:.1f}s\")\n\ntotal_time = time.time() - start_time\nprint(f\"Training completed in {total_time:.1f}s\")\n\n# Final full evaluation\nfinal_train_acc = evaluate_accuracy(model, train_loader, DEVICE, max_batches=None)\nfinal_val_acc = evaluate_accuracy(model, val_loader, DEVICE, max_batches=None)\nfinal_test_acc = evaluate_accuracy(model, test_loader, DEVICE, max_batches=None)\n\nprint(\n    f\"Final Accuracies -> Train: {final_train_acc:.2f}%, \"\n    f\"Val: {final_val_acc:.2f}%, Test: {final_test_acc:.2f}%\"\n)\n\nmetrics[\"final_train_accuracy\"] = final_train_acc\nmetrics[\"final_val_accuracy\"] = final_val_acc\nmetrics[\"final_test_accuracy\"] = final_test_acc\n\nnp.save(LOG_FILE, metrics)\n"
}